#!/usr/bin/env bash
# This script was generated by bashly 1.1.10 (https://bashly.dannyb.co)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if [[ "${BASH_VERSINFO:-0}" -lt 4 ]]; then
  printf "bash version 4 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
playground_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground\n"
    echo

    printf "  🧠 CLI for Kafka Docker Playground 🐳\n  \n  👉 Check documentation https://kafka-docker-playground.io/#/cli\n"
    echo

  else
    printf "playground - 🧠 CLI for Kafka Docker Playground 🐳\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground [OPTIONS] COMMAND\n"
  printf "  playground [COMMAND] --help | -h\n"
  printf "  playground --version\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Show help about a command\n" "$(green "help")                             "
  printf "  %s   🗺️ Show a status\n" "$(green "status")                           "
  printf "  %s   ⚙️ Configure CLI\n" "$(green "config")                           "
  echo
  printf "%s\n" "$(bold "Run commands:")"
  printf "  %s   🕹️ Run any example !\n" "$(green "run")                              "
  printf "  %s   ⚡ Simply re-run last example you ran with <playground run>\n" "$(green "re-run")                           "
  printf "  %s   🏰 Get an history of the examples which were run with run command and run it again\n" "$(green "history")                          "
  printf "  %s   🌩️  Switch to ccloud environment.\n" "$(green "switch-ccloud")                    "
  printf "  %s   💺  Switch back from previous environment before switch-ccloud was called.\n" "$(green "switch-back")                      "
  printf "  %s   ✨ Update current confluent platform or connector(s) with new version(s)\n" "$(green "update-version")                   "
  printf "  %s   👐 When --file is not provided, simply open last example you ran with <playground run>\n" "$(green "open")                             "
  printf "  %s   🛑 Stop currently running example\n" "$(green "stop")                             "
  printf "  %s   🧨 Remove all docker images (including docker volumes)\n" "$(green "remove-all-docker-images")         "
  printf "  %s   🧑‍🎓 Open Confluent documentation of currently running example\n" "$(green "open-docs")                        "
  printf "  %s   🧹 Cleanup cloud resources that were created by running examples from the playground\n" "$(green "cleanup-cloud-resources")          "
  echo
  printf "%s\n" "$(bold "Repro commands:")"
  printf "  %s   👷‍♂️ Reproduction model commands\n" "$(green "repro")                            "
  printf "  %s   📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "repro export")                     "
  printf "  %s   📥 Import tgz file which was created with export command\n" "$(green "repro import")                     "
  printf "  %s   🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n" "$(green "repro bootstrap")                  "
  echo
  printf "%s\n" "$(bold "Kafka commands:")"
  printf "  %s   🐋 Get docker-compose\n" "$(green "get-docker-compose")               "
  printf "  %s   🔢 Get JMX metrics from a container\n" "$(green "get-jmx-metrics")                  "
  echo
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   🔰 Schema commands\n" "$(green "schema")                           "
  printf "  %s   🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "schema get")                       "
  printf "  %s   ⏺️ Register a schema in specified subject\n" "$(green "schema register")                  "
  printf "  %s   🛡️ Get subject-level compatibility\n" "$(green "schema get-compatibility")         "
  printf "  %s   🛡️ Set subject-level compatibility\n" "$(green "schema set-compatibility")         "
  printf "  %s   🔏 Get subject-level mode\n" "$(green "schema get-mode")                  "
  printf "  %s   🔏 Set subject-level mode\n" "$(green "schema set-mode")                  "
  printf "  %s   🧟 Delete schema\n" "$(green "schema delete")                    "
  echo
  printf "%s\n" "$(bold "Debug commands:")"
  printf "  %s   🐞 Debug commands\n" "$(green "debug")                            "
  printf "  %s   🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "debug install-vscode-extension")   "
  printf "  %s   ✨ Enable java remote debugging for container\n" "$(green "debug enable-remote-debugging")    "
  printf "  %s   🔐 Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "debug testssl")                    "
  printf "  %s   ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "debug generate-diagnostics")       "
  printf "  %s   🎯 Take a java thread dump\n" "$(green "debug thread-dump")                "
  printf "  %s   👻 Take a heap dump\n" "$(green "debug heap-dump")                  "
  printf "  %s   🕵️‍♂️ Take a tcp dump (sniffing network)\n" "$(green "debug tcp-dump")                   "
  printf "  %s   🚫 Blocking traffic using iptables\n" "$(green "debug block-traffic")              "
  printf "  %s   🛩️ Record flight recorder\n" "$(green "debug flight-recorder")            "
  printf "  %s   🧬 Set log level for any package\n" "$(green "debug log-level")                  "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   🐳 Container commands\n" "$(green "container")                        "
  printf "  %s   📝 Get properties file from a container\n" "$(green "container get-properties")         "
  printf "  %s   💫 Recreate container(s)\n" "$(green "container recreate")               "
  printf "  %s   🖥️  Get ip address of running containers\n" "$(green "container get-ip-addresses")       "
  printf "  %s   💀 Kill all containers\n" "$(green "container kill-all")               "
  printf "  %s   🕵️  Tail and follow container logs\n" "$(green "container logs")                   "
  printf "  %s   🛬 SSH into container\n" "$(green "container ssh")                    "
  printf "  %s   🪄  Execute command in a container\n" "$(green "container exec")                   "
  printf "  %s   🔁 Restart a container\n" "$(green "container restart")                "
  printf "  %s   ⏸️  Pause a container\n" "$(green "container pause")                  "
  printf "  %s   ⏯️  Resume a container\n" "$(green "container resume")                 "
  printf "  %s   🔫 Kill a container\n" "$(green "container kill")                   "
  echo
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   🗳 Topic commands\n" "$(green "topic")                            "
  printf "  %s   💯 Get number of records in a topic\n" "$(green "topic get-number-records")         "
  printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "topic display-consumer-offsets")   "
  printf "  %s   🔘 List topics\n" "$(green "topic list")                       "
  printf "  %s   🔬 Describe topic\n" "$(green "topic describe")                   "
  printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "topic set-schema-compatibility")   "
  printf "  %s   📥 Consume topic from beginning\n" "$(green "topic consume")                    "
  printf "  %s   📤 Produce to a topic\n" "$(green "topic produce")                    "
  printf "  %s   🆕 Create topic\n" "$(green "topic create")                     "
  printf "  %s   ❌ Delete topic and associated schema/subject if applicable\n" "$(green "topic delete")                     "
  printf "  %s   🪛 Alter topic config\n" "$(green "topic alter")                      "
  echo
  printf "%s\n" "$(bold "Connector-Plugin commands:")"
  printf "  %s   🔌 Connector-plugin commands\n" "$(green "connector-plugin")                 "
  printf "  %s   ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n" "$(green "connector-plugin search-jar")      "
  printf "  %s   💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n" "$(green "connector-plugin versions")        "
  echo
  printf "%s\n" "$(bold "Connector commands:")"
  printf "  %s   🔗 Connector commands\n" "$(green "connector")                        "
  printf "  %s   🧩 Show status of all connectors\n" "$(green "connector status")                 "
  printf "  %s   💈 Handle source and sink connectors offsets\n" "$(green "connector offsets")                "
  printf "  %s   🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n" "$(green "connector plugins")                "
  printf "  %s   ⏸️  Pause connector\n" "$(green "connector pause")                  "
  printf "  %s   🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n" "$(green "connector versions")               "
  printf "  %s   ♻️  Restart connector\n" "$(green "connector restart")                "
  printf "  %s   🛑 Stop connector (only available if CP > 7.5 )\n" "$(green "connector stop")                   "
  printf "  %s   ⏯️  Resume connector\n" "$(green "connector resume")                 "
  printf "  %s   🗑️  Delete connector\n" "$(green "connector delete")                 "
  printf "  %s   🐢 Show lag of sink connector\n" "$(green "connector show-lag")               "
  printf "  %s   🧰 Show current connector config that was applied\n" "$(green "connector show-config")            "
  printf "  %s   🔩 Show all possible configuration parameters of connector\n" "$(green "connector show-config-parameters") "
  printf "  %s   🗜️ Easily select config from all possible configuration parameters of connector\n" "$(green "connector select-config")          "
  printf "  %s   🔌 useful snippets\n" "$(green "connector snippets")               "
  printf "  %s   🧑‍🎓 Open connector documentation of currently running conector(s)\n" "$(green "connector open-docs")              "
  printf "  %s   🧬 Set connect log level\n" "$(green "connector log-level")              "
  printf "  %s   🕵️  Tail and follow connect logs\n" "$(green "connector logs")                   "
  printf "  %s   🤖 Open Fully Managed connector in Confluent Cloud dashboard\n" "$(green "connector open-in-confluent-cloud")"
  printf "  %s   🧑‍🎨  Create or update connector\n" "$(green "connector create-or-update")       "
  printf "  %s   🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n" "$(green "connector update")                 "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--vvv, -v")"
    printf "    🐛 set verbose output (set -x)\n    \n    ❗ it can print sensitive information ❗\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--output-level, -o LEVEL")"
    printf "    ❕Log level used by all commands\n    \n    Default is INFO (all INFO, WARN and ERROR will be printed in command output)\n"
    printf "    Allowed: INFO, WARN, ERROR\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "$(magenta "--version")"
    printf "    Show version number\n"
    echo

  fi
}

# :command.usage
playground_help_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground help - Show help about a command\n"
    echo

  else
    printf "playground help - Show help about a command\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground help [COMMAND]\n"
  printf "  playground help --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "COMMAND")"
    printf "    🆘 Help command\n"
    echo

  fi
}

# :command.usage
playground_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground status - 🗺️ Show a status\n"
    echo

  else
    printf "playground status - 🗺️ Show a status\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground status\n"
  printf "  playground status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_connector_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  else
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-list\n"
  printf "  playground get-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_fzf_find_files_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground generate-fzf-find-files - force call to generate_fzf_find_files\n"
    echo

  else
    printf "playground generate-fzf-find-files - force call to generate_fzf_find_files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-fzf-find-files\n"
  printf "  playground generate-fzf-find-files --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_tag_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground generate-tag-list - generate the confluent platform tag list\n"
    echo

  else
    printf "playground generate-tag-list - generate the confluent platform tag list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-tag-list\n"
  printf "  playground generate-tag-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_connector_plugin_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground generate-connector-plugin-list - generate the confluent hub plugin list\n"
    echo

  else
    printf "playground generate-connector-plugin-list - generate the confluent hub plugin list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-connector-plugin-list\n"
  printf "  playground generate-connector-plugin-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_kafka_region_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground generate-kafka-region-list - generate the confluent kafka region list\n"
    echo

  else
    printf "playground generate-kafka-region-list - generate the confluent kafka region list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-kafka-region-list\n"
  printf "  playground generate-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_connector_plugin_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-connector-plugin - Return some completion for connector plugin\n"
    echo

  else
    printf "playground get-connector-plugin - Return some completion for connector plugin\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-plugin [CUR]\n"
  printf "  playground get-connector-plugin --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_ccloud_environment_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-ccloud-environment-list - Return some completion for ccloud environment\n"
    echo

  else
    printf "playground get-ccloud-environment-list - Return some completion for ccloud environment\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ccloud-environment-list [CUR]\n"
  printf "  playground get-ccloud-environment-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_ccloud_cluster_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-ccloud-cluster-list - Return some completion for ccloud cluster\n"
    echo

  else
    printf "playground get-ccloud-cluster-list - Return some completion for ccloud cluster\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ccloud-cluster-list [CUR]\n"
  printf "  playground get-ccloud-cluster-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_tag_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-tag-list - Return some completion for confluent platform tag\n"
    echo

  else
    printf "playground get-tag-list - Return some completion for confluent platform tag\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-tag-list [CUR]\n"
  printf "  playground get-tag-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_kafka_region_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  else
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-kafka-region-list [CUR]\n"
  printf "  playground get-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  else
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-topic-list [OPTIONS]\n"
  printf "  playground get-topic-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-connect-internal-topics")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_subject_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-subject-list - Return some completion for subject list\n"
    echo

  else
    printf "playground get-subject-list - Return some completion for subject list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-subject-list [OPTIONS]\n"
  printf "  playground get-subject-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    🧟 Include soft deleted schemas\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_examples_list_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  else
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-examples-list-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-examples-list-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--without-repro")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sink-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ccloud-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--repro-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--environment-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--fully-managed-connector-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ksql-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--schema-registry-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--rest-proxy-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--other-playgrounds-only")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_zip_or_jar_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  else
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-zip-or-jar-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-zip-or-jar-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--type TYPE")"
    printf "\n"
    printf "    Allowed: zip, jar\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_any_file_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  else
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-any-file-with-fzf [CUR]\n"
  printf "  playground get-any-file-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_playground_repro_export_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-playground-repro-export-with-fzf - Return some completion for export tgz files\n"
    echo

  else
    printf "playground get-playground-repro-export-with-fzf - Return some completion for export tgz files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-playground-repro-export-with-fzf [CUR]\n"
  printf "  playground get-playground-repro-export-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_predefined_schemas_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-predefined-schemas - Return some completion for predefined schemas\n"
    echo

  else
    printf "playground get-predefined-schemas - Return some completion for predefined schemas\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-predefined-schemas [CUR]\n"
  printf "  playground get-predefined-schemas --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_update_readme_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground update-readme\n"
    echo

  else
    printf "playground update-readme\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-readme [OPTIONS]\n"
  printf "  playground update-readme --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tags TAGS")"
    printf "    💯 list of tags\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GH_TOKEN")"
    printf "    GH_TOKEN\n"
    echo

  fi
}

# :command.usage
playground_bashly_reload_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground bashly-reload\n"
    echo

  else
    printf "playground bashly-reload\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bashly-reload\n"
  printf "  playground bashly-reload --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground state\n"
    echo

  else
    printf "playground state\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state COMMAND\n"
  printf "  playground state [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_show_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground state show - Show the entire playground.ini file\n"
    echo

  else
    printf "playground state show - Show the entire playground.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state show\n"
  printf "  playground state show --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground state get - Read a value from the playground.ini file\n"
    echo

  else
    printf "playground state get - Read a value from the playground.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state get KEY\n"
  printf "  playground state get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state get hello\n"
    printf "  playground state get user.name\n"
    echo

  fi
}

# :command.usage
playground_state_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground state set - Save a value in the playground.ini file\n"
    echo

  else
    printf "playground state set - Save a value in the playground.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state set KEY VALUE\n"
  printf "  playground state set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :argument.usage
    printf "  %s\n" "$(blue "VALUE")"
    printf "    playground.ini value\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state set hello world\n"
    printf "  playground state set user.email me@example.com\n"
    echo

  fi
}

# :command.usage
playground_state_del_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground state del - Remove a value from the playground.ini file\n"
    echo

  else
    printf "playground state del - Remove a value from the playground.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state del KEY\n"
  printf "  playground state del --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state del hello\n"
    printf "  playground state del user.name\n"
    echo

  fi
}

# :command.usage
playground_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config - ⚙️ Configure CLI\n"
    echo

  else
    printf "playground config - ⚙️ Configure CLI\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config COMMAND\n"
  printf "  playground config [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   editor to use to open files\n" "$(green "editor")           "
  printf "  %s   📂 list of folders where to search for zip or jar\n" "$(green "folder_zip_or_jar")"
  printf "  %s   copy to clipboard connector config (only working on MacOS)\n" "$(green "clipboard")        "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_show_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config show - Show the entire playground_config.ini file\n"
    echo

  else
    printf "playground config show - Show the entire playground_config.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config show\n"
  printf "  playground config show --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config get - Read a value from the playground_config.ini file\n"
    echo

  else
    printf "playground config get - Read a value from the playground_config.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config get KEY\n"
  printf "  playground config get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    Config key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config get hello\n"
    printf "  playground config get user.name\n"
    echo

  fi
}

# :command.usage
playground_config_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config set - Save a value in the playground_config.ini file\n"
    echo

  else
    printf "playground config set - Save a value in the playground_config.ini file\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config set KEY VALUE\n"
  printf "  playground config set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground_config.ini key\n"
    echo

    # :argument.usage
    printf "  %s\n" "$(blue "VALUE")"
    printf "    playground_config.ini value\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config set hello world\n"
    printf "  playground config set user.email me@example.com\n"
    echo

  fi
}

# :command.usage
playground_config_editor_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config editor - editor to use to open files\n"
    echo

  else
    printf "playground config editor - editor to use to open files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config editor EDITOR\n"
  printf "  playground config editor --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "EDITOR")"
    printf "    editor\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config editor vi\n"
    printf "  playground config editor code\n"
    echo

  fi
}

# :command.usage
playground_config_folder_zip_or_jar_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config folder_zip_or_jar\n"
    echo

    printf "  📂 list of folders where to search for zip or jar\n  current folder is always included\n  \n  default is ~ (home dir)\n"
    echo

  else
    printf "playground config folder_zip_or_jar - 📂 list of folders where to search for zip or jar\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config folder_zip_or_jar FOLDER...\n"
  printf "  playground config folder_zip_or_jar --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "FOLDER...")"
    printf "    folder\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config folder_zip_or_jar ~/Downloads\n  ~/Documents/github/kafka-connect-*\n"
    printf "  playground config folder_zip_or_jar ~/Downloads\n"
    echo

  fi
}

# :command.usage
playground_config_clipboard_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config clipboard - copy to clipboard connector config (only working on MacOS)\n"
    echo

  else
    printf "playground config clipboard - copy to clipboard connector config (only working on MacOS)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config clipboard [ENABLED]\n"
  printf "  playground config clipboard --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ENABLED")"
    printf "    editor\n"
    printf "    Default: true\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config clipboard false\n"
    printf "  playground config clipboard true\n"
    echo

  fi
}

# :command.usage
playground_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run\n"
    echo

    printf "  🕹️ Run any example !\n  \n  🔥 It start an interactive mode where you'll be fully guided !\n  \n  \n  ⛅ When running Confluent Cloud (ccloud) example:\n  \n    All you have to do is to be already logged in with confluent CLI.\n  \n    By default, a new Confluent Cloud environment with a Cluster will be\n  created.\n  \n    You can configure the new cluster by setting:\n  \n    --cluster-type (or CLUSTER_TYPE environment variable): The type of cluster\n  (possible values: basic, standard and dedicated, default basic)\n    --cluster-cloud (or CLUSTER_CLOUD environment variable): The Cloud provider\n  (possible values: aws, gcp and azure, default aws)\n    --cluster-region (or CLUSTER_REGION environment variable): The Cloud region\n  (use confluent kafka region list to get the list, default eu-west-2 for aws,\n  westeurope for azure and europe-west2 for gcp)\n    --cluster-environment (or ENVIRONMENT environment variable) (optional): The\n  environment id where want your new cluster (example: txxxxx)\n  \n    In case you want to use your own existing cluster, you need to setup, in\n  addition to previous ones:\n  \n    --cluster-name (or CLUSTER_NAME environment variable): The cluster name\n    --cluster-creds (or CLUSTER_CREDS environment variable): The Kafka api key\n  and secret to use, it should be separated with colon (example:\n  <API_KEY>:<API_KEY_SECRET>)\n    --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment\n  variable) (optional, if not set, new one will be created): The Schema Registry\n  api key and secret to use, it should be separated with colon (example:\n  <SR_API_KEY>:<SR_API_KEY_SECRET>)\n"
    echo

  else
    printf "playground run - 🕹️ Run any example !\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run [OPTIONS]\n"
  printf "  playground run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--environment ENVIRONMENT")"
    printf "    🔐 The environment to start when running a connector example \n    \n    - plaintext\n    - ccloud\n    - 2way-ssl\n    - kerberos\n    - kraft-external-plaintext\n    - kraft-plaintext\n    - ldap-authorizer-sasl-plain\n    - ldap-sasl-plain\n    - rbac-sasl-plain\n    - sasl-plain\n    - sasl-scram\n    - sasl-ssl\n    - ssl_kerberos\n    \n    Default is plaintext.\n    This is only supported when example is a connector example\n"
    printf "    Allowed: ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kraft-external-plaintext, kraft-plaintext, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain\n"
    printf "    Default: plaintext\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Example file to run\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    📖 Opening example file with text editor set with playground config editor\n    <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    🤎 Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    🚀 Enable ksqlDB \n    \n    ❗ not supported with ccloud examples\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-rest-proxy")"
    printf "    🧲 Enable Rest Proxy\n    \n    ❗ not supported with ccloud examples\n    \n    By default, rest-proxy container is not started for every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3️⃣ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    🥉 Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is\n    admin/password)\n    \n    🛡️ Prometheus is reachable at http://127.0.0.1:9090\n    \n    📛 Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    🌪️ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-cloud CLUSTER-CLOUD")"
    printf "    🌤 The cloud provider: aws, gcp or azure. Default is aws\n    \n    🎓 Tip: you can also use CLUSTER_CLOUD environment variable\n"
    printf "    Allowed: aws, gcp, azure\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-type CLUSTER-TYPE")"
    printf "    🔋 The cluster type: basic, standard or dedicated. Default is basic\n    \n    🎓 Tip: you can also use CLUSTER_TYPE environment variable\n"
    printf "    Allowed: basic, standard, dedicated\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    🗺 The Cloud region. \n    \n    🎓 Tip: you can also use CLUSTER_REGION environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    🌐 The environment id where want your new cluster (example: txxxxx)\n    \n    ℹ️ Optional, if not set, new environment will be created\n    \n    🎓 Tip: you can also use ENVIRONMENT environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    🎰 The cluster name. \n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_NAME environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    🔒 The Kafka api key and secret to use, it should be separated with colon\n    (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    🔒 The Schema Registry api key and secret to use, it should be separated with\n    colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    ℹ️ Optional, if not set, new credentials will be created\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_re_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground re-run - ⚡ Simply re-run last example you ran with <playground run>\n"
    echo

  else
    printf "playground re-run - ⚡ Simply re-run last example you ran with <playground run>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground re-run\n"
  printf "  playground re-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground re-run (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_history_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground history - 🏰 Get an history of the examples which were run with run command and run it again\n"
    echo

  else
    printf "playground history - 🏰 Get an history of the examples which were run with run command and run it again\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground history\n"
  printf "  playground history --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_start_environment_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground start-environment\n"
    echo

    printf "  🔐 Simply start an environment listed in http://tinyurl.com/y4ybbw32:\n  \n  - ccloud\n  - 2way-ssl\n  - kerberos\n  - kraft-external-plaintext\n  - kraft-plaintext\n  - ldap-authorizer-sasl-plain\n  - ldap-sasl-plain\n  - mdc-kerberos\n  - mdc-plaintext\n  - mdc-sasl-plain\n  - plaintext\n  - rbac-sasl-plain\n  - sasl-plain\n  - sasl-scram\n  - sasl-ssl\n  - ssl_kerberos\n  \n  Note: when running an example with <playground run>, it is already\n  automatically done\n"
    echo

  else
    printf "playground start-environment - 🔐 Simply start an environment listed in http://tinyurl.com/y4ybbw32:\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground start-environment [OPTIONS]\n"
  printf "  playground start-environment --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--environment ENVIRONMENT")"
    printf "    🔐 The environment to start . \n    \n    - ccloud\n    - 2way-ssl\n    - kerberos\n    - kraft-external-plaintext\n    - kraft-plaintext\n    - ldap-authorizer-sasl-plain\n    - ldap-sasl-plain\n    - mdc-kerberos\n    - mdc-plaintext\n    - mdc-sasl-plain\n    - plaintext\n    - rbac-sasl-plain\n    - sasl-plain\n    - sasl-scram\n    - sasl-ssl\n    - ssl_kerberos\n    \n    Default is plaintext\n"
    printf "    Allowed: ccloud, 2way-ssl, kerberos, kraft-external-plaintext, kraft-plaintext, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos\n"
    printf "    Default: plaintext\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-control-center")"
    printf "    😴 Wait for control-center instead of connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE")"
    printf "    🔖 docker-compose override file\n    \n    ❕ It must be absolute full path\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground start-environment\n"
    printf "  playground start-environment --environment rbac-sasl-plain\n"
    echo

  fi
}

# :command.usage
playground_switch_ccloud_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground switch-ccloud\n"
    echo

    printf "  🌩️  Switch to ccloud environment.\n  \n  It will bootstrap ccloud environment based on your previously ran ccloud\n  example.\n"
    echo

  else
    printf "playground switch-ccloud - 🌩️  Switch to ccloud environment.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground switch-ccloud\n"
  printf "  playground switch-ccloud --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_switch_back_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground switch-back - 💺  Switch back from previous environment before switch-ccloud was called.\n"
    echo

  else
    printf "playground switch-back - 💺  Switch back from previous environment before switch-ccloud was called.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground switch-back\n"
  printf "  playground switch-back --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_update_version_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground update-version - ✨ Update current confluent platform or connector(s) with new version(s)\n"
    echo

  else
    printf "playground update-version - ✨ Update current confluent platform or connector(s) with new version(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-version [OPTIONS]\n"
  printf "  playground update-version --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    🤎 Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground update-version (interactive mode)\n"
    printf "  playground update-version --tag 6.2.0 --connector-tag=2.5.12,10.5.7\n"
    echo

  fi
}

# :command.usage
playground_open_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open\n"
    echo

    printf "  👐 When --file is not provided, simply open last example you ran with\n  <playground run>\n  \n  Otherwise, open any file from the playground using --file.\n"
    echo

  else
    printf "playground open - 👐 When --file is not provided, simply open last example you ran with <playground run>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open [OPTIONS]\n"
  printf "  playground open --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔎 Search any file and open it.\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_stop_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground stop - 🛑 Stop currently running example\n"
    echo

  else
    printf "playground stop - 🛑 Stop currently running example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground stop\n"
  printf "  playground stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_remove_all_docker_images_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground remove-all-docker-images - 🧨 Remove all docker images (including docker volumes)\n"
    echo

  else
    printf "playground remove-all-docker-images - 🧨 Remove all docker images (including docker volumes)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground remove-all-docker-images\n"
  printf "  playground remove-all-docker-images --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_open_docs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open-docs - 🧑‍🎓 Open Confluent documentation of currently running example\n"
    echo

  else
    printf "playground open-docs - 🧑‍🎓 Open Confluent documentation of currently running example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open-docs [OPTIONS]\n"
  printf "  playground open-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_cleanup_cloud_resources_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground cleanup-cloud-resources\n"
    echo

    printf "  🧹 Cleanup cloud resources that were created by running examples from the\n  playground\n  \n  ❗it will remove all resources created by the playground, including topics,\n  connectors, clusters, buckets, redshift cluster, etc...\n"
    echo

  else
    printf "playground cleanup-cloud-resources - 🧹 Cleanup cloud resources that were created by running examples from the playground\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground cleanup-cloud-resources [OPTIONS]\n"
  printf "  playground cleanup-cloud-resources --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--force")"
    printf "    ☢️ do not ask for confirmation\n    \n    ❗use with caution\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--resource RESOURCE (repeatable)")"
    printf "    🛁 resource to cleanup\n    \n    If not provided, all of them are cleaned up\n    \n    🎓 Tip: you can pass multiple resources by specifying --resource multiple\n    times\n"
    printf "    Allowed: aws, gcp, azure, ccloud, salesforce\n"
    printf "    Default: aws, gcp, azure, ccloud, salesforce\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AZ_USER")"
    printf "    Azure user\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AZ_PASS")"
    printf "    Azure password\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GCP_PROJECT")"
    printf "    GCP project\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AWS_ACCESS_KEY_ID")"
    printf "    AWS access key id\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AWS_SECRET_ACCESS_KEY")"
    printf "    AWS secret access key\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GCP_KEYFILE_CONTENT")"
    printf "    GCP keyfile (generated with \"cat keyfile.json | jq -aRs .\")\n"
    echo

  fi
}

# :command.usage
playground_repro_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro - 👷‍♂️ Reproduction model commands\n"
    echo

  else
    printf "playground repro - 👷‍♂️ Reproduction model commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro COMMAND\n"
  printf "  playground repro [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "export")   "
  printf "  %s   📥 Import tgz file which was created with export command\n" "$(green "import")   "
  printf "  %s   🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n" "$(green "bootstrap")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "OUTPUT_FOLDER")"
    printf "    📁 Output folder where to generate bootstrapped files\n"
    printf "    Default: reproduction-models\n"
    echo

  fi
}

# :command.usage
playground_repro_export_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro export - 📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n"
    echo

  else
    printf "playground repro export - 📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro export [OPTIONS]\n"
  printf "  playground repro export --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    Export all uncommitted reproduction models\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_import_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro import - 📥 Import tgz file which was created with export command\n"
    echo

  else
    printf "playground repro import - 📥 Import tgz file which was created with export command\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro import [OPTIONS]\n"
  printf "  playground repro import --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🤐 playground_repro_export.tgz file\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_bootstrap_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro bootstrap\n"
    echo

    printf "  🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n  \n  🔥 HIGHLY RECOMMENDED: start in interactive mode by simple running <playground\n  repro bootstrap> !\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%%f0%%9f%%9b%%a0-bootstrap-reproduction-model\n"
    echo

  else
    printf "playground repro bootstrap - 🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro bootstrap [OPTIONS]\n"
  printf "  playground repro bootstrap --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Example file to use as basis, if not set, currently running example is\n    used\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--description, -d DESCRIPTION")"
    printf "    💭 Description for the reproduction model\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--custom-smt")"
    printf "    🔧 Add a custom SMT (which is a no-op)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--pipeline SINK_FILE (repeatable)")"
    printf "    🔖 Sink example file to use for creating a pipeline. multiple --pipeline\n    flags can be used to create a pipeline with multiple sinks.\n    \n    ❕ It must be absolute full path. \n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground repro bootstrap (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_get_docker_compose_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-docker-compose - 🐋 Get docker-compose\n"
    echo

  else
    printf "playground get-docker-compose - 🐋 Get docker-compose\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-docker-compose\n"
  printf "  playground get-docker-compose --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema - 🔰 Schema commands\n"
    echo

  else
    printf "playground schema - 🔰 Schema commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema COMMAND\n"
  printf "  playground schema [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "get")              "
  printf "  %s   ⏺️ Register a schema in specified subject\n" "$(green "register")         "
  printf "  %s   🛡️ Get subject-level compatibility\n" "$(green "get-compatibility")"
  printf "  %s   🛡️ Set subject-level compatibility\n" "$(green "set-compatibility")"
  printf "  %s   🔏 Get subject-level mode\n" "$(green "get-mode")         "
  printf "  %s   🔏 Set subject-level mode\n" "$(green "set-mode")         "
  printf "  %s   🧟 Delete schema\n" "$(green "delete")           "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get - 🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n"
    echo

  else
    printf "playground schema get - 🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get [OPTIONS]\n"
  printf "  playground schema get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--id ID")"
    printf "    💯 Schema id\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    🧟 Include soft deleted subjects\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema get\n"
    printf "  playground schema get --subject <SUBJECT>\n"
    printf "  playground schema get --deleted\n"
    echo

  fi
}

# :command.usage
playground_schema_register_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema register - ⏺️ Register a schema in specified subject\n"
    echo

  else
    printf "playground schema register - ⏺️ Register a schema in specified subject\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema register [OPTIONS]\n"
  printf "  playground schema register --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--schema SCHEMA")"
    printf "    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    printf "    Default: -\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--id ID")"
    printf "    ☢️ Force schema id\n    \n    ❗it will replace any schema which already exists at given id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema register --subject test-protobuf << 'EOF'\n  syntax = \"proto3\";\n  \n  package com.github.vdesabou;\n  \n  message Customer {\n      int64 count = 1;\n      string first_name = 2;\n      string last_name = 3;\n      string address = 4;\n  }\n  EOF\n  \n  playground schema register --subject test-avro << 'EOF'\n  {\n      \"type\": \"record\",\n      \"namespace\": \"com.github.vdesabou\",\n      \"name\": \"Customer\",\n      \"fields\": [\n          {\n              \"name\": \"count\",\n              \"type\": \"long\",\n              \"doc\": \"count\"\n          },\n          {\n              \"name\": \"first_name\",\n              \"type\": \"string\",\n              \"doc\": \"First Name of Customer\"\n          },\n          {\n              \"name\": \"last_name\",\n              \"type\": \"string\",\n              \"doc\": \"Last Name of Customer\"\n          },\n          {\n              \"name\": \"address\",\n              \"type\": \"string\",\n              \"doc\": \"Address of Customer\"\n          }\n      ]\n  }\n  EOF\n"
    echo

  fi
}

# :command.usage
playground_schema_get_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get-compatibility - 🛡️ Get subject-level compatibility\n"
    echo

  else
    printf "playground schema get-compatibility - 🛡️ Get subject-level compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-compatibility [OPTIONS]\n"
  printf "  playground schema get-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-compatibility - 🛡️ Set subject-level compatibility\n"
    echo

  else
    printf "playground schema set-compatibility - 🛡️ Set subject-level compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-compatibility [OPTIONS]\n"
  printf "  playground schema set-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_mode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get-mode - 🔏 Get subject-level mode\n"
    echo

  else
    printf "playground schema get-mode - 🔏 Get subject-level mode\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-mode [OPTIONS]\n"
  printf "  playground schema get-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_mode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-mode\n"
    echo

    printf "  🔏 Set subject-level mode\n  \n  To enable mode changes on a Schema Registry cluster, you must also set\n  mode.mutability=true in the Schema Registry properties file before starting\n  Schema Registry\n"
    echo

  else
    printf "playground schema set-mode - 🔏 Set subject-level mode\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-mode [OPTIONS]\n"
  printf "  playground schema set-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--mode MODE (required)")"
    printf "    Schema Registry mode\n"
    printf "    Allowed: IMPORT, READONLY, READWRITE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema delete - 🧟 Delete schema\n"
    echo

  else
    printf "playground schema delete - 🧟 Delete schema\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema delete [OPTIONS]\n"
  printf "  playground schema delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    📛 Subject name to delete:\n      \n      if --version is provided, only that version will be deleted. Otherwise the\n    complete subject will be deleted\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION")"
    printf "    🔢 Schema version of the provided subject to delete\n    \n    Can only be used when --subject is provided\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--id ID")"
    printf "    🫵 Schema id\n    \n    Can only be used when --subject is provided\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--permanent")"
    printf "    💀 Hard delete (default is soft delete)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug - 🐞 Debug commands\n"
    echo

  else
    printf "playground debug - 🐞 Debug commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug COMMAND\n"
  printf "  playground debug [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "install-vscode-extension")"
  printf "  %s   ✨ Enable java remote debugging for container\n" "$(green "enable-remote-debugging") "
  printf "  %s   🔐 Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "testssl")                 "
  printf "  %s   ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "generate-diagnostics")    "
  printf "  %s   🎯 Take a java thread dump\n" "$(green "thread-dump")             "
  printf "  %s   👻 Take a heap dump\n" "$(green "heap-dump")               "
  printf "  %s   🕵️‍♂️ Take a tcp dump (sniffing network)\n" "$(green "tcp-dump")                "
  printf "  %s   🚫 Blocking traffic using iptables\n" "$(green "block-traffic")           "
  printf "  %s   🛩️ Record flight recorder\n" "$(green "flight-recorder")         "
  printf "  %s   🧬 Set log level for any package\n" "$(green "log-level")               "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_install_vscode_extension_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug install-vscode-extension\n"
    echo

    printf "  🪄 Install a slightly modified version of \"Shell Script Command Completion\"\n  Visual Studio Code extension\n  (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n  \n  After installation, install \"playground\" command:\n  \n  * Go on a .sh file\n  \n  * Type Ctrl+Shift+P (or ⌘+⇧+P on macOS) and choose \"Shell Completion: Load\n  Command Spec (experimental)\"\" and then type \"playground\"\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/cli?id=%%f0%%9f%%aa%%84-setup-shell-script-command-completion-visual-studio-code-extension\n"
    echo

  else
    printf "playground debug install-vscode-extension - 🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug install-vscode-extension\n"
  printf "  playground debug install-vscode-extension --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground install-vscode-extension\n"
    echo

  fi
}

# :command.usage
playground_debug_enable_remote_debugging_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug enable-remote-debugging\n"
    echo

    printf "  ✨ Enable java remote debugging for container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%%e2%%9c%%a8-remote-debugging\n"
    echo

  else
    printf "playground debug enable-remote-debugging - ✨ Enable java remote debugging for container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug enable-remote-debugging [OPTIONS]\n"
  printf "  playground debug enable-remote-debugging --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug enable-remote-debugging\n"
    printf "  playground debug enable-remote-debugging --container broker\n"
    printf "  playground debug enable-remote-debugging -c broker\n"
    echo

  fi
}

# :command.usage
playground_debug_testssl_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug testssl\n"
    echo

    printf "  🔐 Testing TLS/SSL encryption using https://testssl.sh/\n  \n  testssl <URI>, where <URI> is:\n  \n  host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS\n  protocol\n"
    echo

  else
    printf "playground debug testssl - 🔐 Testing TLS/SSL encryption using https://testssl.sh/\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug testssl [ARGUMENTS]\n"
  printf "  playground debug testssl --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ARGUMENTS")"
    printf "    arguments to pass to testssl, see https://testssl.sh for all options\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug testssl https://google.com\n"
    printf "  playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092\n"
    echo

  fi
}

# :command.usage
playground_debug_generate_diagnostics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug generate-diagnostics\n"
    echo

    printf "  ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n  \n  ⚠️ only connect and broker containers are supported for now\n  \n  see\n  https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics\n"
    echo

  else
    printf "playground debug generate-diagnostics - ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug generate-diagnostics [OPTIONS]\n"
  printf "  playground debug generate-diagnostics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug generate-diagnostics\n"
    printf "  playground debug generate-diagnostics --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_thread_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug thread-dump\n"
    echo

    printf "  🎯 Take a java thread dump\n  \n  🔖 It will save output to a file and open with text editor set with playground\n  config editor <editor> (default is code)\n"
    echo

  else
    printf "playground debug thread-dump - 🎯 Take a java thread dump\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug thread-dump [OPTIONS]\n"
  printf "  playground debug thread-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug thread-dump\n"
    printf "  playground debug thread-dump --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_heap_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug heap-dump\n"
    echo

    printf "  👻 Take a heap dump\n  \n  🔖 It will save output to a .hprof file. VisualVM (https://visualvm.github.io/)\n  or MAT (https://www.eclipse.org/mat/) can be used to read the file.\n"
    echo

  else
    printf "playground debug heap-dump - 👻 Take a heap dump\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug heap-dump [OPTIONS]\n"
  printf "  playground debug heap-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug heap-dump\n"
    printf "  playground debug heap-dump --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_tcp_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug tcp-dump - 🕵️‍♂️ Take a tcp dump (sniffing network)\n"
    echo

  else
    printf "playground debug tcp-dump - 🕵️‍♂️ Take a tcp dump (sniffing network)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug tcp-dump [OPTIONS]\n"
  printf "  playground debug tcp-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp dump should be done, if not set sniffing is done on every\n    port\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--duration DURATION")"
    printf "    Duration of the dump (default is 30 seconds).\n"
    printf "    Default: 30\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug tcp-dump --container control-center --port 9021 --duration 60\n"
    echo

  fi
}

# :command.usage
playground_debug_block_traffic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug block-traffic - 🚫 Blocking traffic using iptables\n"
    echo

  else
    printf "playground debug block-traffic - 🚫 Blocking traffic using iptables\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug block-traffic [OPTIONS]\n"
  printf "  playground debug block-traffic --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--destination DESTINATION (required)")"
    printf "    Destination: it could be an ip address, a container name or a hostname\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp traffic should be blocked\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION (required)")"
    printf "    🟢 start or stop\n"
    printf "    Allowed: start, stop\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug block-traffic --destination google.com --action start\n"
    printf "  playground debug block-traffic --container broker --destination zookeeper\n  --action start\n"
    echo

  fi
}

# :command.usage
playground_debug_flight_recorder_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug flight-recorder\n"
    echo

    printf "  🛩️ Record flight recorder\n  \n  Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring\n  \n  Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)\n"
    echo

  else
    printf "playground debug flight-recorder - 🛩️ Record flight recorder\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug flight-recorder [OPTIONS]\n"
  printf "  playground debug flight-recorder --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION (required)")"
    printf "    🟢 start or stop\n"
    printf "    Allowed: start, stop\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug flight-recorder --action start\n"
    printf "  playground debug flight-recorder --action stop\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level - 🧬 Set log level for any package\n"
    echo

  else
    printf "playground debug log-level - 🧬 Set log level for any package\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level COMMAND\n"
  printf "  playground debug log-level [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Get log levels\n" "$(green "get")"
  printf "  %s   Set log level for specific logger\n" "$(green "set")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug log-level get\n"
    printf "  playground debug log-level get -p io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level get --package io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level set -p\n  io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level get - Get log levels\n"
    echo

  else
    printf "playground debug log-level get - Get log levels\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level get [OPTIONS]\n"
  printf "  playground debug log-level get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level set - Set log level for specific logger\n"
    echo

  else
    printf "playground debug log-level set - Set log level for specific logger\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level set [OPTIONS]\n"
  printf "  playground debug log-level set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE (required)")"
    printf "    📦 Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    ❕Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_jmx_metrics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-jmx-metrics\n"
    echo

    printf "  🔢 Get JMX metrics from a container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%94%%a2-jmx-metrics\n"
    echo

  else
    printf "playground get-jmx-metrics - 🔢 Get JMX metrics from a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-jmx-metrics [OPTIONS]\n"
  printf "  playground get-jmx-metrics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--domain, -d DOMAIN")"
    printf "    Domain name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-jmx-metrics --container connect\n"
    printf "  playground get-jmx-metrics --container connect --domain \"kafka.connect\n  kafka.consumer kafka.producer\"\n"
    printf "  playground get-jmx-metrics -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container - 🐳 Container commands\n"
    echo

  else
    printf "playground container - 🐳 Container commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container COMMAND\n"
  printf "  playground container [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   📝 Get properties file from a container\n" "$(green "get-properties")  "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   💫 Recreate container(s)\n" "$(green "recreate")        "
  printf "  %s   🖥️  Get ip address of running containers\n" "$(green "get-ip-addresses")"
  printf "  %s   💀 Kill all containers\n" "$(green "kill-all")        "
  printf "  %s   🕵️  Tail and follow container logs\n" "$(green "logs")            "
  printf "  %s   🛬 SSH into container\n" "$(green "ssh")             "
  printf "  %s   🪄  Execute command in a container\n" "$(green "exec")            "
  printf "  %s   🔁 Restart a container\n" "$(green "restart")         "
  printf "  %s   ⏸️  Pause a container\n" "$(green "pause")           "
  printf "  %s   ⏯️  Resume a container\n" "$(green "resume")          "
  printf "  %s   🔫 Kill a container\n" "$(green "kill")            "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_properties_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-properties\n"
    echo

    printf "  📝 Get properties file from a container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%93%%9d-see-properties-file\n"
    echo

  else
    printf "playground container get-properties - 📝 Get properties file from a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-properties [OPTIONS]\n"
  printf "  playground container get-properties --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-properties\n"
    printf "  playground get-properties --container broker\n"
    printf "  playground get-properties -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_recreate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container recreate\n"
    echo

    printf "  💫 Recreate container(s)\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%e2%%99%%bb%%ef%%b8%%8f-re-create-containers\n"
    echo

  else
    printf "playground container recreate - 💫 Recreate container(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container recreate [OPTIONS]\n"
  printf "  playground container recreate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--ignore-current-versions")"
    printf "    Ignore current confluent platform version\n    \n    By default, the current version is used\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_ip_addresses_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-ip-addresses - 🖥️  Get ip address of running containers\n"
    echo

  else
    printf "playground container get-ip-addresses - 🖥️  Get ip address of running containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-ip-addresses\n"
  printf "  playground container get-ip-addresses --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-ip-address-container\n"
    echo

  fi
}

# :command.usage
playground_container_kill_all_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill-all - 💀 Kill all containers\n"
    echo

  else
    printf "playground container kill-all - 💀 Kill all containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill-all\n"
  printf "  playground container kill-all --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container logs - 🕵️  Tail and follow container logs\n"
    echo

  else
    printf "playground container logs - 🕵️  Tail and follow container logs\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container logs [OPTIONS]\n"
  printf "  playground container logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    😴 Wait until log appears\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)\n"
    printf "    Default: 600\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground container logs --container connect\n"
    printf "  playground container logs -c connect --open\n"
    printf "  playground container logs -c connect --wait-for-log \"StackOverflowError\"\n"
    echo

  fi
}

# :command.usage
playground_container_ssh_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container ssh - 🛬 SSH into container\n"
    echo

  else
    printf "playground container ssh - 🛬 SSH into container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container ssh [OPTIONS]\n"
  printf "  playground container ssh --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell, -s SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ssh -c connect\n"
    printf "  playground ssh -c connect -s sh\n"
    printf "  playground ssh --container connect --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_exec_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container exec - 🪄  Execute command in a container\n"
    echo

  else
    printf "playground container exec - 🪄  Execute command in a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container exec [OPTIONS]\n"
  printf "  playground container exec --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--command COMMAND (required)")"
    printf "    📲 Command to execute\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--root")"
    printf "    👑 Run command as root\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground exec -c connect -d \"date\"\n"
    printf "  playground exec -c connect -d \"whoami\" --root\n"
    printf "  playground exec --container connect --command \"whoami\" --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container restart - 🔁 Restart a container\n"
    echo

  else
    printf "playground container restart - 🔁 Restart a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container restart [OPTIONS]\n"
  printf "  playground container restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container pause - ⏸️  Pause a container\n"
    echo

  else
    printf "playground container pause - ⏸️  Pause a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container pause [OPTIONS]\n"
  printf "  playground container pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container resume - ⏯️  Resume a container\n"
    echo

  else
    printf "playground container resume - ⏯️  Resume a container\n"
    echo

  fi

  printf "Alias: unpause\n"
  echo

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container resume [OPTIONS]\n"
  printf "  playground container resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_kill_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill - 🔫 Kill a container\n"
    echo

  else
    printf "playground container kill - 🔫 Kill a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill [OPTIONS]\n"
  printf "  playground container kill --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic - 🗳 Topic commands\n"
    echo

  else
    printf "playground topic - 🗳 Topic commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic COMMAND\n"
  printf "  playground topic [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   💯 Get number of records in a topic\n" "$(green "get-number-records")      "
  printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "display-consumer-offsets")"
  printf "  %s   🔘 List topics\n" "$(green "list")                    "
  printf "  %s   🔬 Describe topic\n" "$(green "describe")                "
  printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "set-schema-compatibility")"
  printf "  %s   📥 Consume topic from beginning\n" "$(green "consume")                 "
  printf "  %s   📤 Produce to a topic\n" "$(green "produce")                 "
  printf "  %s   🆕 Create topic\n" "$(green "create")                  "
  printf "  %s   ❌ Delete topic and associated schema/subject if applicable\n" "$(green "delete")                  "
  printf "  %s   🪛 Alter topic config\n" "$(green "alter")                   "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_get_number_records_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic get-number-records - 💯 Get number of records in a topic\n"
    echo

  else
    printf "playground topic get-number-records - 💯 Get number of records in a topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic get-number-records [OPTIONS]\n"
  printf "  playground topic get-number-records --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-number-records --topic a-topic\n"
    printf "  playground get-number-records -t a-topic\n"
    echo

  fi
}

# :command.usage
playground_topic_display_consumer_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-consumer-offsets - 📭 Display content of __consumer_offsets topic\n"
    echo

  else
    printf "playground topic display-consumer-offsets - 📭 Display content of __consumer_offsets topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-consumer-offsets [OPTIONS]\n"
  printf "  playground topic display-consumer-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic list - 🔘 List topics\n"
    echo

  else
    printf "playground topic list - 🔘 List topics\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic list\n"
  printf "  playground topic list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_describe_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic describe - 🔬 Describe topic\n"
    echo

  else
    printf "playground topic describe - 🔬 Describe topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic describe [OPTIONS]\n"
  printf "  playground topic describe --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_set_schema_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility\n"
    echo

  else
    printf "playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic set-schema-compatibility [OPTIONS]\n"
  printf "  playground topic set-schema-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_consume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic consume - 📥 Consume topic from beginning\n"
    echo

  else
    printf "playground topic consume - 📥 Consume topic from beginning\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic consume [OPTIONS]\n"
  printf "  playground topic consume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-messages MAX-MESSAGES")"
    printf "    Max number of messages to display (default is 10)\n"
    printf "    Default: 10\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--min-expected-messages MIN-EXPECTED-MESSAGES")"
    printf "    Minimum expected number of messages to be present in topic, returns an error\n    if this is not the case\n    \n    Note: --topic should be specified in this case.\n"
    printf "    Default: 0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--grep GREP")"
    printf "    Verify that topic content contains record which contains specified string\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--timeout TIMEOUT")"
    printf "    Max number of seconds to wait when --min-expected-messages is used.\n    \n    Default is 60 seconds\n"
    printf "    Default: 60\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tail")"
    printf "    Tail on logs.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--plot-latencies-timestamp-field TIMESTAMP")"
    printf "    🗳 Timestamp field name that represents when record was created in source\n    system\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--key-subject KEY-SUBJECT")"
    printf "    📛 Subject for key in schema-registry to use (useful when data was produced\n    with --key-subject-name-strategy other than TopicNameStrategy)\n    \n    Note: --topic should be specified in this case.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-subject VALUE-SUBJECT")"
    printf "    📛 Subject for value in schema-registry to use (useful when data was produced\n    with --value-subject-name-strategy other than TopicNameStrategy)\n    \n    Note: --topic should be specified in this case.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-characters MAX-CHARACTERS")"
    printf "    Max characters per message to display (default is 2500)\n"
    printf "    Default: 2500\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_produce_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic produce - 📤 Produce to a topic\n"
    echo

  else
    printf "playground topic produce - 📤 Produce to a topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic produce [OPTIONS]\n"
  printf "  playground topic produce --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--key KEY")"
    printf "    🗝️ Key to use. If not set, no key is used.\n    \n    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) within single quotes\n    (see examples)\n    \n    * You can also generate json data using json or sql format using syntax from\n    https://github.com/MaterializeInc/datagen\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n    \n    * Directly set payload (\"%%g\" can be used to generate a counter)\n    \n    In case of 'raw' data (i.e not using schema):\n    \n    If the key contain a number, it will be used as starting point and\n    incremented for each record.\n    \n    Example: key1 will start with key1, then key2, etc..\n    Example: mykey-10-suffix will start with mykey-10-suffix then\n    mykey-11-suffix, etc..\n    \n    \"%%g\" can also be used to generate a counter\n    \n    Example: key%%g will start with key1, then key2, etc..\n    \n    Otherwise, the key will be same for all records.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value VALUE")"
    printf "    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * You can also generate json data using json or sql format using syntax from\n    https://github.com/MaterializeInc/datagen\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n    \n    * Directly set payload (\"%%g\" can be used to generate a counter)\n"
    printf "    Default: -\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-messages NB-MESSAGES")"
    printf "    💯 Number of messages to produce (default is 1)\n       \n    🎓  - if > <value of --max-nb-messages-per-batch> (default 300000), messages\n    will be sent in batches of <value of --max-nb-messages-per-batch> (default\n    300000) records\n        - if you set it to -1, an infinite number of records will also be sent\n    in batches\n"
    printf "    Default: 1\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH")"
    printf "    🔼 Max number of messages to send per batch when --nb-messages >\n    --max-nb-messages-per-batch\n       if --nb-messages is set to -1, this is the number of messages sent per\n    batch\n       default is 300000\n"
    printf "    Default: 300000\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH")"
    printf "    💤 Sleep time in seconds between batches\n       default is 0\n"
    printf "    Default: 0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    🔢 Number of partitions for the topic. (default is 1)\n    \n    ❌ Important: If topic is existing, it will be re-created before producing to\n    topic.\n"
    printf "    Default: 1\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compression-codec COMPRESSION-CODEC")"
    printf "    🤐 The compression codec: either 'gzip', 'snappy', 'lz4', or 'zstd'\n    If not set, there is no compression\n"
    printf "    Allowed: gzip, snappy, lz4, zstd\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--key-subject-name-strategy KEY-SUBJECT-NAME-STRATEGY")"
    printf "    Key Subject Name Strategy\n"
    printf "    Allowed: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY")"
    printf "    Value Subject Name Strategy\n"
    printf "    Allowed: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--headers HEADERS")"
    printf "    🚏 Headers to use for all records. If not set, no header is used.\n    \n    Example: --headers \"header1:value1,header2:value2\"\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--forced-key FORCED-KEY")"
    printf "    ☢️ Key to use for all records. \n    \n    🎓 Tip: use --generate-only first with avro, json-schema or protobuf to get\n    skeleton of messages and then use --forced-key to send the message you need.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--forced-value FORCED-VALUE")"
    printf "    ☢️ Value to use for all records. \n    \n    🎓 Tip: use --generate-only first with avro, json-schema or protobuf to get\n    skeleton of messages and then use --forced-value to send the message you\n    need.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--generate-only")"
    printf "    🚪 Only generate messages without sending to kafka topic.\n    \n    Used with --forced-value, this is a powerful way to send specific messages.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tombstone")"
    printf "    ⚰️ Generate tombstone (record with null value). \n    \n    --key must be set when this flag is used.\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate")"
    printf "    ☑️ Validate schema according to connect sink converter used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--no-null")"
    printf "    🪹 Never generate null fields even for optional fields\n    \n    N.B: only work with avro and json-schema\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate-config VALIDATE-CONFIG (repeatable)")"
    printf "    🔩 Converter configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr\n    \n    🎓 Tip: you can pass multiple parameters by specifying --validate-config\n    multiple times\n"
    printf "    Allowed: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-property PRODUCER-PROPERTY (repeatable)")"
    printf "    🔩 Producer configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer\n    \n    🎓 Tip: you can pass multiple parameters by specifying --producer-property\n    multiple times\n    \n    Example: --producer-property \"max.request.size=990485760\"\n    --producer-property \"client.id=myid\"\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--record-size RECORD-SIZE")"
    printf "    🏋️ Record size in bytes, eg. 1048576 for 1MB\n    \n    📢 If size is > 1Mb, --producer-property max.request.size and topic\n    max.message.bytes will be automatically set to support the record size.\n"
    printf "    Default: 0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-schema-id VALUE-SCHEMA-ID")"
    printf "    🔰 Do not auto register schema and specify schema id to use. \n    \n    It sets --property value.schema.id=x --property auto.register=false\n    --property use.latest.version=true\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic produce --tombstone --topic a-topic --key mykey\n  \n  playground topic produce -t topic-json --nb-messages 10 << 'EOF'\n  {\n      \"_meta\": {\n          \"topic\": \"\",\n          \"key\": \"\",\n          \"relationships\": []\n      },\n      \"nested\": {\n          \"phone\": \"faker.phone.imei()\",\n          \"website\": \"faker.internet.domainName()\"\n      },\n      \"id\": \"iteration.index\",\n      \"name\": \"faker.internet.userName()\",\n      \"email\": \"faker.internet.exampleEmail()\",\n      \"phone\": \"faker.phone.imei()\",\n      \"website\": \"faker.internet.domainName()\",\n      \"city\": \"faker.address.city()\",\n      \"company\": \"faker.company.name()\"\n  }\n  EOF\n  \n  playground topic produce -t topic-avro --nb-messages 10 << 'EOF'\n  {\n    \"fields\": [\n      {\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"default\": null,\n        \"name\": \"address\",\n        \"type\": [\n          \"null\",\n          \"string\"\n        ]\n      },\n      {\n        \"name\": \"last_sale_date\",\n        \"type\": {\n          \"logicalType\": \"timestamp-millis\",\n          \"type\": \"long\"\n        }\n      },\n      {\n        \"name\": \"last_sale_price\",\n        \"type\": {\n          \"logicalType\": \"decimal\",\n          \"precision\": 15,\n          \"scale\": 2,\n          \"type\": \"bytes\"\n        }\n      },\n      {\n        \"name\": \"last_connection\",\n        \"type\": {\n          \"logicalType\": \"date\",\n          \"type\": \"int\"\n        }\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'\n  {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"additionalProperties\": false,\n    \"$id\": \"http://lh.test/Customer.schema.json\",\n    \"title\": \"Customer\",\n    \"description\": \"Customer description\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"description\": \"Customer name\",\n        \"type\": \"string\",\n        \"maxLength\": 25\n      },\n      \"surname\": {\n        \"description\": \"Customer surname\",\n        \"type\": \"string\",\n        \"minLength\": 2\n      },\n      \"email\": {\n        \"description\": \"Email\",\n        \"type\": \"string\",\n        \"pattern\": \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n      }\n    },\n    \"required\": [\n      \"name\",\n      \"surname\"\n    ]\n  }\n  EOF\n  \n  \n  playground topic produce -t topic-proto --nb-messages 1 << 'EOF'\n  syntax = \"proto3\";\n  \n  package com.github.vdesabou;\n  \n  message Customer {\n      int64 count = 1;\n      string first_name = 2;\n      string last_name = 3;\n      string address = 4;\n  }\n  EOF\n  \n  playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'\n  CREATE TABLE \"notused\".\"notused\" (\n    \"id\" int PRIMARY KEY,\n    \"name\" varchar COMMENT 'faker.internet.userName()',\n    \"merchant_id\" int NOT NULL COMMENT 'faker.datatype.number()',\n    \"price\" int COMMENT 'faker.datatype.number()',\n    \"status\" int COMMENT 'faker.datatype.boolean()',\n    \"created_at\" datetime DEFAULT (now())\n  );\n  EOF\n  \n  playground topic produce -t topic-json --nb-messages 1 --producer-property\n  \"max.request.size=990485760\" < bigjson.json\n  \n  playground topic produce -t topic-string --nb-messages 5000 << 'EOF'\n  Ad et ut pariatur officia eos.\n  Nesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet\n  atque.\n  Quidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto\n  neque.\n  Quibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat\n  molestiae natus assumenda omnis expedita.\n  Et sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum\n  culpa.\n  Qui enim facilis eos similique aperiam totam eius et at dolor dolores.\n  Ut sunt quia qui quia consectetur aut reiciendis.\n  Modi adipisci iusto aut voluptatem dolores laudantium.\n  Sequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.\n  Rerum aut amet quo possimus nihil velit quisquam ut cumque.\n  Pariatur ad officiis voluptatibus quia vel corporis ea fugit adipisci porro.\n  EOF\n  \n  # key and headers\n  # mykey1 %%g can also be used\n  playground topic produce -t topic-json-multiple-lines --nb-messages 10 --key\n  \"mykey1\" --headers \"header1:value1,header2:value2\" << 'EOF'\n  {\"u_name\": \"scissors\", \"u_price\": 2.75, \"u_quantity\": 3}\n  {\"u_name\": \"tape\", \"u_price\": 0.99, \"u_quantity\": 10}\n  {\"u_name\": \"notebooks\", \"u_price\": 1.99, \"u_quantity\": 5}\n  EOF\n  \n  # avro key\n  playground topic produce -t topic-avro-with-key --nb-messages 10 --key '\n  {\n    \"fields\": [\n      {\n        \"name\": \"id\",\n        \"type\": \"long\"\n      }\n    ],\n    \"name\": \"Key\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  ' << 'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # tombstone\n  playground topic produce -t topic-json-multiple-lines --tombstone --key\n  \"mykey1\"\n  \n  # input file\n  playground topic produce -t topic-avro-example3 < avro-schema.avsc\n  \n  # record-size\n  playground topic produce -t topic-avro-example-big-size --nb-messages 3\n  --record-size 10000000 << 'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Address of Customer\",\n        \"name\": \"address\",\n        \"type\": \"string\"\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # validate\n  playground topic produce -t topic-json-schema-validate --nb-messages 3\n  --validate << 'EOF'\n  {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"additionalProperties\": false,\n    \"$id\": \"http://lh.test/Customer.schema.json\",\n    \"title\": \"Customer\",\n    \"description\": \"Customer description\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"description\": \"Customer name\",\n        \"type\": \"string\",\n        \"maxLength\": 25\n      },\n      \"surname\": {\n        \"description\": \"Customer surname\",\n        \"type\": \"string\",\n        \"minLength\": 2\n      },\n      \"email\": {\n        \"description\": \"Email\",\n        \"type\": \"string\",\n        \"pattern\": \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n      },\n      \"holiday\": {\n        \"oneOf\": [\n          {\n            \"title\": \"Not included\",\n            \"type\": \"null\"\n          },\n          {}\n        ]\n      },\n      \"f2\": {}\n    },\n    \"required\": [\n      \"name\",\n      \"surname\"\n    ]\n  }\n  EOF\n  \n  #  --value-subject-name-strategy\n  playground topic produce -t topic-avro-example-value-subject-name-strategy\n  --nb-messages 10 --value-subject-name-strategy TopicRecordNameStrategy <<\n  'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Address of Customer\",\n        \"name\": \"address\",\n        \"type\": \"string\"\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # --generate-only\n  playground topic produce -t topic-avro-example-forced-value --nb-messages 10 \n  --generate-only << 'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Address of Customer\",\n        \"name\": \"address\",\n        \"type\": \"string\"\n      },\n      {\n        \"name\": \"createdDate\",\n        \"type\": {\n          \"logicalType\": \"timestamp-millis\",\n          \"type\": \"long\"\n        }\n      },\n      {\n        \"default\": null,\n        \"name\": \"warranty_expiration\",\n        \"type\": [\n          \"null\",\n          {\n            \"logicalType\": \"date\",\n            \"type\": \"int\"\n          }\n        ]\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # --forced-value\n  playground topic produce -t topic-avro-example-forced-value --nb-messages 1\n  --forced-value '{\"count\":4,\"first_name\":\"Vincent\",\"last_name\":\"de\n  Saboulin\",\"address\":\"xxx\",\"createdDate\":1697852606000,\"warranty_expiration\":{\"int\":19653}}'\n  << 'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Address of Customer\",\n        \"name\": \"address\",\n        \"type\": \"string\"\n      },\n      {\n        \"name\": \"createdDate\",\n        \"type\": {\n          \"logicalType\": \"timestamp-millis\",\n          \"type\": \"long\"\n        }\n      },\n      {\n        \"default\": null,\n        \"name\": \"warranty_expiration\",\n        \"type\": [\n          \"null\",\n          {\n            \"logicalType\": \"date\",\n            \"type\": \"int\"\n          }\n        ]\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # json schema references\n  playground topic produce --value\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/customer.json\n  --reference\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/address.json\n  --reference\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/email.json\n  --topic customers\n"
    echo

  fi
}

# :command.usage
playground_topic_create_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic create - 🆕 Create topic\n"
    echo

  else
    printf "playground topic create - 🆕 Create topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic create [OPTIONS] [--] [ARGUMENTS...]\n"
  printf "  playground topic create --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    Number of partitions for the topic. (default is 1)\n"
    printf "    Default: 1\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-topics --create\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic create --topic atopic\n  playground topic create --topic atopic --nb-partitions 8 --config\n  retention.ms=30000 --config cleanup.policy=compact\n"
    echo

  fi
}

# :command.usage
playground_topic_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic delete - ❌ Delete topic and associated schema/subject if applicable\n"
    echo

  else
    printf "playground topic delete - ❌ Delete topic and associated schema/subject if applicable\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic delete [OPTIONS]\n"
  printf "  playground topic delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-delete-schema SKIP-DELETE-SCHEMA")"
    printf "    🔰 Do not delete subject/schema\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_alter_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic alter - 🪛 Alter topic config\n"
    echo

  else
    printf "playground topic alter - 🪛 Alter topic config\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic alter [OPTIONS] [--] [ARGUMENTS...]\n"
  printf "  playground topic alter --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-configs --alter. If the topic does not\n    exist, it is created first.\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic alter --topic atopic --add-config max.message.bytes=5242940\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector-plugin - 🔌 Connector-plugin commands\n"
    echo

  else
    printf "playground connector-plugin - 🔌 Connector-plugin commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin COMMAND\n"
  printf "  playground connector-plugin [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n" "$(green "search-jar")"
  printf "  %s   💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n" "$(green "versions")  "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_search_jar_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector-plugin search-jar - ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n"
    echo

  else
    printf "playground connector-plugin search-jar - ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin search-jar [OPTIONS]\n"
  printf "  playground connector-plugin search-jar --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-plugin, -c CONNECTOR-PLUGIN (required)")"
    printf "    🔌 Connector plugin name\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--class CLASS")"
    printf "    ☕ Java class name to search for in all jars\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector-plugin search-jar --connector-plugin\n  confluentinc/kafka-connect-s3 --class WebIdentityTokenCredentialsProvider\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_versions_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector-plugin versions - 💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n"
    echo

  else
    printf "playground connector-plugin versions - 💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin versions [OPTIONS]\n"
  printf "  playground connector-plugin versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-plugin, -c CONNECTOR-PLUGIN (required)")"
    printf "    🔌 Connector plugin name\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    ☢️ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--last LAST")"
    printf "    🆕 Number of last versions to show\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector-plugin versions --connector-plugin\n  confluentinc/kafka-connect-s3\n"
    echo

  fi
}

# :command.usage
playground_connector_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector - 🔗 Connector commands\n"
    echo

  else
    printf "playground connector - 🔗 Connector commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector COMMAND\n"
  printf "  playground connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🧩 Show status of all connectors\n" "$(green "status")                 "
  printf "  %s   💈 Handle source and sink connectors offsets\n" "$(green "offsets")                "
  printf "  %s   🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n" "$(green "plugins")                "
  printf "  %s   ⏸️  Pause connector\n" "$(green "pause")                  "
  printf "  %s   🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n" "$(green "versions")               "
  printf "  %s   ♻️  Restart connector\n" "$(green "restart")                "
  printf "  %s   🛑 Stop connector (only available if CP > 7.5 )\n" "$(green "stop")                   "
  printf "  %s   ⏯️  Resume connector\n" "$(green "resume")                 "
  printf "  %s   🗑️  Delete connector\n" "$(green "delete")                 "
  printf "  %s   🐢 Show lag of sink connector\n" "$(green "show-lag")               "
  printf "  %s   🧰 Show current connector config that was applied\n" "$(green "show-config")            "
  printf "  %s   🔩 Show all possible configuration parameters of connector\n" "$(green "show-config-parameters") "
  printf "  %s   🗜️ Easily select config from all possible configuration parameters of connector\n" "$(green "select-config")          "
  printf "  %s   🔌 useful snippets\n" "$(green "snippets")               "
  printf "  %s   🧑‍🎓 Open connector documentation of currently running conector(s)\n" "$(green "open-docs")              "
  printf "  %s   🧬 Set connect log level\n" "$(green "log-level")              "
  printf "  %s   🧑‍🎨  Create or update connector\n" "$(green "create-or-update")       "
  printf "  %s   🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n" "$(green "update")                 "
  echo
  printf "%s\n" "$(bold "Connect commands:")"
  printf "  %s   🕵️  Tail and follow connect logs\n" "$(green "logs")                   "
  printf "  %s   🤖 Open Fully Managed connector in Confluent Cloud dashboard\n" "$(green "open-in-confluent-cloud")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector status\n"
    printf "  playground connector status --json\n"
    printf "  playground connector resume --connector <connector-name>\n"
    printf "  playground connector pause -c <connector-name>\n"
    printf "  playground connector delete -c <connector-name>\n"
    echo

  fi
}

# :command.usage
playground_connector_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector status - 🧩 Show status of all connectors\n"
    echo

  else
    printf "playground connector status - 🧩 Show status of all connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector status [OPTIONS]\n"
  printf "  playground connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets\n"
    echo

    printf "  💈 Handle source and sink connectors offsets\n  \n    Note: First-class offsets (KIP-875) is only available if CP > 7.6\n"
    echo

  else
    printf "playground connector offsets - 💈 Handle source and sink connectors offsets\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets COMMAND\n"
  printf "  playground connector offsets [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🏹 Get current offsets for source and sink connectors\n" "$(green "get")  "
  printf "  %s   🆕 Reset offsets for source and sink connectors\n" "$(green "reset")"
  printf "  %s   ⛏️ Alter offsets for source and sink connectors\n" "$(green "alter")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets get\n"
    echo

    printf "  🏹 Get current offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud source connectors as EA (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n"
    echo

  else
    printf "playground connector offsets get - 🏹 Get current offsets for source and sink connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets get [OPTIONS]\n"
  printf "  playground connector offsets get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_reset_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets reset\n"
    echo

    printf "  🆕 Reset offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud connectors as EA (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n"
    echo

  else
    printf "playground connector offsets reset - 🆕 Reset offsets for source and sink connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets reset [OPTIONS]\n"
  printf "  playground connector offsets reset --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_alter_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets alter\n"
    echo

    printf "  ⛏️ Alter offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud connectors as EA (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n"
    echo

  else
    printf "playground connector offsets alter - ⛏️ Alter offsets for source and sink connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets alter [OPTIONS]\n"
  printf "  playground connector offsets alter --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugins_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector plugins - 🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n"
    echo

  else
    printf "playground connector plugins - 🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector plugins [OPTIONS]\n"
  printf "  playground connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    🌕 Show also transforms, converters, predicates available\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector pause - ⏸️  Pause connector\n"
    echo

  else
    printf "playground connector pause - ⏸️  Pause connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector pause [OPTIONS]\n"
  printf "  playground connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_versions_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector versions\n"
    echo

    printf "  🧞 Get current and latest versions available on Confluent Hub for connector(s)\n  used in example\n"
    echo

  else
    printf "playground connector versions - 🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector versions\n"
  printf "  playground connector versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector restart - ♻️  Restart connector\n"
    echo

  else
    printf "playground connector restart - ♻️  Restart connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector restart [OPTIONS]\n"
  printf "  playground connector restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_stop_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector stop - 🛑 Stop connector (only available if CP > 7.5 )\n"
    echo

  else
    printf "playground connector stop - 🛑 Stop connector (only available if CP > 7.5 )\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector stop [OPTIONS]\n"
  printf "  playground connector stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector resume - ⏯️  Resume connector\n"
    echo

  else
    printf "playground connector resume - ⏯️  Resume connector\n"
    echo

  fi

  printf "Alias: unpause\n"
  echo

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector resume [OPTIONS]\n"
  printf "  playground connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector delete - 🗑️  Delete connector\n"
    echo

  else
    printf "playground connector delete - 🗑️  Delete connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector delete [OPTIONS]\n"
  printf "  playground connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-lag\n"
    echo

    printf "  🐢 Show lag of sink connector\n  \n  It will run until all lag becomes 0 (press ctrl-c to exit)\n"
    echo

  else
    printf "playground connector show-lag - 🐢 Show lag of sink connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-lag [OPTIONS]\n"
  printf "  playground connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--interval INTERVAL")"
    printf "    Interval between lag checks (default is 20 seconds).\n"
    printf "    Default: 20\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-config\n"
    echo

    printf "  🧰 Show current connector config that was applied\n  \n  use --force-rest-endpoint to get results with REST API /config endpoint\n  (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)\n"
    echo

  else
    printf "playground connector show-config - 🧰 Show current connector config that was applied\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config [OPTIONS]\n"
  printf "  playground connector show-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-rest-endpoint")"
    printf "    ☢️ Force using REST API /config endpoint\n    (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_parameters_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-config-parameters - 🔩 Show all possible configuration parameters of connector\n"
    echo

  else
    printf "playground connector show-config-parameters - 🔩 Show all possible configuration parameters of connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config-parameters [OPTIONS]\n"
  printf "  playground connector show-config-parameters --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    ☢️ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-json")"
    printf "    📗 Only show list of all available parameters for connector (with default\n    value when applicable)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_select_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector select-config\n"
    echo

    printf "  🗜️ Easily select config from all possible configuration parameters of\n  connector\n  \n  🎓 Tip: use <tab> to select multiple config at once !\n"
    echo

  else
    printf "playground connector select-config - 🗜️ Easily select config from all possible configuration parameters of connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector select-config [OPTIONS]\n"
  printf "  playground connector select-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_snippets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector snippets - 🔌 useful snippets\n"
    echo

  else
    printf "playground connector snippets - 🔌 useful snippets\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector snippets [OPTIONS]\n"
  printf "  playground connector snippets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--converter CONVERTER")"
    printf "    🔌 Converter\n"
    printf "    Allowed: avro, protobuf, json-schema, json, json-schema-enabled, string, bytearray\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--dlq")"
    printf "    💀 dlq\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector snippets --converter avro --dlq\n"
    echo

  fi
}

# :command.usage
playground_connector_open_docs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector open-docs - 🧑‍🎓 Open connector documentation of currently running conector(s)\n"
    echo

  else
    printf "playground connector open-docs - 🧑‍🎓 Open connector documentation of currently running conector(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector open-docs [OPTIONS]\n"
  printf "  playground connector open-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level\n"
    echo

    printf "  🧬 Set connect log level\n  \n  🎓 Tip: it will also set\n  io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema\n  registry rest requests) and\n  org.apache.kafka.connect.runtime.TransformationChain (to see records before\n  and after SMTs)\n          it will also set org.apache.kafka.connect.runtime.WorkerSinkTask for\n  sink and org.apache.kafka.connect.runtime.WorkerSourceTask for source\n  connectors.\n"
    echo

  else
    printf "playground connector log-level - 🧬 Set connect log level\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level [OPTIONS]\n"
  printf "  playground connector log-level --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    ❕Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector logs\n"
    echo

    printf "  🕵️  Tail and follow connect logs\n  \n  This is basically a shortcut for \"playground container logs --container\n  connect\"\n  \n  It does not work for Fully Managed connectors, except if you're a Confluent\n  employee, this will open log in our internal tools (make sure to follow this\n  first\n  https://github.com/confluentinc/kafka-docker-playground-internal#how-to-use)\n"
    echo

  else
    printf "playground connector logs - 🕵️  Tail and follow connect logs\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector logs [OPTIONS]\n"
  printf "  playground connector logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    😴 Wait until log appears\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)\n"
    printf "    Default: 600\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--lcc-id LCC-ID")"
    printf "    ☁️ Fully Managed lcc id (only for Confluent employees)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_open_in_confluent_cloud_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector open-in-confluent-cloud - 🤖 Open Fully Managed connector in Confluent Cloud dashboard\n"
    echo

  else
    printf "playground connector open-in-confluent-cloud - 🤖 Open Fully Managed connector in Confluent Cloud dashboard\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector open-in-confluent-cloud [OPTIONS]\n"
  printf "  playground connector open-in-confluent-cloud --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_create_or_update_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector create-or-update - 🧑‍🎨  Create or update connector\n"
    echo

  else
    printf "playground connector create-or-update - 🧑‍🎨  Create or update connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector create-or-update [JSON] [OPTIONS]\n"
  printf "  playground connector create-or-update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    🔗 Connector name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL")"
    printf "    ❕Log level\n    \n    ⚠️ Not available for ccloud connectors\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-zero-lag")"
    printf "    😴 Wait until lag becomes 0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate")"
    printf "    ✅ Validate config using PUT /connector-plugins/(string:name)/config/validate\n    (https://docs.confluent.io/platform/current/connect/references/restapi.html#put--connector-plugins-(string-name)-config-validate)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-automatic-connector-config")"
    printf "    🤖 If example is run (playground run) with --environment flag, automatic\n    configuration to adapt to the environment is added.\n    \n    This flag allows to skip this automatic configuration (only useful to\n    reproduce issues)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "JSON")"
    printf "    json (reads from stdin if empty)\n"
    printf "    Default: -\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector create-or-update -c filestream-sink << EOF\n{\n    \"tasks.max\": \"1\",\n    \"connector.class\":\n\"org.apache.kafka.connect.file.FileStreamSinkConnector\",\n    \"topics\": \"filestream\",\n    \"file\": \"/tmp/output.json\",\n    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n    \"value.converter.schemas.enable\": \"false\"\n}\nEOF\n"
echo

fi
}

# :command.usage
playground_connector_update_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector update - 🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n"
    echo

  else
    printf "playground connector update - 🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector update [OPTIONS]\n"
  printf "  playground connector update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector update -c filestream-sink\n"
    echo

  fi
}

# :command.normalize_input
# :command.normalize_input_function
normalize_input() {
  local arg flags passthru
  passthru=false

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $passthru == true ]]; then
      input+=("$arg")
    elif [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    elif [[ "$arg" == "--" ]]; then
      passthru=true
      input+=("$arg")
    else
      input+=("$arg")
    fi

    shift
  done
}

# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do
      echo "- \${args[$k]} = ${args[$k]}"
    done
  else
    echo args: none
  fi

  if ((${#other_args[@]})); then
    echo
    echo other_args:
    echo "- \${other_args[*]} = ${other_args[*]}"
    for i in "${!other_args[@]}"; do
      echo "- \${other_args[$i]} = ${other_args[$i]}"
    done
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do
      echo "- \${deps[$k]} = ${deps[$k]}"
    done
  fi

  if ((${#env_var_names[@]})); then
    readarray -t sorted_names < <(printf '%s\n' "${env_var_names[@]}" | sort)
    echo
    echo "environment variables:"
    for k in "${sorted_names[@]}"; do
      echo "- \$$k = ${!k:-}"
    done
  fi
}

# :command.user_lib
# src/lib/cli_function.sh
function get_environment_used() {
  environment=$(playground state get run.environment)
}

function get_connect_url_and_security() {
  get_environment_used

  connect_url="http://localhost:8083"
  security=""
  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      connect_url="https://localhost:8083"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/connect.certificate.pem --key $DIR_CLI/../../environment/$environment/security/connect.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u connectorSubmitter:connectorSubmitter"
  fi
}

function generate_get_examples_add_emoji () {
  repro=""
  if [[ $file_path == *"reproduction-models"* ]]
  then
    repro="🛠"
  fi

  if [[ $file_path == *"ccloud"* ]]
  then
    if [[ $file_path == *"fm-"* ]]
    then
      echo "${repro}🌤️🤖 $file_path" >> $output_file
    elif [[ $file_path == *"custom-connector"* ]]
    then
      echo "${repro}🌤️🛃 $file_path" >> $output_file
    elif [[ $file_path == *"environment"* ]]
    then
      echo "${repro}🌤️🔐 $file_path" >> $output_file
    else
      echo "${repro}🌤️ $file_path" >> $output_file
    fi
  elif [[ $file_path == *"connect"* ]]
  then
    if [[ $file_path == *"sink"* ]]
    then
      echo "${repro}🔗🌎🔹 $file_path" >> $output_file
    elif [[ $file_path == *"source"* ]]
    then
      echo "${repro}🔗🌎🔻 $file_path" >> $output_file
    else
      echo "${repro}🔗🌎 $file_path" >> $output_file
    fi
  elif [[ $file_path == *"ksql"* ]]
  then
    echo "${repro}🎏 $file_path" >> $output_file
  elif [[ $file_path == *"schema-registry"* ]]
  then
    echo "${repro}🔰 $file_path" >> $output_file
  elif [[ $file_path == *"rest-proxy"* ]]
  then
    echo "${repro}😴 $file_path" >> $output_file
  elif [[ $file_path == *"environment"* ]]
  then
    echo "${repro}🔐 $file_path" >> $output_file
  else
    echo "${repro}👾 $file_path" >> $output_file
  fi
}

function generate_fzf_find_files() {
  generate_get_examples_list_with_fzf_without_repro_sink_only
  generate_get_examples_list_with_fzf_without_repro
  generate_get_examples_list_with_fzf_ccloud_only
  generate_get_examples_list_with_fzf

  generate_get_examples_list_with_fzf_connector_only
  generate_get_examples_list_with_fzf_repro_only
  generate_get_examples_list_with_fzf_environemnt_only
  generate_get_examples_list_with_fzf_ksql_only
  generate_get_examples_list_with_fzf_fully_managed_connector_only
  generate_get_examples_list_with_fzf_schema_registry_only
  generate_get_examples_list_with_fzf_rest_proxy_only
  generate_get_examples_list_with_fzf_other_playgrounds_only
}

function generate_get_examples_list_with_fzf_connector_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_connector_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/connect/connect-*/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' ! -path '*/ccloud/*'  | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  sort -o $output_file $output_file
}

function generate_get_examples_list_with_fzf_repro_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_repro_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_environemnt_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_environment_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'update_run.sh' ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/security/*' -path '*/environment/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_ksql_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/ksqldb/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_fully_managed_connector_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/fm-*/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_schema_registry_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/schema-registry/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_rest_proxy_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/rest-proxy/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_other_playgrounds_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' ! -path '*/reproduction-models/*' ! -path '*/connect/*' ! -path '*/ksqldb/*' ! -path '*/schema-registry/*'  | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_without_repro_sink_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*'  ! -path '*/other/*' ! -path '*/ccloud/*'  ! -path '*/academy/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_without_repro () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' ! -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_ccloud_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/security/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_all"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/security/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function get_ccloud_connect() {
  get_kafka_docker_playground_dir

  if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
  then
      logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
      exit 1
  fi

  environment=$(grep "ENVIRONMENT ID" $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta | cut -d " " -f 4)
  cluster=$(grep "KAFKA CLUSTER ID" $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta | cut -d " " -f 5)

  if [ -z $CLOUD_API_KEY ]
  then
    logerror "❌ environment variable CLOUD_API_KEY should be set to use $CONNECTOR_TYPE_FULLY_MANAGED or $CONNECTOR_TYPE_CUSTOM connector"
    logerror "Set it with Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
    exit 1
  fi

  if [ -z $CLOUD_API_SECRET ]
  then
    logerror "❌ environment variable CLOUD_API_SECRET should be set to use $CONNECTOR_TYPE_FULLY_MANAGED or $CONNECTOR_TYPE_CUSTOM connector"
    logerror "Set it with Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
    exit 1
  fi

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      authorization=$(echo -n "$CLOUD_API_KEY:$CLOUD_API_SECRET" | base64)
  else
      authorization=$(echo -n "$CLOUD_API_KEY:$CLOUD_API_SECRET" | base64 -w 0)
  fi
}

function get_sr_url_and_security() {
  get_environment_used

  sr_url="http://localhost:8081"
  sr_security=""

  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      sr_url="https://localhost:8081"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      sr_security="--cert $DIR_CLI/../../environment/$environment/security/schema-registry.certificate.pem --key $DIR_CLI/../../environment/$environment/security/schema-registry.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      sr_security="-u superUser:superUser"
  elif [[ "$environment" == "ccloud" ]]
  then
    if [[ ! -n "$root_folder" ]]
    then
      # can happen in filter function where before hook is not called
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
    fi
    if [ -f $root_folder/.ccloud/env.delta ]
    then
        source $root_folder/.ccloud/env.delta
    else
        logerror "ERROR: $root_folder/.ccloud/env.delta has not been generated"
        exit 1
    fi
    sr_url=$SCHEMA_REGISTRY_URL
    sr_security="-u $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
  fi
}

function get_security_broker() {
  config_file_name="$1"
  get_environment_used

  container="broker"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="$config_file_name /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [ "$environment" == "ldap-authorizer-sasl-plain" ]
  then
      security="$config_file_name /service/kafka/users/kafka.properties"
  elif [ "$environment" == "ldap-sasl-plain" ] || [ "$environment" == "sasl-plain" ] || [ "$environment" == "sasl-scram" ]
  then
      security="$config_file_name /tmp/client.properties"
  elif [[ "$environment" != *plaintext ]]
  then
      security="$config_file_name /etc/kafka/secrets/client_without_interceptors.config"
  fi
}

function get_fzf_version() {
    version=$(fzf --version | grep -oE "[0-9]+\.[0-9]+\.[0-9]+" | cut -d " " -f 1)
    echo "$version"
}

function get_examples_list_with_fzf() {
  cur="$1"
  file="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
        res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat /{2..}');echo "$cur@$(echo $res | cut -d ' ' -f 2)"
    else
      res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 /{2..}');echo "$cur@$(echo $res | cut -d ' ' -f 2)"
    fi
  else
    res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$(echo $res | cut -d ' ' -f 2)"
  fi
}

function get_zip_or_jar_with_fzf() {
  cur="$1"
  type="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  folder_zip_or_jar=$(playground config get folder_zip_or_jar)
  if [ "$folder_zip_or_jar" == "" ]
  then
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  res=$(find $folder_zip_or_jar $PWD -name \*.$type ! -path '*/\.*' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🤐" --header="select zip or jar file" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_playground_repro_export_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  folder_zip_or_jar=$(playground config get folder_zip_or_jar)
  if [ "$folder_zip_or_jar" == "" ]
  then
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  res=$(find $folder_zip_or_jar $PWD -name playground_repro_export.tgz ! -path '*/\.*' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🍺" --header="select repro zip file" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_ccloud_environment_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(confluent environment list | awk -F'|' '{print $2"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "ID" | grep -v "\-\-\-" | grep -v '^/' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌐" --header="select ccloud environment" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_ccloud_cluster_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(confluent kafka cluster list | awk -F'|' '{print $2"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "ID" | grep -v "\-\-\-" | grep -v '^/' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌐" --header="select ccloud cluster" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_confluent_kafka_region_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat $root_folder/scripts/cli/confluent-kafka-region-list.txt | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌍" --header="select region" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_tag_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(tail -r $root_folder/scripts/cli/tag-list.txt | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🎯" --header="select cp version" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_any_files_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat $root_folder/scripts/cli/get_any_files_with_fzf | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="📃" --header="select file" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_predefined_schemas_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})
  predefined_folder=$dir2/scripts/cli/predefined-schemas

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=70%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $predefined_folder $PWD -maxdepth 3 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔰" --header="select a predefined schema" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $predefined_folder $PWD -maxdepth 3 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔰" --header="select a predefined schema" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_plugin_list() {
  cur="$1"
  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat $root_folder/scripts/cli/confluent-hub-plugin-list.txt | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔌" --header="select connector plugin" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function choose_connector_tag() {
  connector_plugin="$1"

  owner=$(echo "$connector_plugin" | cut -d "/" -f 1)
  name=$(echo "$connector_plugin" | cut -d "/" -f 2)

  filename="/tmp/version_$owner_$name"

  if [ ! -f $filename ]
  then
    playground connector-plugin versions --connector-plugin $owner/$name > /dev/null 2>&1
  fi

  if [ ! -f $filename ]
  then
      logerror "❌ could not get versions for connector plugin $connector_plugin"
      exit 1
  fi

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  tail -r $filename | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔢" --header="select connector version for $owner/$name" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer
}

function filter_not_mdc_environment() {
  get_environment_used

  if [[ "$environment" == "mdc"* ]]
  then
    echo "$environment is not supported with this command !"
  fi
}

function filter_ccloud_environment() {
  get_environment_used

  if [[ "$environment" != "ccloud" ]]
  then
    echo "environment should be ccloud with this command (it is $environment)!"
  fi
}

function filter_schema_registry_running() {
  get_sr_url_and_security

  curl $sr_security -s "${sr_url}/config" > /dev/null 2>&1
  if [ $? != 0 ]
  then
    echo "schema registry rest api should be running to run this command"
  fi
}

function filter_connect_running() {
  get_connect_url_and_security

  curl $security -s "${connect_url}" > /dev/null 2>&1
  if [ $? != 0 ]
  then
    echo "connect rest api should be running to run this command"
  fi
}

function filter_docker_running() {
  docker info >/dev/null 2>&1 || echo "Docker must be running"
}

function increment_cli_metric() {
  metric_name="$1"
  metric=$(playground state get "metrics.$metric_name")
  if [ "$metric" == "" ]
  then
    # initialize
    playground state set "metrics.$metric_name" 1
  else
    playground state set "metrics.$metric_name" $((metric+1))
  fi
}

function get_cli_metric() {
  metric_name="$1"
  playground state get "metrics.$metric_name"
}

function set_cli_metric() {
  metric_name="$1"
  metric_value="$2"
  playground state set "metrics.$metric_name" "$metric_value"
}

function add_connector_config_based_on_environment () {
  environment="$1"
  json_content="$2"

  echo "$json_content" > $tmp_dir/1.json

  case "${environment}" in
    plaintext)
      # nothing to do
      return
    ;;
    ccloud)
      if [ -f $root_folder/.ccloud/env.delta ]
      then
          source $root_folder/.ccloud/env.delta
      else
          logerror "ERROR: $root_folder/.ccloud/env.delta has not been generated"
          exit 1
      fi

      echo "$json_content" > $tmp_dir/input.json
      jq ".[\"topic.creation.default.replication.factor\"] = \"-1\" | .[\"topic.creation.default.partitions\"] = \"-1\"" $tmp_dir/input.json > $tmp_dir/output.json
      json_content=$(cat $tmp_dir/output.json)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"\${file:/data:bootstrap.servers}\" | .[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)

          if [ "$prefix" == "confluent.topic" ]
          then
            echo "$json_content" > $tmp_dir/input.json
            jq ".[\"confluent.topic.replication.factor\"] = \"3\"" $tmp_dir/input.json > $tmp_dir/output.json
            json_content=$(cat $tmp_dir/output.json)
          fi
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"$SCHEMA_REGISTRY_URL\" | .[\"$prefix.converter.basic.auth.user.info\"] = \"\${file:/data:schema.registry.basic.auth.user.info}\" | .[\"$prefix.converter.basic.auth.credentials.source\"] = \"USER_INFO\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"\${file:/data:bootstrap.servers}\" | .[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"\${file:/data:bootstrap.servers}\" | .[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.bootstrap.servers\"] = \"\${file:/data:bootstrap.servers}\" | .[\"reporter.result.topic.replication.factor\"] = \"3\" | .[\"reporter.error.topic.replication.factor\"] = \"3\" | .[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/data:sasl.username}\\\" password=\\\"\${file:/data:sasl.password}\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-plain|ldap-authorizer-sasl-plain|ldap-sasl-plain)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-ssl)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"broker:9092\" | .[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"https://schema-registry:8081\" | .[\"$prefix.converter.schema.registry.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.converter.schema.registry.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.converter.schema.registry.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"broker:9092\" | .[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"broker:9092\" | .[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    2way-ssl)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"broker:9092\" | .[\"$prefix.security.protocol\"] = \"SSL\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"https://schema-registry:8081\" | .[\"$prefix.converter.schema.registry.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.converter.schema.registry.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.converter.schema.registry.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"broker:9092\" | .[\"database.history.producer.security.protocol\"] = \"SSL\" | .[\"database.history.consumer.security.protocol\"] = \"SSL\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"database.history.producer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.producer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"database.history.consumer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"broker:9092\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SSL\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SSL\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"schema.history.internal.producer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.producer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"schema.history.internal.consumer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.security.protocol\"] = \"SSL\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.admin.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"reporter.admin.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.admin.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.security.protocol\"] = \"SSL\" | .[\"reporter.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"reporter.producer.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-scram)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    kerberos)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"GSSAPI\" | .[\"$prefix.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.consumer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.consumer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.admin.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.producer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    ssl_kerberos)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"GSSAPI\" | .[\"$prefix.sasl.kerberos.service.name\"] = \"kafka\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.consumer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.consumer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.admin.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    rbac-sasl-plain)

      echo "$json_content" > $tmp_dir/input.json
      jq ".[\"principal.service.name\"] = \"connectorSA\" | .[\"principal.service.password\"] = \"connectorSA\"" $tmp_dir/input.json > $tmp_dir/output.json
      json_content=$(cat $tmp_dir/output.json)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    *)
      return
    ;;
  esac

  echo "$json_content" > $tmp_dir/2.json
  log "✨ Following config was added to handle environment $environment:"
  set +e
  diff <(jq --sort-keys . $tmp_dir/1.json) <(jq --sort-keys . $tmp_dir/2.json)
  set -e
}

function maybe_remove_flag () {
  flag="$1"
  for ((i=0; i<${#array_flag_list[@]}; i++))
  do
    if [[ ${array_flag_list[i]} == ${flag}=* ]]
    then
        unset "array_flag_list[i]"
    fi
  done
}

function display_interactive_menu_categories () {
  repro=$1

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
      fzf_option_wrap="--preview-window=40%,wrap"
      fzf_option_pointer="--pointer=👉"
      fzf_option_rounded="--border=rounded"
  else
      fzf_option_pointer=""
      fzf_option_rounded=""
  fi

  if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only ]
  then
    playground generate-fzf-find-files
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    MAX_LENGTH=$((${terminal_columns}-120))
  else
    MAX_LENGTH=$((${terminal_columns}-65))
  fi

  if [ -f $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only ]
  then
    nb_repro=$(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only | awk '{print $1}')
  else
    nb_repro=0
  fi

  MENU_CONNECTOR="🔗 Connectors $(printf '%*s' $((${MAX_LENGTH}-13-${#MENU_CONNECTOR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_connector_only | awk '{print $1}') examples"
  MENU_CCLOUD="🌤️  Confluent cloud $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_CCLOUD})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only | awk '{print $1}') examples"
  MENU_FULLY_MANAGED_CONNECTOR="🤖 Fully-Managed connectors $(printf '%*s' $((${MAX_LENGTH}-27-${#MENU_FULLY_MANAGED_CONNECTOR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only | awk '{print $1}') examples"
  MENU_REPRO="🛠  Reproduction models $(printf '%*s' $((${MAX_LENGTH}-22-${#MENU_REPRO})) ' ') $nb_repro examples"
  MENU_OTHER="👾 Other playgrounds $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_OTHER})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only | awk '{print $1}') examples"
  MENU_ENVIRONMENTS="🔐 Environments $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_ENVIRONMENTS})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_environment_only | awk '{print $1}') examples"
  MENU_ALL="🎲 All $(printf '%*s' $((${MAX_LENGTH}-6-${#MENU_ALL})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_all | awk '{print $1}') examples"
  MENU_KSQL="🎏 ksqlDB $(printf '%*s' $((${MAX_LENGTH}-9-${#MENU_KSQL})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only | awk '{print $1}') examples"
  MENU_SR="🔰 Schema registry $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_SR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only | awk '{print $1}') examples"
  MENU_RP="🧲 Rest proxy $(printf '%*s' $((${MAX_LENGTH}-13-${#MENU_RP})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only | awk '{print $1}') examples"

  if [ "$repro" == 1 ]
  then
    propose_current_example=0
    set +e
    current_file=$(playground state get run.test_file)
    if [ $? -ne 0 ]
    then
      propose_current_example=0
    fi
    set -e
    if [ -f "$current_file" ]
    then
      last_two_folders=$(basename $(dirname $(dirname $current_file)))/$(basename $(dirname $current_file))
      filename=$(basename $current_file)
      current_file="$last_two_folders/$filename"

      if [[ $current_file != *"reproduction-models"* ]]
      then
        propose_current_example=1
      fi
    fi

    if [ $propose_current_example -eq 1 ]
    then
      MENU_CURRENT_EXAMPLE="🕹️  Current example $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_CURRENT_EXAMPLE})) ' ') $current_file"
      options=("$MENU_CURRENT_EXAMPLE" "$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP")
    else
      options=("$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP")
    fi
  else
    options=("$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_REPRO" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP")
  fi

  res=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select a category (ctrl-c or esc to quit)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_pointer)

  case "${res}" in
    "$MENU_CURRENT_EXAMPLE")
      test_file=$(playground state get run.test_file)
      if [ ! -f $test_file ]
      then
          logerror "❌ file $test_file retrieved from $root_folder/playground.ini does not exist!"
          exit 1
      fi
    ;;
    "$MENU_CONNECTOR")
      test_file=$(playground get-examples-list-with-fzf --connector-only)
    ;;
    "$MENU_CCLOUD")
      test_file=$(playground get-examples-list-with-fzf --ccloud-only)
    ;;
    "$MENU_FULLY_MANAGED_CONNECTOR")
      test_file=$(playground get-examples-list-with-fzf --fully-managed-connector-only)
    ;;
    "$MENU_REPRO")
      test_file=$(playground get-examples-list-with-fzf --repro-only)
    ;;
    "$MENU_ENVIRONMENTS")
      test_file=$(playground get-examples-list-with-fzf --environment-only)
    ;;
    "$MENU_KSQL")
      test_file=$(playground get-examples-list-with-fzf --ksql-only)
    ;;
    "$MENU_SR")
      test_file=$(playground get-examples-list-with-fzf --schema-registry-only)
    ;;
    "$MENU_RP")
      test_file=$(playground get-examples-list-with-fzf --rest-proxy-only)
    ;;
    "$MENU_OTHER")
      test_file=$(playground get-examples-list-with-fzf --other-playgrounds-only)
    ;;
    "$MENU_ALL")
      test_file=$(playground get-examples-list-with-fzf)
    ;;
    *)
      logerror "❌ wrong choice: $res"
      exit 1
    ;;
  esac
}

function cleanup_confluent_cloud_resources () {
  bootstrap_ccloud_environment

  log "🧹 cleanup resources for confluent cloud cluster $CLUSTER_NAME"

  # for row in $(confluent api-key list --output json | jq -r '.[] | @base64'); do
  #     _jq() {
  #     echo ${row} | base64 --decode | jq -r ${1}
  #     }

  #     key=$(echo $(_jq '.key'))
  #     resource_type=$(echo $(_jq '.resource_type'))

  #     if [[ $resource_type = cloud ]] && [[ "$key" != "$CLOUD_API_KEY" ]]
  #     then
  #       log "deleting cloud api key $key"
  #       confluent api-key delete $key --force
  #     fi
  # done

  for row in $(confluent connect cluster list --output json | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 --decode | jq -r ${1}
      }

      id=$(echo $(_jq '.id'))
      name=$(echo $(_jq '.name'))

      if [[ $name = *_${user}* ]]
      then
          log "deleting connector $id ($name)"
          check_if_skip "confluent connect cluster delete $id --force"
      fi
  done

  for row in $(confluent environment list --output json | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 --decode | jq -r ${1}
      }

      id=$(echo $(_jq '.id'))
      name=$(echo $(_jq '.name'))

      if [[ $name = pg-${user}-sa-* ]]
      then
          log "deleting environment $id ($name)"
          check_if_skip "confluent environment delete $id --force"
      fi
  done

  for topic in $(confluent kafka topic list | awk '{if(NR>2) print $1}')
  do
      log "delete topic $topic"
      check_if_skip "confluent kafka topic delete \"$topic\" --force"
  done

  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    for subject in $(curl -u "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL/subjects" | jq -r '.[]')
    do
        log "permanently delete subject $subject"
        check_if_skip "curl --request DELETE -u \"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" \"$SCHEMA_REGISTRY_URL/subjects/$subject\" && curl --request DELETE -u \"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" \"$SCHEMA_REGISTRY_URL/subjects/$subject?permanent=true\""
    done

    for row in $(confluent iam service-account list --output json | jq -r '.[] | @base64'); do
        _jq() {
        echo ${row} | base64 --decode | jq -r ${1}
        }

        description=$(echo $(_jq '.description'))
        id=$(echo $(_jq '.id'))
        name=$(echo $(_jq '.name'))

        log "deleting service-account $id ($description)"
        check_if_skip "confluent iam service-account delete $id --force"
    done
  fi
}

# src/lib/colors.sh
print_in_color() {
  local color="$1"
  shift
  if [[ -z ${NO_COLOR+x} ]]; then
    printf "$color%b\e[0m\n" "$*"
  else
    printf "%b\n" "$*"
  fi
}

red() { print_in_color "\e[31m" "$*"; }
green() { print_in_color "\e[32m" "$*"; }
yellow() { print_in_color "\e[33m" "$*"; }
blue() { print_in_color "\e[34m" "$*"; }
magenta() { print_in_color "\e[35m" "$*"; }
cyan() { print_in_color "\e[36m" "$*"; }
bold() { print_in_color "\e[1m" "$*"; }
underlined() { print_in_color "\e[4m" "$*"; }
red_bold() { print_in_color "\e[1;31m" "$*"; }
green_bold() { print_in_color "\e[1;32m" "$*"; }
yellow_bold() { print_in_color "\e[1;33m" "$*"; }
blue_bold() { print_in_color "\e[1;34m" "$*"; }
magenta_bold() { print_in_color "\e[1;35m" "$*"; }
cyan_bold() { print_in_color "\e[1;36m" "$*"; }
red_underlined() { print_in_color "\e[4;31m" "$*"; }
green_underlined() { print_in_color "\e[4;32m" "$*"; }
yellow_underlined() { print_in_color "\e[4;33m" "$*"; }
blue_underlined() { print_in_color "\e[4;34m" "$*"; }
magenta_underlined() { print_in_color "\e[4;35m" "$*"; }
cyan_underlined() { print_in_color "\e[4;36m" "$*"; }

# src/lib/ini.sh
ini_load() {
  declare -gA ini

  local ini_file="$1"

  local section=""
  local key=""
  local value=""
  local section_regex="^\[(.+)\]"
  local key_regex="^([^ =]+) *= *(.*) *$"
  local comment_regex="^;"

  while IFS= read -r line; do
    if [[ $line =~ $comment_regex ]]; then
      continue
    elif [[ $line =~ $section_regex ]]; then
      section="${BASH_REMATCH[1]}."
    elif [[ $line =~ $key_regex ]]; then
      key="${BASH_REMATCH[1]}"
      value="${BASH_REMATCH[2]}"
      [[ $value == *\$* ]] && eval "value=\"$value\""
      ini["${section}${key}"]="$value"
    fi
  done <"$ini_file"
}

ini_save() {
  declare -gA ini

  local ini_file="$1"

  local current_section=""
  local has_free_keys=false

  rm -f "$ini_file"

  for key in $(ini_keys); do
    [[ $key == *.* ]] && continue
    has_free_keys=true
    value="${ini[$key]}"
    echo "$key = $value" >>"$ini_file"
  done

  [[ "${has_free_keys}" == "true" ]] && echo >>"$ini_file"

  for key in $(ini_keys); do
    [[ $key == *.* ]] || continue
    value="${ini[$key]}"
    IFS="." read -r section_name key_name <<<"$key"

    if [[ "$current_section" != "$section_name" ]]; then
      [[ $current_section ]] && echo >>"$ini_file"
      echo "[$section_name]" >>"$ini_file"
      current_section="$section_name"
    fi

    echo "$key_name = $value" >>"$ini_file"
  done
}

ini_show() {
  declare -gA ini

  for key in $(ini_keys); do
    echo "$key = ${ini[$key]}"
  done
}

ini_keys() {
  declare -gA ini

  local keys=("${!ini[@]}")
  for a in "${keys[@]}"; do echo "$a"; done | sort
}

# src/lib/send_completions.sh
send_completions() {
  echo $'# playground completion                                    -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/dannyben/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_playground_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $'  '
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_playground_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    \'recreate-container\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get-properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'completions\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'bootstrap\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'recreate\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'boot\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'b\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'g\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'r\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help --version -h -v b boot bootstrap completions g get get-properties properties r recreate recreate-container")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'complete -F _playground_completions playground'
  echo $''
  echo $'# ex: filetype=sh'
}

# src/lib/utils_function.sh
function verbose_begin () {
  # Check if set -x is currently active
  if [[ $- = *x* ]]
  then
    # Disable set -x
    set +x
    was_x_set=1
  else
    was_x_set=0
  fi
}

function verbose_end () {
  ret="$?"
  # If set -x was initially active, re-enable it
  if [[ $was_x_set -eq 1 ]]
  then
    set -x
  fi
  return $ret
}

function log() {
  if [ ! -z $PG_LOG_LEVEL ]
  then
    case "${PG_LOG_LEVEL}" in
      WARN|ERROR)
        return
      ;;
    esac
  fi

  verbose_begin
  YELLOW='\033[0;33m'
  NC='\033[0m' # No Color
  echo -e "$YELLOW$(date +"%H:%M:%S") ℹ️ $@$NC"
  verbose_end
}

function logerror() {
  verbose_begin
  RED='\033[0;31m'
  NC='\033[0m' # No Color
  echo -e "$RED$(date +"%H:%M:%S") 🔥 $@$NC"
  verbose_end
}

function logwarn() {
  if [ ! -z $PG_LOG_LEVEL ]
  then
    case "${PG_LOG_LEVEL}" in
      INFO)
        return
      ;;
    esac
  fi
  verbose_begin
  PURPLE='\033[0;35m'
  NC='\033[0m' # No Color
  echo -e "$PURPLE`date +"%H:%M:%S"` ❗ $@$NC"
  verbose_end
}

function urlencode() {
  # https://gist.github.com/cdown/1163649
  # urlencode <string>

  old_lc_collate=$LC_COLLATE
  LC_COLLATE=C

  local length="${#1}"
  for (( i = 0; i < length; i++ )); do
      local c="${1:$i:1}"
      case $c in
          [a-zA-Z0-9.~_-]) printf '%s' "$c" ;;
          *) printf '%%%02X' "'$c" ;;
      esac
  done

  LC_COLLATE=$old_lc_collate
}

function jq() {
  verbose_begin
  if [[ $(type -f jq 2>&1) =~ "not found" ]]
  then
    docker run --quiet --rm -i imega/jq "$@"
  else
    $(type -f jq | awk '{print $3}') "$@"
  fi
  verbose_end
}

function yq() {
  verbose_begin
  if [[ $(type -f yq 2>&1) =~ "not found" ]]
  then
    docker run --quiet  -u0 -v /tmp:/tmp --rm -i mikefarah/yq "$@"
  else
    $(type -f yq | awk '{print $3}') "$@"
  fi
  verbose_end
}

# https://stackoverflow.com/a/24067243
function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function set_kafka_client_tag()
{
    if [[ $TAG_BASE = 7.6.* ]]
    then
      export KAFKA_CLIENT_TAG="3.6.0"
    fi

    if [[ $TAG_BASE = 7.5.* ]]
    then
      export KAFKA_CLIENT_TAG="3.5.0"
    fi

    if [[ $TAG_BASE = 7.4.* ]]
    then
      export KAFKA_CLIENT_TAG="3.4.0"
    fi

    if [[ $TAG_BASE = 7.3.* ]]
    then
      export KAFKA_CLIENT_TAG="3.3.0"
    fi

    if [[ $TAG_BASE = 7.2.* ]]
    then
      export KAFKA_CLIENT_TAG="3.2.0"
    fi

    if [[ $TAG_BASE = 7.1.* ]]
    then
      export KAFKA_CLIENT_TAG="3.1.0"
    fi

    if [[ $TAG_BASE = 7.0.* ]]
    then
      export KAFKA_CLIENT_TAG="3.0.0"
    fi

    if [[ $TAG_BASE = 6.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.8.0"
    fi

    if [[ $TAG_BASE = 6.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.7.0"
    fi

    if [[ $TAG_BASE = 6.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.6.0"
    fi

    if [[ $TAG_BASE = 5.5.* ]]
    then
      export KAFKA_CLIENT_TAG="2.5.0"
    fi

    if [[ $TAG_BASE = 5.4.* ]]
    then
      export KAFKA_CLIENT_TAG="2.4.0"
    fi

    if [[ $TAG_BASE = 5.3.* ]]
    then
      export KAFKA_CLIENT_TAG="2.3.0"
    fi

    if [[ $TAG_BASE = 5.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.2.0"
    fi

    if [[ $TAG_BASE = 5.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.1.0"
    fi

    if [[ $TAG_BASE = 5.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.0.0"
    fi
}

function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D > 0 )) && printf '%d days ' $D
  (( $H > 0 )) && printf '%d hours ' $H
  (( $M > 0 )) && printf '%d minutes ' $M
  (( $D > 0 || $H > 0 || $M > 0 )) && printf 'and '
  printf '%d seconds\n' $S
}

function choosejar()
{
  log "☕ Select the jar to replace:"
  select jar
  do
    # Check the selected menu jar number
    if [ 1 -le "$REPLY" ] && [ "$REPLY" -le $# ];
    then
      break;
    else
      logwarn "Wrong selection: select any number from 1-$#"
    fi
  done
}

function verify_installed()
{
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    logerror "❌ the script requires $cmd. Please install $cmd and run again"
    exit 1
  fi
}

function maybe_create_image()
{
  if [ ! -z "$DOCKER_COMPOSE_FILE_UPDATE_VERSION" ]
  then
    return
  fi
  set +e
  log "🧰 Checking if Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} contains additional tools"
  log "⏳ it can take a while if image is downloaded for the first time"
  docker run --quiet --rm ${CP_CONNECT_IMAGE}:${CONNECT_TAG} type unzip > /dev/null 2>&1
  if [ $? != 0 ]
  then
    if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
    then
      export CONNECT_USER="appuser"
      if [ `uname -m` = "arm64" ]
      then
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm && touch /tmp/done; fi"
      else
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then curl http://mirror.centos.org/centos/8-stream/AppStream/x86_64/os/Packages/tcpdump-4.9.3-1.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm && yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && touch /tmp/done; fi"
      fi
    else
      export CONNECT_USER="root"
      CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then apt-get update && echo bind-utils openssl unzip findutils net-tools nc jq which iptables tree | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/* && touch /tmp/done; fi"
    fi

    tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
    if [ -z "$PG_VERBOSE_MODE" ]
then
    trap 'rm -rf $tmp_dir' EXIT
else
    log "🐛📂 not deleting tmp dir $tmp_dir"
fi
cat << EOF > $tmp_dir/Dockerfile
FROM ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
USER root
RUN ${CONNECT_3RDPARTY_INSTALL}
USER ${CONNECT_USER}
EOF
    log "👷📦 Re-building Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} to include additional tools"
    docker build -t ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $tmp_dir
    rm -rf $tmp_dir
  fi
  set -e
}

function verify_docker_and_memory()
{
  set +e
  docker info > /dev/null 2>&1
  if [[ $? -ne 0 ]]
  then
    logerror "Cannot connect to the Docker daemon. Is the docker daemon running?"
    exit 1
  fi
  set -e
  # Check only with Mac OS
  # if [[ "$OSTYPE" == "darwin"* ]]
  # then
  #   # Verify Docker memory is increased to at least 8GB
  #   DOCKER_MEMORY=$(docker system info | grep Memory | grep -o "[0-9\.]\+")
  #   if (( $(echo "$DOCKER_MEMORY 7.0" | awk '{print ($1 < $2)}') )); then
  #       logerror "WARNING: Did you remember to increase the memory available to Docker to at least 8GB (default is 2GB)? Demo may otherwise not work properly"
  #       exit 1
  #   fi
  # fi
  return 0
}

function verify_confluent_login()
{
  local cmd="$1"
  set +e
  output=$($cmd 2>&1)
  set -e
  if [ "${output}" = "Error: You must login to run that command." ] || [ "${output}" = "Error: Your session has expired. Please login again." ]; then
    logerror "This script requires confluent CLI to be logged in. Please execute 'confluent login' and run again."
    exit 1
  fi
}

function verify_confluent_details()
{
    if [ "$(confluent prompt -f "%E")" = "(none)" ]
    then
        logerror "confluent command is badly configured: environment is not set"
        logerror "Example: confluent kafka environment list"
        logerror "then: confluent kafka environment use <environment id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%K")" = "(none)" ]
    then
        logerror "confluent command is badly configured: cluster is not set"
        logerror "Example: confluent kafka cluster list"
        logerror "then: confluent kafka cluster use <cluster id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%a")" = "(none)" ]
    then
        logerror "confluent command is badly configured: api key is not set"
        logerror "Example: confluent api-key store <api key> <password>"
        logerror "then: confluent api-key use <api key>"
        exit 1
    fi

    CCLOUD_PROMPT_FMT='You will be using Confluent Cloud cluster with user={{fgcolor "green" "%u"}}, environment={{fgcolor "red" "%E"}}, cluster={{fgcolor "cyan" "%K"}}, api key={{fgcolor "yellow" "%a"}}'
    confluent prompt -f "$CCLOUD_PROMPT_FMT"
}

function check_if_continue()
{
  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
      # running with github actions, continue
      return
  fi
  read -p "Continue (y/n)?" choice
  case "$choice" in
  y|Y ) ;;
  n|N ) exit 1;;
  * ) logerror "invalid response <$choice>!";exit 1;;
  esac
}

function check_if_skip() {

  if [[ -n "$force" ]] || [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    eval "$1"
  else
    read -p "Do you want to skip this command? (y/n) " reply

    if [[ $reply != 'y' ]]

    then
      eval "$1"
    else
      log "Skipping command..."
    fi
  fi
}

function create_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? == 0 ]]; then
    log "Create topic $topic"
    log "confluent kafka topic create $topic --partitions 1"
    confluent kafka topic create "$topic" --partitions 1 || true
  else
    log "Topic $topic already exists"
  fi
}

function delete_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? != 0 ]]; then
    log "Delete topic $topic"
    log "confluent kafka topic delete $topic --force"
    confluent kafka topic delete "$topic" --force || true
  else
    log "Topic $topic does not exist"
  fi
}

function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function get_docker_compose_version() {
  docker compose version | grep "^Docker Compose version" | cut -d' ' -f3 | cut -d',' -f1
}

function check_docker_compose_version() {
  REQUIRED_DOCKER_COMPOSE_VER=${1:-"1.28.0"}
  DOCKER_COMPOSE_VER=$(get_docker_compose_version)

  if version_gt $REQUIRED_DOCKER_COMPOSE_VER $DOCKER_COMPOSE_VER; then
    logerror "docker compose version ${REQUIRED_DOCKER_COMPOSE_VER} or greater is required. Current reported version: ${DOCKER_COMPOSE_VER}"
    exit 1
  fi
}

function get_bash_version() {
  bash_major_version=$(bash --version | head -n1 | awk '{print $4}')
  major_version="${bash_major_version%%.*}"
  echo "$major_version"
}

function check_bash_version() {
  REQUIRED_BASH_VER=${1:-"4"}
  BASH_VER=$(get_bash_version)

  if version_gt $REQUIRED_BASH_VER $BASH_VER; then
    logerror "bash version ${REQUIRED_BASH_VER} or greater is required. Current reported version: ${BASH_VER}"
    exit 1
  fi
}

function check_playground_version() {
  set +e
  X=3
  git fetch
  latest_commit_date=$(git log -1 --format=%cd --date=short)
  remote_commit_date=$(git log -1 --format=%cd --date=short origin/master)

  if [[ "$OSTYPE" == "darwin"* ]]
  then
    latest_commit_date_seconds=$(date -j -f "%Y-%m-%d" "$latest_commit_date" +%s)
    remote_commit_date_seconds=$(date -j -f "%Y-%m-%d" "$remote_commit_date" +%s)
  else
    latest_commit_date_seconds=$(date -d "$latest_commit_date" +%s)
    remote_commit_date_seconds=$(date -d "$remote_commit_date" +%s)
  fi

  difference=$(( (remote_commit_date_seconds - latest_commit_date_seconds) / (60*60*24) ))

  if [ $difference -gt $X ]
  then
      logwarn "🥶 The current repo version is older than $X days ($difference days), please refresh your version using git pull !"
      check_if_continue
  fi
  set -e
}

function set_profiles() {
  # https://docs.docker.com/compose/profiles/
  profile_control_center_command=""
  if [ -z "$ENABLE_CONTROL_CENTER" ]
  then
    log "🛑 control-center is disabled"
    playground state del flags.ENABLE_CONTROL_CENTER
  else
    log "💠 control-center is enabled"
    log "Use http://localhost:9021 to login"
    profile_control_center_command="--profile control-center"
    playground state set flags.ENABLE_CONTROL_CENTER 1
  fi

  profile_ksqldb_command=""
  if [ -z "$ENABLE_KSQLDB" ]
  then
    log "🛑 ksqldb is disabled"
    playground state del flags.ENABLE_KSQLDB
  else
    log "🚀 ksqldb is enabled"
    log "🔧 You can use ksqlDB with CLI using:"
    log "docker exec -i ksqldb-cli ksql http://ksqldb-server:8088"
    profile_ksqldb_command="--profile ksqldb"
    playground state set flags.ENABLE_KSQLDB 1
  fi

  profile_rest_proxy_command=""
  if [ -z "$ENABLE_RESTPROXY" ]
  then
    log "🛑 REST Proxy is disabled"
    playground state del flags.ENABLE_RESTPROXY
  else
    log "📲 REST Proxy is enabled"
    profile_rest_proxy_command="--profile rest-proxy"
    playground state set flags.ENABLE_RESTPROXY 1
  fi

  # defined grafana variable and when profile is included/excluded
  profile_grafana_command=""
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "🛑 Grafana is disabled"
    playground state del flags.ENABLE_JMX_GRAFANA
  else
    log "📊 Grafana is enabled"
    profile_grafana_command="--profile grafana"
    playground state set flags.ENABLE_JMX_GRAFANA 1
  fi
  profile_kcat_command=""
  if [ -z "$ENABLE_KCAT" ]
  then
    log "🛑 kcat is disabled"
    playground state del flags.ENABLE_KCAT
  else
    log "🧰 kcat is enabled"
    profile_kcat_command="--profile kcat"
    playground state set flags.ENABLE_KCAT 1
  fi
  profile_conduktor_command=""
  if [ -z "$ENABLE_CONDUKTOR" ]
  then
    log "🛑 conduktor is disabled"
    playground state del flags.ENABLE_CONDUKTOR
  else
    log "🐺 conduktor is enabled"
    log "Use http://localhost:8080/console (admin/admin) to login"
    profile_conduktor_command="--profile conduktor"
    playground state set flags.ENABLE_CONDUKTOR 1
  fi
  profile_sql_datagen_command=""
  if [ ! -z "$SQL_DATAGEN" ]
  then
    profile_sql_datagen_command="--profile sql_datagen"
    playground state set flags.SQL_DATAGEN 1
  else
    playground state del flags.SQL_DATAGEN
  fi

  #define kafka_nodes variable and when profile is included/excluded
  profile_kafka_nodes_command=""
  if [ -z "$ENABLE_KAFKA_NODES" ]
  then
    profile_kafka_nodes_command=""
    playground state del flags.ENABLE_KAFKA_NODES
  else
    log "3️⃣  Multi broker nodes enabled"
    profile_kafka_nodes_command="--profile kafka_nodes"
    playground state set flags.ENABLE_KAFKA_NODES 1
  fi

  # defined 3 Connect variable and when profile is included/excluded
  profile_connect_nodes_command=""
  if [ -z "$ENABLE_CONNECT_NODES" ]
  then
    playground state del flags.ENABLE_CONNECT_NODES
  elif [ ${nb_connect_services} -gt 1 ]
  then
    log "🥉 Multiple Connect nodes mode is enabled, connect2 and connect 3 containers will be started"
    profile_connect_nodes_command="--profile connect_nodes"
    export CONNECT_NODES_PROFILES="connect_nodes"
    playground state set flags.ENABLE_CONNECT_NODES 1
  else
    if [ ! -f "${DOCKER_COMPOSE_FILE_OVERRIDE}" ]
    then
      log "🥉 Multiple connect nodes mode is enabled, connect2 and connect 3 containers will be started"
      profile_connect_nodes_command="--profile connect_nodes"
      playground state set flags.ENABLE_CONNECT_NODES 1
    else
      logerror "🛑 Could not find connect2 and connect3 in ${DOCKER_COMPOSE_FILE_OVERRIDE}. Update the yaml files to contain the connect2 && connect3 in ${DOCKER_COMPOSE_FILE_OVERRIDE}"
      exit 1
    fi
  fi
}

function get_confluent_version() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function get_ansible_version() {
  ansible --version | grep "core" | cut -d'[' -f2 | cut -d']' -f1 | cut -d' ' -f 2
}

function check_confluent_version() {
  REQUIRED_CONFLUENT_VER=${1:-"3.0.0"}
  CONFLUENT_VER=$(get_confluent_version)

  if version_gt $REQUIRED_CONFLUENT_VER $CONFLUENT_VER; then
    log "confluent version ${REQUIRED_CONFLUENT_VER} or greater is required.  Current reported version: ${CONFLUENT_VER}"
    echo 'To update run: confluent update'
    exit 1
  fi
}

function container_to_ip() {
    name=$1
    echo $(docker exec $name hostname -I)
}

function block_host() {
    name=$1
    shift 1

    # https://serverfault.com/a/906499
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 root handle 1: prio" 2>&1

    for ip in $@; do
        docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $ip flowid 1:1" 2>&1
    done

    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:1 handle 10: netem loss 100%" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:2 handle 20: sfq" 2>&1
}

function remove_partition() {
    for name in $@; do
        docker exec --privileged -t $name bash -c "tc qdisc del dev eth0 root"
    done
}

function aws() {

    if [ -z "$AWS_ACCESS_KEY_ID" ] && [ -z "$AWS_SECRET_ACCESS_KEY" ] && [ ! -f $HOME/.aws/credentials ]
    then
      logerror 'ERROR: Neither AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY or $HOME/.aws/credentials are set. AWS credentials must be set !'
      if [ -z "$AWS_ACCESS_KEY_ID" ]
      then
        log 'AWS_ACCESS_KEY_ID environment variable is not set.'
      fi
      if [ -z "$AWS_SECRET_ACCESS_KEY" ]
      then
        log 'AWS_SECRET_ACCESS_KEY environment variable is not set.'
      fi
      if [ ! -f $HOME/.aws/credentials ]
      then
        log '$HOME/.aws/credentials does not exist.'
      fi
      return 1
    fi

    if [ ! -f $HOME/.aws/config ]
    then
      aws_tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
cat << EOF > $aws_tmp_dir/config
[default]
region = $AWS_REGION
EOF
    fi

    if [ ! -z "$AWS_ACCESS_KEY_ID" ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
    then
      AWS_ACCESS_KEY_ID=$(echo "$AWS_ACCESS_KEY_ID"| sed 's/[[:blank:]]//g')
      AWS_SECRET_ACCESS_KEY=$(echo "$AWS_SECRET_ACCESS_KEY"| sed 's/[[:blank:]]//g')
      AWS_SESSION_TOKEN=$(echo "$AWS_SESSION_TOKEN"| sed 's/[[:blank:]]//g')
      # log "💭 Using environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
      if [ -f $aws_tmp_dir/config ]
      then
        docker run --quiet --rm -iv $aws_tmp_dir/config:/root/.aws/config -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
        rm -rf $aws_tmp_dir
      else
        docker run --quiet --rm -iv $HOME/.aws/config:/root/.aws/config -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      fi
    else
      if [ ! -f $HOME/.aws/credentials ]
      then
        logerror '$HOME/.aws/credentials does not exist.'
      else
        # log "💭 AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are set based on $HOME/.aws/credentials"
        docker run --quiet --rm -iv $HOME/.aws:/root/.aws -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      fi
    fi
}

function timeout() {
  verbose_begin
  if [[ $(type -f timeout 2>&1) =~ "not found" ]]; then
    # ignore
    shift
    eval "$@"
  else
    $(type -f timeout | awk '{print $3}') "$@"
  fi
  verbose_end
}

function get_connect_image() {
  set +e
  CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  set -e
  if [ "$CONNECT_TAG" == "" ]
  then
    CONNECT_TAG=$(grep "export TAG" $root_folder/scripts/utils.sh | head -1 | cut -d "=" -f 2 | cut -d " " -f 1)

    if [ "$CONNECT_TAG" == "" ]
    then
      logerror "Error while getting default TAG in get_connect_image()"
      exit 1
    fi
  fi

  if version_gt $CONNECT_TAG 5.2.99
  then
    CP_CONNECT_IMAGE=confluentinc/cp-server-connect-base
  else
    CP_CONNECT_IMAGE=confluentinc/cp-kafka-connect-base
  fi
}

function az() {
  docker run --quiet --rm -v /tmp:/tmp -v $HOME/.azure:/home/az/.azure -e HOME=/home/az --rm -i mcr.microsoft.com/azure-cli az "$@"
}

function display_docker_container_error_log() {
  set +e
  logerror "####################################################"
  logerror "🐳 docker ps"
  docker ps
  logerror "####################################################"
  for container in $(docker ps  --format="{{.Names}}")
  do
      logerror "####################################################"
      logerror "$container logs"
      if [[ "$container" == "connect" ]] || [[ "$container" == "sap" ]]
      then
          # always show all logs for connect
          docker container logs --tail=500 $container 2>&1 | grep -v "was supplied but isn't a known config"
      else
          docker container logs $container 2>&1 | egrep "ERROR|FATAL"
      fi
      logwarn "####################################################"
  done
}

function retry() {
  local n=1
  local max_retriable=3
  local max_default_retry=1
  while true; do
    "$@"
    ret=$?
    if [ $ret -eq 0 ]
    then
      return 0
    elif [ $ret -eq 111 ] # skipped
    then
      return 111
    elif [ $ret -eq 107 ] # known issue https://github.com/vdesabou/kafka-docker-playground/issues/907
    then
      return 107
    else
      test_file=$(echo "$@" | awk '{ print $4}')
      script=$(basename $test_file)
      # check for retriable scripts in scripts/tests-retriable.txt
      grep "$script" ${DIR}/tests-retriable.txt > /dev/null
      if [ $? = 0 ]
      then
        if [[ $n -lt $max_retriable ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🧟‍♂️ The test $script (retriable) has failed. Retrying (attempt $n/$max_retriable)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (retriable) has failed after $n attempts."
          return 1
        fi
      else
        if [[ $n -lt $max_default_retry ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🎰 The test $script (default_retry) has failed. Retrying (attempt $n/$max_default_retry)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (default_retry) has failed after $n attempts."
          return 1
        fi
      fi
    fi
  done
}

retrycmd() {
    local -r -i max_attempts="$1"; shift
    local -r -i sleep_interval="$1"; shift
    local -r cmd="$@"
    local -i attempt_num=1

    until $cmd
    do
        if (( attempt_num == max_attempts ))
        then
            display_docker_container_error_log
            logerror "Failed after $attempt_num attempts. Please troubleshoot and run again."
            return 1
        else
            printf "."
            ((attempt_num++))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

# for RBAC, taken from cp-demo
function host_check_kafka_cluster_registered() {
  KAFKA_CLUSTER_ID=$(docker container exec zookeeper zookeeper-shell zookeeper:2181 get /cluster/id 2> /dev/null | grep \"version\" | jq -r .id)
  if [ -z "$KAFKA_CLUSTER_ID" ]; then
    return 1
  fi
  echo $KAFKA_CLUSTER_ID
  return 0
}

# for RBAC, taken from cp-demo
function host_check_mds_up() {
  docker container logs broker > /tmp/out.txt 2>&1
  FOUND=$(cat /tmp/out.txt | grep "Started NetworkTrafficServerConnector")
  if [ -z "$FOUND" ]; then
    return 1
  fi
  return 0
}

# for RBAC, taken from cp-demo
function mds_login() {
  MDS_URL=$1
  SUPER_USER=$2
  SUPER_USER_PASSWORD=$3

  # Log into MDS
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi
  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $MDS_URL
    expect "Username: "
    send "${SUPER_USER}\r";
    expect "Password: "
    send "${SUPER_USER_PASSWORD}\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into MDS.  Please check all parameters and run again"
    exit 1
  fi
}

# https://raw.githubusercontent.com/zlabjp/kubernetes-scripts/master/wait-until-pods-ready

function __is_pod_ready() {
  [[ "$(kubectl get po "$1" -n $namespace -o 'jsonpath={.status.conditions[?(@.type=="Ready")].status}')" == 'True' ]]
}

function __pods_ready() {
  local pod

  [[ "$#" == 0 ]] && return 0

  for pod in $pods; do
    __is_pod_ready "$pod" || return 1
  done

  return 0
}

function wait-until-pods-ready() {
  local period interval i pods

  if [[ $# != 3 ]]; then
    echo "Usage: wait-until-pods-ready PERIOD INTERVAL NAMESPACE" >&2
    echo "" >&2
    echo "This script waits for all pods to be ready in the current namespace." >&2

    return 1
  fi

  period="$1"
  interval="$2"
  namespace="$3"

  sleep 10

  for ((i=0; i<$period; i+=$interval)); do
    pods="$(kubectl get po -n $namespace -o 'jsonpath={.items[*].metadata.name}')"
    if __pods_ready $pods; then
      return 0
    fi

    echo "Waiting for pods to be ready..."
    sleep "$interval"
  done

  echo "Waited for $period seconds, but all pods are not ready yet."
  return 1
}

function wait_for_datagen_connector_to_inject_data () {
  sleep 3
  connector_name="$1"
  datagen_tasks="$2"
  prefix_cmd="$3"
  set +e
  # wait for all tasks to be FAILED with org.apache.kafka.connect.errors.ConnectException: Stopping connector: generated the configured xxx number of messages
  MAX_WAIT=3600
  CUR_WAIT=0
  log "⌛ Waiting up to $MAX_WAIT seconds for connector $connector_name to finish injecting requested load"
  $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
  while [[ ! $(cat /tmp/out.txt) =~ "${datagen_tasks}" ]]; do
    sleep 5
    $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
    CUR_WAIT=$(( CUR_WAIT+10 ))
    if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
      echo -e "\nERROR: Please troubleshoot'.\n"
      $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq
      exit 1
    fi
  done
  log "Connector $connector_name has finish injecting requested load"
  set -e
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
# remove specified host from /etc/hosts
function removehost() {
    if [ ! -z "$1" ]
    then
        HOSTNAME=$1

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
        then
            echo "$HOSTNAME Found in your /etc/hosts, Removing now...";
            sudo sed -i".bak" "/$HOSTNAME/d" /etc/hosts
        else
            echo "$HOSTNAME was not found in your /etc/hosts";
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  removehost domain"
    fi
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
#add new ip host pair to /etc/hosts
function addhost() {
    if [ $# -eq 2 ]
    then
        IP=$1
        HOSTNAME=$2

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
            then
                echo "$HOSTNAME already exists:";
                echo $(grep $HOSTNAME /etc/hosts);
            else
                echo "Adding $HOSTNAME to your /etc/hosts";
                printf "%s\t%s\n" "$IP" "$HOSTNAME" | sudo tee -a /etc/hosts > /dev/null;

                if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
                    then
                        echo "$HOSTNAME was added succesfully:";
                        echo $(grep $HOSTNAME /etc/hosts);
                    else
                        echo "Failed to Add $HOSTNAME, Try again!";
                fi
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  addhost ip domain"
    fi
}

function stop_all() {
  playground stop
}

function wait_container_ready() {

  CONNECT_CONTAINER=${1:-"connect"}
  CONTROL_CENTER_CONTAINER=${1:-"control-center"}
  MAX_WAIT=300

  if [ ! -z $WAIT_FOR_CONTROL_CENTER ]
  then
    log "⌛ Waiting up to $MAX_WAIT seconds for ${CONTROL_CENTER_CONTAINER} to start"
    playground --output-level WARN container logs --container $CONTROL_CENTER_CONTAINER --wait-for-log "Started NetworkTrafficServerConnector" --max-wait $MAX_WAIT
  else
    log "⌛ Waiting up to $MAX_WAIT seconds for ${CONNECT_CONTAINER} to start"
    playground --output-level WARN container logs --container $CONNECT_CONTAINER --wait-for-log "Finished starting connectors and tasks" --max-wait $MAX_WAIT
  fi
  # Verify Docker containers started
  if [[ $(docker container ps) =~ "Exit 137" ]]
  then
    logerror "at least one Docker container did not start properly, see <docker container ps>"
    exit 1
  fi

  log "🚦 containers have started!"
}

function display_jmx_info() {
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "📊 JMX metrics are available locally on those ports:"
  else
    log "🛡️ Prometheus is reachable at http://127.0.0.1:9090"
    log "📛 Pyroscope is reachable at http://127.0.0.1:4040"
    log "📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password) or JMX metrics are available locally on those ports:"
  fi
  log "    - zookeeper       : 9999"
  log "    - broker          : 10000"
  log "    - schema-registry : 10001"
  log "    - connect         : 10002"

  if [ ! -z "$ENABLE_KSQLDB" ]
  then
    log "    - ksqldb-server   : 10003"
  fi
}
function get_jmx_metrics() {
  JMXTERM_VERSION="1.0.2"
  JMXTERM_UBER_JAR="/tmp/jmxterm-$JMXTERM_VERSION-uber.jar"
  if [ ! -f $JMXTERM_UBER_JAR ]
  then
    curl -L https://github.com/jiaqi/jmxterm/releases/download/v$JMXTERM_VERSION/jmxterm-$JMXTERM_VERSION-uber.jar -o $JMXTERM_UBER_JAR -s
  fi

  rm -f /tmp/commands
  rm -f /tmp/jmx_metrics.log

  container="$1"
  domains="$2"
  open="$3"
  if [ "$domains" = "" ]
  then
    # non existing domain: all domains will be in output !
    logwarn "You did not specify a list of domains, all domains will be exported!"
    domains="ALL"
  fi

  case "$container" in
  zookeeper )
    port=9999
  ;;
  broker )
    port=10000
  ;;
  schema-registry )
    port=10001
  ;;
  connect )
    port=10002
  ;;
  connect2 )
    port=10022
  ;;
  connect3 )
    port=10032
  ;;
  n|N ) ;;
  * ) logerror "invalid container $container! it should be one of zookeeper, broker, schema-registry, connect, connect2 or connect3";exit 1;;
  esac

  docker cp $JMXTERM_UBER_JAR $container:$JMXTERM_UBER_JAR
  if [ "$domains" = "ALL" ]
  then

log "This is the list of domains for container $container"
docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent << EOF
domains
exit
EOF
  fi

for domain in `echo $domains`
do
docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent > /tmp/beans.log << EOF
domain $domain
beans
exit
EOF
  while read line; do echo "get *"  -b $line; done < /tmp/beans.log >> /tmp/commands

  if [[ -n "$open" ]]
  then
    echo "####### domain $domain ########" >> /tmp/jmx_metrics.log
    docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands >> /tmp/jmx_metrics.log 2>&1
  else
    echo "####### domain $domain ########"
    docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands 2>&1
  fi
done

  if [[ -n "$open" ]]
  then
    editor=$(playground config get editor)
    if [ "$editor" != "" ]
    then
      log "📖 Opening /tmp/jmx_metrics.log using configured editor $editor"
      $editor /tmp/jmx_metrics.log
    else
        if [[ $(type code 2>&1) =~ "not found" ]]
        then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
            exit 1
        else
            log "📖 Opening /tmp/jmx_metrics.log with code (default) - you can change editor by using playground config editor <editor>"
            code /tmp/jmx_metrics.log
        fi
    fi
  fi
}

# https://www.linuxjournal.com/content/validating-ip-address-bash-script
function valid_ip()
{
    local  ip=$1
    local  stat=1

    if [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        OIFS=$IFS
        IFS='.'
        ip=($ip)
        IFS=$OIFS
        [[ ${ip[0]} -le 255 && ${ip[1]} -le 255 \
            && ${ip[2]} -le 255 && ${ip[3]} -le 255 ]]
        stat=$?
    fi
    return $stat
}

function container_to_name() {
    container=$1
    echo "${PWD##*/}_${container}_1"
}

function container_to_ip() {
    if [ $# -lt 1 ]; then
        echo "Usage: container_to_ip container"
    fi
    echo $(docker inspect $1 -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
}

function clear_traffic_control() {
    if [ $# -lt 1 ]; then
        echo "Usage: clear_traffic_control src_container"
    fi

    src_container=$1

    echo "Removing all traffic control settings on $src_container"

    # Delete the entry from the tc table so the changes made to tc do not persist
    docker exec --privileged -u0 -t $src_container tc qdisc del dev eth0 root
}

function get_latency() {
    if [ $# -lt 2 ]; then
        echo "Usage: get_latency src_container dst_container"
    fi
    src_container=$1
    dst_container=$2
    docker exec --privileged -u0 -t $src_container ping $dst_container -c 4 -W 80 | tail -1 | awk -F '/' '{print $5}'
}

# https://serverfault.com/a/906499
function add_latency() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_latency src_container dst_container (or ip address) latency"
        echo "Example: add_latency container-1 container-2 100ms"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    latency=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $latency latency from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have delay applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem delay $latency

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_corruption() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_corruption src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_corruption container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    corruption=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $corruption corruption from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have corrupt applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem corrupt $corruption

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_loss() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_loss src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_loss container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    loss=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $loss loss from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have loss applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem loss $loss

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function get_3rdparty_file () {
  file="$1"

  if [ -f $file ]
  then
    log "$file already present, skipping"
    return
  fi

  folder="3rdparty"
  if [[ "$file" == *repro* ]]
  then
    folder="repro-files"
  fi
  set +e
  aws s3 ls s3://kafka-docker-playground/$folder/$file > /dev/null 2>&1
  if [ $? -eq 0 ]
  then
      log "Downloading <s3://kafka-docker-playground/$folder/$file> from S3 bucket"
      if [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/$folder/$file" .
      else
        aws s3 cp "s3://kafka-docker-playground/$folder/$file" .
      fi
      if [ $? -eq 0 ]; then
        log "📄 <s3://kafka-docker-playground/$folder/$file> was downloaded from S3 bucket"
      fi
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # workaround for issue on linux, see https://github.com/vdesabou/kafka-docker-playground/issues/851#issuecomment-821151962
          chmod a+rw $file
      else
          # on CI, docker is run as runneradmin user, need to use sudo
          sudo chmod a+rw $file
      fi
  fi
  set -e
}

function remove_cdb_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi

  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  if [ `uname -m` = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "🧹 Removing Oracle image $ORACLE_IMAGE"
    docker image rm $ORACLE_IMAGE
  fi
}

function create_or_get_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      if [ `uname -m` = "arm64" ]
      then
          ZIP_FILE="LINUX.ARM64_1919000_db_home.zip"
      else
          ZIP_FILE="LINUX.X64_193000_db_home.zip"
      fi
      ORACLE_VERSION="19.3.0-ee"
  fi
  # used for docker-images repo
  DOCKERFILE_VERSION=$(echo "$ORACLE_VERSION" | cut -d "-" -f 1)

  # https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance/samples/prebuiltdb
  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')

  if [ `uname -m` = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi
  TEMP_CONTAINER="oracle-build-$ORACLE_VERSION-$(basename $SETUP_FOLDER)"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    set +e
    log "attempting to get the Oracle prebuilt docker image from Confluent S3 bucket (only works for Confluent employees)..."
    log "command is <aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar>"
    aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar
    if [ $? -eq 0 ]
    then
        log "Downloading prebuilt image <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> from S3 bucket"
        if [ ! -z "$GITHUB_RUN_NUMBER" ]
        then
          aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" .
        else
          aws s3 cp "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" .
        fi
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> was downloaded from S3 bucket"
          docker load -i $ORACLE_IMAGE.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "🧹 Removing prebuilt image $ORACLE_IMAGE.tar"
            rm -f $ORACLE_IMAGE.tar
          else
            log "🧹 Removing prebuilt image $ORACLE_IMAGE.tar with sudo"
            sudo rm -f $ORACLE_IMAGE.tar
          fi
        fi
    else
      logwarn "If you're a Confluent employee, please check this link https://confluent.slack.com/archives/C0116NM415F/p1636391410032900 and also here https://confluent.slack.com/archives/C0116NM415F/p1636389483030900"
      logwarn "re-run with <playground -v (or --vvv) run> to troubleshoot"
    fi
    set -e
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
    return
  fi

  BASE_ORACLE_IMAGE="oracle/database:$ORACLE_VERSION"

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> from S3 bucket"
        if [ ! -z "$GITHUB_RUN_NUMBER" ]
        then
          aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" .
        else
          aws s3 cp "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" .
        fi
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> was downloaded from S3 bucket"
          docker load -i oracle_database_$ORACLE_VERSION.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $BASE_ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "🧹 Removing $ORACLE_IMAGE.tar"
            rm -f oracle_database_$ORACLE_VERSION.tar
          else
            log "🧹 Removing $ORACLE_IMAGE.tar with sudo"
            sudo rm -f oracle_database_$ORACLE_VERSION.tar
          fi
        fi
    fi
    set -e
  fi

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
      if [ ! -f ${ZIP_FILE} ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/${ZIP_FILE} > /dev/null 2>&1
          if [ $? -eq 0 ]
          then
              log "Downloading <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> from S3 bucket"

              if [ ! -z "$GITHUB_RUN_NUMBER" ]
              then
                aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              else
                aws s3 cp "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              fi
              if [ $? -eq 0 ]
              then
                log "📄 <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> was downloaded from S3 bucket"
              fi
          fi
          set -e
      fi
      if [ ! -f ${ZIP_FILE} ]
      then
          logerror "ERROR: ${ZIP_FILE} is missing. It must be downloaded manually in order to acknowledge user agreement"
          exit 1
      fi
      log "👷 Building $BASE_ORACLE_IMAGE docker image..it can take a while...(more than 15 minutes!)"
      OLDDIR=$PWD
      rm -rf docker-images
      git clone https://github.com/oracle/docker-images.git

      mv ${ZIP_FILE} docker-images/OracleDatabase/SingleInstance/dockerfiles/$DOCKERFILE_VERSION/${ZIP_FILE}
      cd docker-images/OracleDatabase/SingleInstance/dockerfiles
      ./buildContainerImage.sh -v $DOCKERFILE_VERSION -e
      rm -rf docker-images
      cd ${OLDDIR}
  fi

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
      log "🏭 Prebuilt $ORACLE_IMAGE docker image does not exist, building it now..it can take a while..."
      log "🚦 Startup a container ${TEMP_CONTAINER} with setup folder $SETUP_FOLDER and create the database"
      cd $SETUP_FOLDER
      docker run -d -e ORACLE_PWD=Admin123 -v $PWD:/opt/oracle/scripts/setup --name ${TEMP_CONTAINER} ${BASE_ORACLE_IMAGE}
      cd -

      MAX_WAIT=2500
      CUR_WAIT=0
      log "⌛ Waiting up to $MAX_WAIT seconds for ${TEMP_CONTAINER} to start"
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      while [[ ! $(cat /tmp/out.txt) =~ "DATABASE IS READY TO USE" ]]; do
      sleep 10
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      CUR_WAIT=$(( CUR_WAIT+10 ))
      if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
            logerror "ERROR: The logs in ${TEMP_CONTAINER} container do not show 'DATABASE IS READY TO USE' after $MAX_WAIT seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'.\n"
            exit 1
      fi
      done
      log "${TEMP_CONTAINER} has started! Check logs in /tmp/${TEMP_CONTAINER}.log"
      docker container logs ${TEMP_CONTAINER} > /tmp/${TEMP_CONTAINER}.log 2>&1
      log "🛑 Stop the running container"
      docker stop -t 600 ${TEMP_CONTAINER}
      log "🛠 Create the image with the prebuilt database"
      docker commit -m "Image with prebuilt database" ${TEMP_CONTAINER} ${ORACLE_IMAGE}
      log "🧹 Clean up ${TEMP_CONTAINER}"
      docker rm ${TEMP_CONTAINER}

      if [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
          if [ $? -ne 0 ]
          then
              log "📄 Uploading </tmp/$ORACLE_IMAGE.tar> to S3 bucket"
              docker save -o /tmp/$ORACLE_IMAGE.tar $ORACLE_IMAGE
              aws s3 cp --only-show-errors "/tmp/$ORACLE_IMAGE.tar" "s3://kafka-docker-playground/3rdparty/"
              if [ $? -eq 0 ]; then
                    log "📄 </tmp/$ORACLE_IMAGE.tar> was uploaded to S3 bucket"
              fi
          fi
          set -e
      fi
  fi

  log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
}

function print_code_pass() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_PASS}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"
}
function print_code_error() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_ERROR}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"
}

function exit_with_error()
{
  local USAGE="\nUsage: exit_with_error -c code -n name -m message -l line_number\n"
  local NAME=""
  local MESSAGE=""
  local CODE=$UNSPECIFIED_ERROR
  local LINE=
  OPTIND=1
  while getopts ":n:m:c:l:" opt; do
    case ${opt} in
      n ) NAME=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
      c ) CODE=${OPTARG};;
      l ) LINE=${OPTARG};;
      ? ) printf $USAGE;return 1;;
    esac
  done
  shift $((OPTIND-1))
  print_error "error ${CODE} occurred in ${NAME} at line $LINE"
	printf "\t${MESSAGE}\n"
  exit $CODE
}

function get_kafka_docker_playground_dir () {
  DIR_UTILS="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  KAFKA_DOCKER_PLAYGROUND_DIR="$(echo $DIR_UTILS | sed 's|\(.*kafka-docker-playground\).*|\1|')"
}

function maybe_delete_ccloud_environment () {
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #
    # CLUSTER_NAME is not set
    #
    log "🧹❌ Confluent Cloud cluster will be deleted..."
    verify_installed "confluent"
    check_confluent_version 2.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"

    export QUIET=true

    if [ ! -z "$ENVIRONMENT" ]
    then
      log "🌐 ENVIRONMENT $ENVIRONMENT is set, it will not be deleted"
      export PRESERVE_ENVIRONMENT=true
    else
      export PRESERVE_ENVIRONMENT=false
    fi
    SERVICE_ACCOUNT_ID=$(ccloud:get_service_account_from_current_cluster_name)
    set +e
    ccloud::destroy_ccloud_stack $SERVICE_ACCOUNT_ID
    set -e
  fi
}

function bootstrap_ccloud_environment () {

  DIR_UTILS="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

  if [ -z "$GITHUB_RUN_NUMBER" ] && [ -z "$CLOUDFORMATION" ]
  then
    # not running with CI
    verify_installed "confluent"
    check_confluent_version 3.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"
  else
    if [ ! -f /usr/local/bin/confluent ]
    then
      log "🚚 installing confluent CLI"
      curl -L --http1.1 https://cnfl.io/cli | sudo sh -s -- -b /usr/local/bin
    fi
    export PATH=$PATH:/usr/local/bin
    log "⛺ log in to Confluent Cloud"
    confluent login --save
  fi

  suggest_use_previous_example_ccloud=1
  test_file=$(playground state get run.test_file)

  if [ -f "$test_file" ]
  then
    if [[ $test_file == *"fm-databricks-delta-lake-sink"* ]]
    then
      if [ ! -z "$AWS_DATABRICKS_CLUSTER_NAME" ]
      then
        log "AWS_DATABRICKS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_DATABRICKS_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AWS_DATABRICKS_CLUSTER_NAME
        export CLUSTER_REGION=$AWS_DATABRICKS_CLUSTER_REGION
        export CLUSTER_CLOUD=$AWS_DATABRICKS_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AWS_DATABRICKS_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-aws"* ]]
    then
      if [ ! -z "$AWS_CLUSTER_NAME" ]
      then
        log "🤖 AWS Fully managed example and AWS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AWS_CLUSTER_NAME
        export CLUSTER_REGION=$AWS_CLUSTER_REGION
        export CLUSTER_CLOUD=$AWS_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AWS_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-gcp"* ]]
    then
      if [ ! -z "$GCP_CLUSTER_NAME" ]
      then
        log "🤖 GCP Fully managed example and GCP_CLUSTER_NAME environment variable is set, forcing the cluster $GCP_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$GCP_CLUSTER_NAME
        export CLUSTER_REGION=$GCP_CLUSTER_REGION
        export CLUSTER_CLOUD=$GCP_CLUSTER_CLOUD
        export CLUSTER_CREDS=$GCP_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-azure"* ]]
    then
      if [ ! -z "$AZURE_CLUSTER_NAME" ]
      then
        log "🤖 Azure Fully managed example and AZURE_CLUSTER_NAME environment variable is set, forcing the cluster $AZURE_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AZURE_CLUSTER_NAME
        export CLUSTER_REGION=$AZURE_CLUSTER_REGION
        export CLUSTER_CLOUD=$AZURE_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AZURE_CLUSTER_CREDS
      fi
    fi
  fi

  for item in {ENVIRONMENT,CLUSTER_NAME,CLUSTER_CLOUD,CLUSTER_REGION,CLUSTER_CREDS}
  do
      i=$(playground state get "ccloud.${item}")
      if [ "$i" == "" ]
      then
        # at least one mandatory field is missing
        suggest_use_previous_example_ccloud=0
        break
      fi
  done

  if [ ! -z "$CLUSTER_NAME" ]
  then
    if [ "$(playground state get "ccloud.CLUSTER_NAME")" == "$CLUSTER_NAME" ]
    then
      suggest_use_previous_example_ccloud=0
    fi
  fi

  if [ "$(playground state get "ccloud.suggest_use_previous_example_ccloud")" == "0" ]
  then
    suggest_use_previous_example_ccloud=0
  fi

  if [ $suggest_use_previous_example_ccloud -eq 1 ] && [ -z "$GITHUB_RUN_NUMBER" ]
  then
    log "🙋 Use previously used ccloud cluster:"
    log "  🌐 ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)"
    log "  🎰 CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)"
    log "  🌤  CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)"
    log "  🗺  CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)"

    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y )

      ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)
      CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)
      CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)
      CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)
      CLUSTER_CREDS=$(playground state get ccloud.CLUSTER_CREDS)
      SCHEMA_REGISTRY_CREDS=$(playground state get ccloud.SCHEMA_REGISTRY_CREDS)
      ;;
    n|N )

      playground state del ccloud.ENVIRONMENT
      playground state del ccloud.CLUSTER_NAME
      playground state del ccloud.CLUSTER_CLOUD
      playground state del ccloud.CLUSTER_REGION
      playground state del ccloud.CLUSTER_CREDS
      playground state del ccloud.SCHEMA_REGISTRY_CREDS
      ;;
    * )

      logerror "invalid response!";
      exit 1
      ;;
    esac
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #
    # CLUSTER_NAME is not set
    #
    log "🛠👷‍♀️ CLUSTER_NAME is not set, a new Confluent Cloud cluster will be created..."
    log "🎓 If you wanted to use an existing cluster, set CLUSTER_NAME, ENVIRONMENT, CLUSTER_CLOUD, CLUSTER_REGION and CLUSTER_CREDS (also optionnaly SCHEMA_REGISTRY_CREDS)"

    if [ -z "$CLUSTER_CLOUD" ] || [ -z "$CLUSTER_REGION" ]
    then
      logwarn "CLUSTER_CLOUD and/or CLUSTER_REGION are not set, the cluster will be created 🌤 AWS provider and 🗺 eu-west-2 region"
      export CLUSTER_CLOUD=aws
      export CLUSTER_REGION=eu-west-2
      if [ -z "$CLUSTER_TYPE" ]
      then
        export CLUSTER_TYPE=basic
      fi
    fi

    if [ ! -z "$CLUSTER_CREDS" ]
    then
      # make sure it is unset
      unset CLUSTER_CREDS
    fi

    if [ ! -z $ENVIRONMENT ]
    then
      log "🌐 ENVIRONMENT is set with $ENVIRONMENT and will be used"
    else
      if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
      then
        # make sure it is unset
        unset SCHEMA_REGISTRY_CREDS
      fi
    fi
    log "🔋 CLUSTER_TYPE is set with $CLUSTER_TYPE"
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    export EXAMPLE=$(basename $PWD)
    export WARMUP_TIME=15
    export QUIET=true

    check_if_continue
  else
    #
    # CLUSTER_NAME is set
    #
    log "🌱 CLUSTER_NAME is set, your existing Confluent Cloud cluster will be used..."
    if [ -z $ENVIRONMENT ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_REGION ] || [ -z $CLUSTER_CREDS ]
    then
      logerror "One mandatory environment variable to use your cluster is missing:"
      logerror "ENVIRONMENT=$ENVIRONMENT"
      logerror "CLUSTER_NAME=$CLUSTER_NAME"
      logerror "CLUSTER_CLOUD=$CLUSTER_CLOUD"
      logerror "CLUSTER_REGION=$CLUSTER_REGION"
      logerror "CLUSTER_CREDS=$CLUSTER_CREDS"
      exit 1
    fi

    log "🌐 ENVIRONMENT is set with $ENVIRONMENT"
    log "🎰 CLUSTER_NAME is set with $CLUSTER_NAME"
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    for row in $(confluent kafka cluster list --output json | jq -r '.[] | @base64'); do
        _jq() {
        echo ${row} | base64 --decode | jq -r ${1}
        }

        is_current=$(echo $(_jq '.is_current'))
        name=$(echo $(_jq '.name'))

        if [ "$is_current" == "true" ] && [ "$name" == "$CLUSTER_NAME" ]
        then
          if [ -f $DELTA_CONFIGS_ENV ]
          then
            source $DELTA_CONFIGS_ENV
            log "🌱 cluster $CLUSTER_NAME is ready to be used!"

            # trick
            playground state set run.environment "ccloud"
            return
          else
            logwarn "$DELTA_CONFIGS_ENV has not been generated, doing it now..."
            break
          fi
        fi
    done

    export WARMUP_TIME=0
  fi

  ccloud::create_ccloud_stack false  \
    && print_code_pass -c "ccloud::create_ccloud_stack false"

  CCLOUD_CONFIG_FILE=/tmp/tmp.config
  export CCLOUD_CONFIG_FILE=$CCLOUD_CONFIG_FILE
  ccloud::validate_ccloud_config $CCLOUD_CONFIG_FILE || exit 1

  ccloud::generate_configs $CCLOUD_CONFIG_FILE \
    && print_code_pass -c "ccloud::generate_configs $CCLOUD_CONFIG_FILE"

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  playground state set ccloud.ENVIRONMENT "$ENVIRONMENT"
  playground state set ccloud.CLUSTER_NAME "$CLUSTER_NAME"
  playground state set ccloud.CLUSTER_CLOUD "$CLUSTER_CLOUD"
  playground state set ccloud.CLUSTER_REGION "$CLUSTER_REGION"
  playground state set ccloud.CLUSTER_CREDS "$CLUSTER_CREDS"
  playground state set ccloud.SCHEMA_REGISTRY_CREDS "$SCHEMA_REGISTRY_CREDS"

  # trick
  playground state set run.environment "ccloud"
}

function create_ccloud_connector() {
  file=$1

  log "🛠️ Creating connector from $file"
  confluent connect cluster create --config-file $file
  if [[ $? != 0 ]]
  then
    logerror "Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
  fi

  return 0
}

function validate_ccloud_connector_up() {
  connector="$1"
  if [ -f "/tmp/config-$connector" ]
  then
    set +e
    playground connector create-or-update --connector "$connector" --no-clipboard < "/tmp/config-$connector" > /dev/null 2>&1
    if [ $? -ne 0 ]
    then
      echo "💀"
    else
      echo "🔁"
    fi
  else
    echo "❌"
  fi
  set -e

  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function get_ccloud_connector_lcc() {
  confluent connect cluster list -o json | jq -r -e 'map(select(.name == "'"$1"'")) | .[].id'
}

function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
}

function wait_for_ccloud_connector_up() {
  connectorName=$1
  maxWait=$2

  connectorId=$(get_ccloud_connector_lcc $connectorName)
  log "⏳ waiting up to $maxWait seconds for connector $connectorName ($connectorId) to be RUNNING"
  ccloud::retry $maxWait validate_ccloud_connector_up $connectorName || exit 1
  log "🟢 connector $connectorName ($connectorId) is RUNNING"

  if [ -z "$GITHUB_RUN_NUMBER" ]
  then
    playground connector open-in-confluent-cloud --connector $connectorName
  fi

  return 0
}

function delete_ccloud_connector() {
  connectorName=$1
  connectorId=$(get_ccloud_connector_lcc $connectorName)

  log "Deleting connector $connectorName ($connectorId)"
  confluent connect cluster delete $connectorId --force
  return 0
}

function wait_for_log () {
  message="$1"
  container=${2:-connect}
  max_wait=${3:-600}
  cur_wait=0
  log "⌛ Waiting up to $max_wait seconds for message $message to be present in $container container logs..."
  docker container logs ${container} > /tmp/out.txt 2>&1
  while ! grep "$message" /tmp/out.txt > /dev/null;
  do
  sleep 10
  docker container logs ${container} > /tmp/out.txt 2>&1
  cur_wait=$(( cur_wait+10 ))
  if [[ "$cur_wait" -gt "$max_wait" ]]; then
    logerror "The logs in $container container do not show '$message' after $max_wait seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'."
    return 1
  fi
  done
  grep "$message" /tmp/out.txt
  log "The log is there !"
}


CLI_MIN_VERSION=${CLI_MIN_VERSION:-2.5.0}

# --------------------------------------------------------------
# Library
# --------------------------------------------------------------

function ccloud::validate_expect_installed() {
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi

  return 0
}
function ccloud::validate_cli_installed() {
  if [[ $(type confluent 2>&1) =~ "not found" ]]; then
    echo "'confluent' is not found. Install the Confluent CLI (https://docs.confluent.io/confluent-cli/current/install.html) and try again."
    exit 1
  fi
}

function ccloud::validate_cli_v2() {
  ccloud::validate_cli_installed || exit 1

  if [[ -z $(confluent version 2>&1 | grep "Go") ]]; then
    echo "This example requires the new Confluent CLI. Please update your version and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_logged_in_cli() {
  ccloud::validate_cli_v2 || exit 1

  if [[ "$(confluent kafka cluster list 2>&1)" =~ "confluent login" ]]; then
    echo
    echo "ERROR: Not logged into Confluent Cloud."
    echo "Log in with the command 'confluent login --save' before running the example. The '--save' argument saves your Confluent Cloud user login credentials or refresh token (in the case of SSO) to the local netrc file."
    exit 1
  fi

  return 0
}

function ccloud::get_version_cli() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function ccloud::validate_version_cli() {
  ccloud::validate_cli_installed || exit 1

  CLI_VERSION=$(ccloud::get_version_cli)

  if ccloud::version_gt $CLI_MIN_VERSION $CLI_VERSION; then
    echo "confluent version ${CLI_MIN_VERSION} or greater is required. Current version: ${CLI_VERSION}"
    echo "To update, follow: https://docs.confluent.io/confluent-cli/current/migrate.html"
    exit 1
  fi
}

function ccloud::validate_psql_installed() {
  if [[ $(type psql 2>&1) =~ "not found" ]]; then
    echo "psql is not found. Install psql and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_aws_cli_installed() {
  if [[ $(type aws 2>&1) =~ "not found" ]]; then
    echo "AWS CLI is not found. Install AWS CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::get_version_aws_cli() {
  version_major=$(aws --version 2>&1 | awk -F/ '{print $2;}' | head -c 1)
  if [[ "$version_major" -eq 2 ]]; then
    echo "2"
  else
    echo "1"
  fi
  return 0
}

function ccloud::validate_gsutil_installed() {
  if [[ $(type gsutil 2>&1) =~ "not found" ]]; then
    echo "Google Cloud gsutil is not found. Install Google Cloud gsutil and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_az_installed() {
  if [[ $(type az 2>&1) =~ "not found" ]]; then
    echo "Azure CLI is not found. Install Azure CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_source() {
  config=$1

  source $config

  if [[ "$DATA_SOURCE" == "kinesis" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$KINESIS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=kinesis, but KINESIS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws kinesis list-streams --profile $AWS_PROFILE --region $KINESIS_REGION > /dev/null \
      || { echo "Could not run 'aws kinesis list-streams'.  Check credentials and run again." ; exit 1; }
  elif [[ "$DATA_SOURCE" == "rds" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$RDS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=rds, but RDS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws rds describe-db-instances --profile $AWS_PROFILE --region $RDS_REGION > /dev/null \
      || { echo "Could not run 'aws rds describe-db-instances'.  Check credentials and run again." ; exit 1; }
  else
    echo "Cloud source $cloudsource is not valid.  Must be one of [kinesis|rds]."
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_storage() {
  config=$1

  source $config
  storage=$DESTINATION_STORAGE

  if [[ "$storage" == "s3" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    ccloud::validate_credentials_s3 $S3_PROFILE $S3_BUCKET || exit 1
    aws s3api list-buckets --profile $S3_PROFILE --region $STORAGE_REGION > /dev/null \
      || { echo "Could not run 'aws s3api list-buckets'.  Check credentials and run again." ; exit 1; }
  elif [[ "$storage" == "gcs" ]]; then
    ccloud::validate_gsutil_installed || exit 1
    ccloud::validate_credentials_gcp $GCS_CREDENTIALS_FILE $GCS_BUCKET || exit 1
  elif [[ "$storage" == "az" ]]; then
    ccloud::validate_az_installed || exit 1
    ccloud::validate_credentials_az $AZBLOB_STORAGE_ACCOUNT $AZBLOB_CONTAINER || exit 1
  else
    echo "Storage destination $storage is not valid.  Must be one of [s3|gcs|az]."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_gcp() {
  GCS_CREDENTIALS_FILE=$1
  GCS_BUCKET=$2

  if [[ -z "$GCS_CREDENTIALS_FILE" || -z "$GCS_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=gcs, but GCS_CREDENTIALS_FILE or GCS_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  gcloud auth activate-service-account --key-file $GCS_CREDENTIALS_FILE || {
    echo "ERROR: Cannot activate service account with key file $GCS_CREDENTIALS_FILE. Verify your credentials and try again."
    exit 1
  }

  # Create JSON-formatted string of the GCS credentials
  export GCS_CREDENTIALS=$(python ./stringify-gcp-credentials.py $GCS_CREDENTIALS_FILE)
  # Remove leading and trailing double quotes, otherwise connector creation from CLI fails
  GCS_CREDENTIALS=$(echo "${GCS_CREDENTIALS:1:${#GCS_CREDENTIALS}-2}")

  return 0
}

function ccloud::validate_credentials_az() {
  AZBLOB_STORAGE_ACCOUNT=$1
  AZBLOB_CONTAINER=$2

  if [[ -z "$AZBLOB_STORAGE_ACCOUNT" || -z "$AZBLOB_CONTAINER" ]]; then
    echo "ERROR: DESTINATION_STORAGE=az, but AZBLOB_STORAGE_ACCOUNT or AZBLOB_CONTAINER is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_s3() {
  S3_PROFILE=$1
  S3_BUCKET=$2

  if [[ -z "$S3_PROFILE" || -z "$S3_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=s3, but S3_PROFILE or S3_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  aws configure get aws_access_key_id --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_access_key_id from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  aws configure get aws_secret_access_key --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_secret_access_key from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  return 0
}

function ccloud::validate_schema_registry_up() {
  auth=$1
  sr_endpoint=$2

  curl --silent -u $auth $sr_endpoint > /dev/null || {
    echo "ERROR: Could not validate credentials to Confluent Cloud Schema Registry. Please troubleshoot"
    exit 1
  }

  echo "Validated credentials to Confluent Cloud Schema Registry at $sr_endpoint"
  return 0
}

function ccloud::get_environment_id_from_service_id() {
  SERVICE_ACCOUNT_ID=$1

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-${USER}-$$SERVICE_ACCOUNT_ID"}
  local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')

  echo $environment_id

  return 0
}

function ccloud::create_and_use_environment() {
  ENVIRONMENT_NAME=$1

  OUTPUT=$(confluent environment create $ENVIRONMENT_NAME -o json)
  (($? != 0)) && { echo "ERROR: Failed to create environment $ENVIRONMENT_NAME. Please troubleshoot and run again"; exit 1; }
  ENVIRONMENT=$(echo "$OUTPUT" | jq -r ".id")
  confluent environment use $ENVIRONMENT &>/dev/null

  echo $ENVIRONMENT

  return 0
}

function ccloud::find_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3

  local FOUND_CLUSTER=$(confluent kafka cluster list -o json | jq -c -r '.[] | select((.name == "'"$CLUSTER_NAME"'") and (.provider == "'"$CLUSTER_CLOUD"'") and (.region == "'"$CLUSTER_REGION"'"))')
  [[ ! -z "$FOUND_CLUSTER" ]] && {
      echo "$FOUND_CLUSTER" | jq -r .id
      return 0
    } || {
      return 1
    }
}

function ccloud::create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4

  OUTPUT=$(confluent kafka cluster create "$CLUSTER_NAME" --cloud $CLUSTER_CLOUD --region $CLUSTER_REGION --type $CLUSTER_TYPE --output json 2>&1)
  (($? != 0)) && { echo "$OUTPUT"; exit 1; }
  CLUSTER=$(echo "$OUTPUT" | jq -r .id)
  confluent kafka cluster use $CLUSTER 2>/dev/null

  # Wait until the cluster status is not PROVISIONING
  while true; do
    CLUSTER_STATUS=$(confluent kafka cluster describe $CLUSTER --output json | jq -r .status)
    if [ "$CLUSTER_STATUS" != "PROVISIONING" ]; then
      break
    fi
    sleep 5
  done

  echo $CLUSTER
  return 0
}

function ccloud::maybe_create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4
  CLUSTER_ID=$(ccloud::find_cluster $CLUSTER_NAME $CLUSTER_CLOUD $CLUSTER_REGION)
  if [ $? -eq 0 ]
  then
    confluent kafka cluster use $CLUSTER_ID
    echo $CLUSTER_ID
  else

    # VINC: added
    if [[ ! -z "$CLUSTER_CREDS" ]]
    then
      echo "ERROR: Could not find your $CLUSTER_CLOUD cluster $CLUSTER_NAME in region $CLUSTER_REGION"
      echo "Make sure CLUSTER_CLOUD and CLUSTER_REGION are set with values that correspond to your cluster!"
      exit 1
    else
      OUTPUT=$(ccloud::create_and_use_cluster "$CLUSTER_NAME" "$CLUSTER_CLOUD" "$CLUSTER_REGION" "$CLUSTER_TYPE")
      (($? != 0)) && { echo "$OUTPUT"; exit 1; }
      echo "$OUTPUT"
    fi
  fi

  return 0
}

function ccloud::create_service_account() {
  SERVICE_NAME=$1

  CCLOUD_EMAIL=$(confluent prompt -f '%u')
  OUTPUT=$(confluent iam service-account create $SERVICE_NAME --description "SA for $EXAMPLE run by $CCLOUD_EMAIL"  -o json)
  SERVICE_ACCOUNT_ID=$(echo "$OUTPUT" | jq -r ".id")

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud:get_service_account_from_current_cluster_name() {
  SERVICE_ACCOUNT_ID=$(confluent kafka cluster describe -o json | jq -r '.name' | awk -F'-' '{print $3 "-" $4;}')

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud::enable_schema_registry() {
  SCHEMA_REGISTRY_CLOUD=$1
  SCHEMA_REGISTRY_GEO=$2

  OUTPUT=$(confluent schema-registry cluster enable --cloud $SCHEMA_REGISTRY_CLOUD --geo $SCHEMA_REGISTRY_GEO -o json)
  SCHEMA_REGISTRY=$(echo "$OUTPUT" | jq -r ".id")

  echo $SCHEMA_REGISTRY

  return 0
}

function ccloud::find_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2
  local FOUND_CRED=$(confluent api-key list -o json | jq -c -r 'map(select((.resource_id == "'"$RESOURCE"'") and (.owner_resource_id == "'"$SERVICE_ACCOUNT_ID"'")))')
  local FOUND_COUNT=$(echo "$FOUND_CRED" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_CRED" | jq -r '.[0].api_key'
      return 0
    } || {
      return 1
    }
}
function ccloud::create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  OUTPUT=$(confluent api-key create --service-account $SERVICE_ACCOUNT_ID --resource $RESOURCE -o json)
  API_KEY_SA=$(echo "$OUTPUT" | jq -r ".api_key")
  API_SECRET_SA=$(echo "$OUTPUT" | jq -r ".api_secret")
  echo "${API_KEY_SA}:${API_SECRET_SA}"

  # vinc
  sleep 30
  return 0
}
# The return from this function will be a colon ':' delimited
#   list, if the api-key is created the second element of the
#   list will be the secret.  If the api-key is being reused
#   the second element of the list will be empty
function ccloud::maybe_create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  local KEY=$(ccloud::find_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE)
  [[ -z $KEY ]] && {
    ccloud::create_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE
  } || {
    echo "$KEY:"; # the secret cannot be retrieved from a found key, caller needs to handle this
    return 0
  }
}

function ccloud::find_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2

  local FOUND_APP=$(confluent ksql cluster list -o json | jq -c -r 'map(select((.name == "'"$KSQLDB_NAME"'") and (.kafka == "'"$CLUSTER"'")))')
  local FOUND_COUNT=$(echo "$FOUND_APP" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_APP" | jq -r '.[].id'
      return 0
    } || {
      return 1
    }
}

function ccloud::create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3
  local kafka_api_key=$(echo $ksqlDB_kafka_creds | cut -d':' -f1)
  local kafka_api_secret=$(echo $ksqlDB_kafka_creds | cut -d':' -f2)

  KSQLDB=$(confluent ksql cluster create --cluster $CLUSTER --api-key "$kafka_api_key" --api-secret "$kafka_api_secret" --csu 1 -o json "$KSQLDB_NAME" | jq -r ".id")
  echo $KSQLDB

  return 0
}
function ccloud::maybe_create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3

  APP_ID=$(ccloud::find_ksqldb_app $KSQLDB_NAME $CLUSTER)
  if [ $? -eq 0 ]
  then
    echo $APP_ID
  else
    ccloud::create_ksqldb_app "$KSQLDB_NAME" "$CLUSTER" "$ksqlDB_kafka_creds"
  fi

  return 0
}

function ccloud::create_acls_all_resources_full_access() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::delete_acls_ccloud_stack() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Deleting ACLs for service account ID $SERVICE_ACCOUNT_ID"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::validate_ccloud_config() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ccloud_config expects one parameter (configuration file with Confluent Cloud connection information)"
    exit 1
  }

  local cfg_file="$1"
  local bootstrap=$(grep "bootstrap\.servers" "$cfg_file" | cut -d'=' -f2-)
  [ -z "$bootstrap" ] && {
    echo "ERROR: Cannot read the 'bootstrap.servers' key-value pair from $cfg_file."
    exit 1;
  }
  return 0;
}

function ccloud::validate_ksqldb_up() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ksqldb_up expects one parameter (ksqldb endpoint)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::validate_ksqldb_up function expects one parameter"

  local ksqldb_endpoint=$1

  ccloud::validate_logged_in_cli || exit 1

  local ksqldb_meta=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$ksqldb_endpoint"'")) | .[]')

  local ksqldb_appid=$(echo "$ksqldb_meta" | jq -r '.id')
  if [[ "$ksqldb_appid" == "" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint is not found. Provision a ksqlDB cluster via the Confluent Cloud UI and add the configuration parameter ksql.endpoint and ksql.basic.auth.user.info into your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  local ksqldb_status=$(echo "$ksqldb_meta" | jq -r '.status')
  if [[ $ksqldb_status != "UP" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint with id $ksqlDBAppId is not in UP state. Troubleshoot and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_azure_account() {
  AZBLOB_STORAGE_ACCOUNT=$1

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of STORAGE_PROFILE in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of STORAGE_PROFILE in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_ksqldb() {
  ksqldb_endpoint=$1
  ccloud_config_file=$2
  credentials=$3

  response=$(curl ${ksqldb_endpoint}/info \
             -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" \
             --silent \
             -u $credentials)
  if [[ "$response" =~ "Unauthorized" ]]; then
    echo "ERROR: Authorization failed to the ksqlDB cluster. Check your ksqlDB credentials set in the configuration parameter ksql.basic.auth.user.info in your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  echo "Validated credentials to Confluent Cloud ksqlDB at $ksqldb_endpoint"
  return 0
}

function ccloud::create_connector() {
  file=$1

  echo -e "\nCreating connector from $file\n"

  # About the Confluent CLI command 'confluent connect cluster create':
  # - Typical usage of this CLI would be 'confluent connect cluster create --config-file <filename>'
  # - However, in this example, the connector's configuration file contains parameters that need to be first substituted
  #   so the CLI command includes eval and heredoc.
  # - The '-vvv' is added for verbose output
  confluent connect cluster create -vvv --config <(eval "cat <<EOF
$(<$file)
EOF
")
  if [[ $? != 0 ]]; then
    echo "ERROR: Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function ccloud::wait_for_connector_up() {
  connectorName=$1
  maxWait=$2

  echo "Waiting up to $maxWait seconds for connector $filename ($connectorName) to be RUNNING"
  ccloud::retry $maxWait ccloud::validate_connector_up $connectorName || exit 1
  echo "Connector $filename ($connectorName) is RUNNING"

  return 0
}

function ccloud::validate_ccloud_ksqldb_endpoint_ready() {
  KSQLDB_ENDPOINT=$1

  STATUS=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$KSQLDB_ENDPOINT"'")) | .[].status' | grep UP)
  if [[ "$STATUS" == "" ]]; then
    return 1
  fi

  return 0
}

function ccloud::validate_ccloud_cluster_ready() {
  confluent kafka topic list &>/dev/null
  return $?
}

function ccloud::validate_topic_exists() {
  topic=$1

  confluent kafka topic describe $topic &>/dev/null
  return $?
}

function ccloud::validate_subject_exists() {
  subject=$1
  sr_url=$2
  sr_credentials=$3

  curl --silent -u $sr_credentials $sr_url/subjects/$subject/versions/latest | jq -r ".subject" | grep $subject > /dev/null
  return $?
}

function ccloud::login_cli(){
  URL=$1
  EMAIL=$2
  PASSWORD=$3

  ccloud::validate_expect_installed

  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $URL --prompt -vvvv
    expect "Email: "
    send "$EMAIL\r";
    expect "Password: "
    send "$PASSWORD\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into your cluster. Please check all parameters and run again."
  fi

  return 0
}

function ccloud::get_service_account() {

  [ -z "$1" ] && {
    echo "ccloud::get_service_account expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::get_service_account function expects one parameter, received two"

  local key="$1"

  serviceAccount=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'"))) | .[].owner_resource_id')
  if [[ "$serviceAccount" == "" ]]; then
    echo "ERROR: Could not associate key $key to a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi
  if ! [[ "$serviceAccount" =~ ^sa-[a-z0-9]+$ ]]; then
    echo "ERROR: $serviceAccount value is not a valid value for a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  echo "$serviceAccount"

  return 0
}

function ccloud::create_acls_connector() {
  serviceAccount=$1

  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope
  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE --prefix --topic dlq-lcc
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --prefix --consumer-group connect-lcc

  return 0
}

function ccloud::create_acls_control_center() {
  serviceAccount=$1

  echo "Confluent Control Center: creating _confluent-command and ACLs for service account $serviceAccount"
  confluent kafka topic create _confluent-command --partitions 1

  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ,CREATE --topic _confluent --prefix

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ,WRITE,CREATE --consumer-group _confluent --prefix

  return 0
}

function ccloud::create_acls_replicator() {
  serviceAccount=$1
  topic=$2

  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS,ALTER-CONFIGS,DESCRIBE --topic $topic

  return 0
}

function ccloud::create_acls_connect_topics() {
  serviceAccount=$1

  echo "Connect: creating topics and ACLs for service account $serviceAccount"

  TOPIC=connect-demo-configs
  confluent kafka topic create $TOPIC --partitions 1 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-offsets
  confluent kafka topic create $TOPIC --partitions 6 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-statuses
  confluent kafka topic create $TOPIC --partitions 3 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix

  for TOPIC in _confluent-monitoring _confluent-command ; do
    confluent kafka topic create $TOPIC --partitions 1 &>/dev/null
    confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix
  done

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-cloud

  echo "Connectors: creating topics and ACLs for service account $serviceAccount"
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-replicator
  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope

  return 0
}

function ccloud::validate_ccloud_stack_up() {
  CLOUD_KEY=$1
  CCLOUD_CONFIG_FILE=$2
  enable_ksqldb=$3

  if [ -z "$enable_ksqldb" ]; then
    enable_ksqldb=true
  fi

  ccloud::validate_environment_set || exit 1
  ccloud::set_kafka_cluster_use_from_api_key "$CLOUD_KEY" || exit 1
  ccloud::validate_schema_registry_up "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL" || exit 1
  if $enable_ksqldb ; then
    ccloud::validate_ksqldb_up "$KSQLDB_ENDPOINT" || exit 1
    ccloud::validate_credentials_ksqldb "$KSQLDB_ENDPOINT" "$CCLOUD_CONFIG_FILE" "$KSQLDB_BASIC_AUTH_USER_INFO" || exit 1
  fi
}

function ccloud::validate_environment_set() {
  confluent environment list | grep '*' &>/dev/null || {
    echo "ERROR: could not determine if environment is set. Run 'confluent environment list' and set 'confluent environment use' and try again"
    exit 1
  }

  return 0
}

function ccloud::set_kafka_cluster_use_from_api_key() {
  [ -z "$1" ] && {
    echo "ccloud::set_kafka_cluster_use_from_api_key expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::set_kafka_cluster_use_from_api_key function expects one parameter, received two"

  local key="$1"

  local kafkaCluster=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'" and .resource_type == "kafka"))) | .[].resource_id')
  if [[ "$kafkaCluster" == "" ]]; then
    echo "ERROR: Could not associate key $key to a Confluent Cloud Kafka cluster. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  confluent kafka cluster use $kafkaCluster
  local endpoint=$(confluent kafka cluster describe $kafkaCluster -o json | jq -r ".endpoint" | cut -c 12-)
  echo -e "\nAssociated key $key to Confluent Cloud Kafka cluster $kafkaCluster at $endpoint"

  return 0
}

# Deprecated 10/28/2020, use ccloud::set_kafka_cluster_use_from_api_key
function ccloud::set_kafka_cluster_use() {
  echo "WARN: set_kafka_cluster_use is deprecated, use ccloud::set_kafka_cluster_use_from_api_key"
  ccloud::set_kafka_cluster_use_from_api_key "$@"
}

#
# ccloud-stack documentation:
# https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html
#
function ccloud::create_ccloud_stack() {
  #ccloud::validate_version_cli $CLI_MIN_VERSION || exit 1
  QUIET="${QUIET:-false}"
  REPLICATION_FACTOR=${REPLICATION_FACTOR:-3}
  enable_ksqldb=${1:-false}
  EXAMPLE=${EXAMPLE:-ccloud-stack-function}
  CHECK_CREDIT_CARD="${CHECK_CREDIT_CARD:-false}"

  # Check if credit card is on file, which is required for cluster creation
  if $CHECK_CREDIT_CARD && [[ $(confluent admin payment describe) =~ "not found" ]]; then
    echo "ERROR: No credit card on file. Add a payment method and try again."
    echo "If you are using a cloud provider's Marketplace, see documentation for a workaround: https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html#running-with-marketplace"
    exit 1
  fi

  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-${USER}-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi

    if [[ "$SERVICE_NAME" == "" ]]; then
      echo "ERROR: SERVICE_NAME is not defined. If you are providing the SERVICE_ACCOUNT_ID to this function please also provide the SERVICE_NAME"
      exit 1
    fi

    echo "Creating Confluent Cloud stack for service account $SERVICE_NAME, ID: $SERVICE_ACCOUNT_ID."
  fi

  if [[ -z "$ENVIRONMENT" ]];
  then
    # Environment is not received so it will be created
    MAX_LENGTH=64
    ENVIRONMENT_NAME=${ENVIRONMENT_NAME:-"pg-${USER}-$SERVICE_ACCOUNT_ID-$EXAMPLE"}
    if [ ${#ENVIRONMENT_NAME} -gt $MAX_LENGTH ]
    then
      ENVIRONMENT_NAME=$(echo $ENVIRONMENT_NAME | cut -c 1-$MAX_LENGTH)
    fi

    ENVIRONMENT=$(ccloud::create_and_use_environment $ENVIRONMENT_NAME)
    (($? != 0)) && { echo "$ENVIRONMENT"; exit 1; }
  else
    confluent environment use $ENVIRONMENT || exit 1
  fi

  CLUSTER_NAME=${CLUSTER_NAME:-"pg-${USER}-cluster-$SERVICE_ACCOUNT_ID"}
  CLUSTER_CLOUD="${CLUSTER_CLOUD:-aws}"
  CLUSTER_REGION="${CLUSTER_REGION:-us-west-2}"
  CLUSTER_TYPE="${CLUSTER_TYPE:-basic}"
  CLUSTER=$(ccloud::maybe_create_and_use_cluster "$CLUSTER_NAME" $CLUSTER_CLOUD $CLUSTER_REGION $CLUSTER_TYPE)
  (($? != 0)) && { echo "$CLUSTER"; exit 1; }
  if [[ "$CLUSTER" == "" ]] ; then
    echo "Kafka cluster id is empty"
    echo "ERROR: Could not create cluster. Please troubleshoot."
    exit 1
  fi

  endpoint=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".endpoint")
  if [[ $endpoint == "SASL_SSL://"* ]]
  then
    BOOTSTRAP_SERVERS=$(echo "$endpoint" | cut -c 12-)
  else
    BOOTSTRAP_SERVERS="$endpoint"
  fi

  NEED_ACLS=0
  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    CLUSTER_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $CLUSTER)
    NEED_ACLS=1
  fi

  MAX_WAIT=720
  echo ""
  echo "Waiting up to $MAX_WAIT seconds for Confluent Cloud cluster to be ready"
  ccloud::retry $MAX_WAIT ccloud::validate_ccloud_cluster_ready || exit 1

  # VINC: added
  if [[ $NEED_ACLS -eq 1 ]]
  then
    # Estimating another 80s wait still sometimes required
    WARMUP_TIME=${WARMUP_TIME:-80}
    echo "Sleeping an additional ${WARMUP_TIME} seconds to ensure propagation of all metadata"
    sleep $WARMUP_TIME

    ccloud::create_acls_all_resources_full_access $SERVICE_ACCOUNT_ID
  fi

  SCHEMA_REGISTRY_GEO="${SCHEMA_REGISTRY_GEO:-us}"
  SCHEMA_REGISTRY=$(ccloud::enable_schema_registry $CLUSTER_CLOUD $SCHEMA_REGISTRY_GEO)

  # VINC: added
  if [[ -z "$SCHEMA_REGISTRY_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-${USER}-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi
    SCHEMA_REGISTRY_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $SCHEMA_REGISTRY)
  fi

  SCHEMA_REGISTRY_ENDPOINT=$(confluent schema-registry cluster describe -o json | jq -r ".endpoint_url")

  if [[ $NEED_ACLS -eq 1 ]]
  then
    # VINC
    set +e
    if [ "$SERVICE_ACCOUNT_ID" != "" ]
    then
      log "Adding ResourceOwner RBAC role for all subjects"
      confluent iam rbac role-binding create --principal User:$SERVICE_ACCOUNT_ID --role ResourceOwner --environment $ENVIRONMENT --schema-registry-cluster $SCHEMA_REGISTRY --resource Subject:*
    fi
    set -e
  fi

  if $enable_ksqldb ; then
    KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}
    KSQLDB=$(ccloud::maybe_create_ksqldb_app "$KSQLDB_NAME" $CLUSTER "$CLUSTER_CREDS")
    KSQLDB_ENDPOINT=$(confluent ksql cluster describe $KSQLDB -o json | jq -r ".endpoint")
    KSQLDB_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $KSQLDB)
    confluent ksql cluster configure-acls $KSQLDB
  fi

  KAFKA_API_KEY=`echo $CLUSTER_CREDS | awk -F: '{print $1}'`
  KAFKA_API_SECRET=`echo $CLUSTER_CREDS | awk -F: '{print $2}'`
  # FIX THIS: added by me
  confluent api-key store "$KAFKA_API_KEY" "$KAFKA_API_SECRET" --resource ${CLUSTER} --force
  confluent api-key use $KAFKA_API_KEY --resource ${CLUSTER}

  if [[ -z "$SKIP_CONFIG_FILE_WRITE" ]]; then
    if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
      CCLOUD_CONFIG_FILE="/tmp/tmp.config"
    fi

    cat <<EOF > $CCLOUD_CONFIG_FILE
# --------------------------------------
# Confluent Cloud connection information
# --------------------------------------
# ENVIRONMENT ID: ${ENVIRONMENT}
# SERVICE ACCOUNT ID: ${SERVICE_ACCOUNT_ID}
# KAFKA CLUSTER ID: ${CLUSTER}
# SCHEMA REGISTRY CLUSTER ID: ${SCHEMA_REGISTRY}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
# KSQLDB APP ID: ${KSQLDB}
EOF
    fi
    cat <<EOF >> $CCLOUD_CONFIG_FILE
# --------------------------------------
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
bootstrap.servers=${BOOTSTRAP_SERVERS}
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${KAFKA_API_KEY}' password='${KAFKA_API_SECRET}';
basic.auth.credentials.source=USER_INFO
schema.registry.url=${SCHEMA_REGISTRY_ENDPOINT}
basic.auth.user.info=`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $1}'`:`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $2}'`
replication.factor=${REPLICATION_FACTOR}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
ksql.endpoint=${KSQLDB_ENDPOINT}
ksql.basic.auth.user.info=`echo $KSQLDB_CREDS | awk -F: '{print $1}'`:`echo $KSQLDB_CREDS | awk -F: '{print $2}'`
EOF
    fi
  fi

  return 0
}

function ccloud::destroy_ccloud_stack() {
  if [ $# -eq 0 ];then
    echo "ccloud::destroy_ccloud_stack requires a single parameter, the service account id."
    exit 1
  fi

  SERVICE_ACCOUNT_ID=$1
  ENVIRONMENT=${ENVIRONMENT:-$(ccloud::get_environment_id_from_service_id $SERVICE_ACCOUNT_ID)}

  confluent environment use $ENVIRONMENT || exit 1

  PRESERVE_ENVIRONMENT="${PRESERVE_ENVIRONMENT:-false}"

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-${USER}-$SERVICE_ACCOUNT_ID"}
  CLUSTER_NAME=${CLUSTER_NAME:-"pg-${USER}-cluster-$SERVICE_ACCOUNT_ID"}
  CCLOUD_CONFIG_FILE=${CCLOUD_CONFIG_FILE:-"/tmp/tmp.config"}
  KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}

  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Destroying Confluent Cloud stack associated to service account id $SERVICE_ACCOUNT_ID"

  # Delete associated ACLs
  ccloud::delete_acls_ccloud_stack $SERVICE_ACCOUNT_ID

  ksqldb_id_found=$(confluent ksql cluster list -o json | jq -r 'map(select(.name == "'"$KSQLDB_NAME"'")) | .[].id')
  if [[ $ksqldb_id_found != "" ]]; then
    echo "Deleting KSQLDB: $KSQLDB_NAME : $ksqldb_id_found"
    confluent ksql cluster delete $ksqldb_id_found &> "$REDIRECT_TO"
  fi

  # Delete connectors associated to this Kafka cluster, otherwise cluster deletion fails
  local cluster_id=$(confluent kafka cluster list -o json | jq -r 'map(select(.name == "'"$CLUSTER_NAME"'")) | .[].id')
  confluent connect cluster list --cluster $cluster_id -o json | jq -r '.[].id' | xargs -I{} confluent connect cluster delete {} --force

  echo "Deleting CLUSTER: $CLUSTER_NAME : $cluster_id"
  confluent kafka cluster delete $cluster_id &> "$REDIRECT_TO"

  # Delete API keys associated to the service account
  confluent api-key list --service-account $SERVICE_ACCOUNT_ID -o json | jq -r '.[].api_key' | xargs -I{} confluent api-key delete {} --force

  # Delete service account
  confluent iam service-account delete $SERVICE_ACCOUNT_ID --force &>"$REDIRECT_TO"

  if [[ $PRESERVE_ENVIRONMENT == "false" ]]; then
    local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')
    if [[ "$environment_id" == "" ]]; then
      echo "WARNING: Could not find environment with name that starts with $ENVIRONMENT_NAME_PREFIX (did you create this ccloud-stack reusing an existing environment?)"
    else
      echo "Deleting ENVIRONMENT: prefix $ENVIRONMENT_NAME_PREFIX : $environment_id"
      confluent environment delete $environment_id &> "$REDIRECT_TO"
    fi
  fi

  rm -f $CCLOUD_CONFIG_FILE

  return 0
}

# Overview:
#
# This code reads a local Confluent Cloud configuration file
# and writes delta configuration files into ./delta_configs for
# Confluent Platform components and clients connecting to Confluent Cloud.
#
# Confluent Platform Components:
# - Confluent Schema Registry
# - KSQL Data Generator
# - ksqlDB server
# - Confluent Replicator (executable)
# - Confluent Control Center
# - Confluent Metrics Reporter
# - Confluent REST Proxy
# - Kafka Connect
# - Kafka connector
# - Kafka command line tools
#
# Kafka Clients:
# - Java (Producer/Consumer)
# - Java (Streams)
# - librdkafka config
# - Python
# - .NET
# - Go
# - Node.js (https://github.com/Blizzard/node-rdkafka)
# - C++
#
# Documentation for using this script:
#
#   https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html
#
# Arguments:
#
#   CCLOUD_CONFIG_FILE, defaults to ~/.ccloud/config
#
# Example CCLOUD_CONFIG_FILE at ~/.ccloud/config
#
#   $ cat $HOME/.ccloud/config
#
#   bootstrap.servers=<BROKER ENDPOINT>
#   security.protocol=SASL_SSL
#   sasl.mechanism=PLAIN
#   sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<API KEY>' password='<API SECRET>';
#
# If you are using Confluent Cloud Schema Registry, add the following configuration parameters
#
#   basic.auth.credentials.source=USER_INFO
#   basic.auth.user.info=<SR API KEY>:<SR API SECRET>
#   schema.registry.url=https://<SR ENDPOINT>
#
# If you are using Confluent Cloud ksqlDB, add the following configuration parameters
#
#   ksql.endpoint=<ksqlDB ENDPOINT>
#   ksql.basic.auth.user.info=<ksqlDB API KEY>:<ksqlDB API SECRET>
#
function ccloud::generate_configs() {
  CCLOUD_CONFIG_FILE=$1
  if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
    CCLOUD_CONFIG_FILE=~/.ccloud/config
  fi
  if [[ ! -f "$CCLOUD_CONFIG_FILE" ]]; then
    echo "File $CCLOUD_CONFIG_FILE is not found.  Please create this properties file to connect to your Confluent Cloud cluster and then try again"
    echo "See https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html for more information"
    return 1
  fi

  # log "Generating component configurations"
  # log "(If you want to run any of these components to talk to Confluent Cloud, these are the configurations to add to the properties file for each component)"

  # Set permissions
  PERM=600
  if ls --version 2>/dev/null | grep -q 'coreutils' ; then
    # GNU binutils
    PERM=$(stat -c "%a" $CCLOUD_CONFIG_FILE)
  else
    # BSD
    PERM=$(stat -f "%OLp" $CCLOUD_CONFIG_FILE)
  fi

  # Make destination
  get_kafka_docker_playground_dir
  DEST=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud
  mkdir -p $DEST
  # Glean parameters from the Confluent Cloud configuration file

  # Kafka cluster
  BOOTSTRAP_SERVERS=$( grep "^bootstrap.server" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS/\\/}
  SASL_JAAS_CONFIG=$( grep "^sasl.jaas.config" $CCLOUD_CONFIG_FILE | cut -d'=' -f2- )
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG/username\\=/username=}
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG_PROPERTY_FORMAT/password\\=/password=}
  CLOUD_KEY=$( echo $SASL_JAAS_CONFIG | awk '{print $3}' | awk -F"'" '$0=$2' )
  CLOUD_SECRET=$( echo $SASL_JAAS_CONFIG | awk '{print $4}' | awk -F"'" '$0=$2' )

  # Schema Registry
  BASIC_AUTH_CREDENTIALS_SOURCE=$( grep "^basic.auth.credentials.source" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=$( grep "^basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_URL=$( grep "^schema.registry.url" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # ksqlDB
  KSQLDB_ENDPOINT=$( grep "^ksql.endpoint" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  KSQLDB_BASIC_AUTH_USER_INFO=$( grep "^ksql.basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # Build configuration file with Confluent Cloud connection parameters and
  # Confluent Monitoring Interceptors for Streams Monitoring in Confluent Control Center
  INTERCEPTORS_CONFIG_FILE=$DEST/interceptors-ccloud.config
  rm -f $INTERCEPTORS_CONFIG_FILE
  echo "# Configuration derived from $CCLOUD_CONFIG_FILE" > $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    echo $line >> $INTERCEPTORS_CONFIG_FILE
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Monitoring Interceptor specific configuration" >> $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    if [[ ${line:0:4} == 'sasl' ||
          ${line:0:3} == 'ssl' ||
          ${line:0:8} == 'security' ||
          ${line:0:9} == 'bootstrap' ]]; then
      echo "confluent.monitoring.interceptor.$line" >> $INTERCEPTORS_CONFIG_FILE
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $INTERCEPTORS_CONFIG_FILE

  #log "Confluent Platform Components:"

  # Confluent Schema Registry instance (local) for Confluent Cloud
  SR_CONFIG_DELTA=$DEST/schema-registry-ccloud.delta
  #echo "$SR_CONFIG_DELTA"
  rm -f $SR_CONFIG_DELTA
  while read -r line
  do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:29} != 'basic.auth.credentials.source' && ${line:0:15} != 'schema.registry' ]]; then
        echo "kafkastore.$line" >> $SR_CONFIG_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $SR_CONFIG_DELTA

  # Confluent Replicator (executable) for Confluent Cloud
  REPLICATOR_PRODUCER_DELTA=$DEST/replicator-to-ccloud-producer.delta
  #echo "$REPLICATOR_PRODUCER_DELTA"
  rm -f $REPLICATOR_PRODUCER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $REPLICATOR_PRODUCER_DELTA
  echo -e "\n# Confluent Replicator (executable) specific configuration" >> $REPLICATOR_PRODUCER_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $REPLICATOR_PRODUCER_DELTA
  REPLICATOR_SASL_JAAS_CONFIG=$SASL_JAAS_CONFIG
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\\=/=}
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\"/\\\"}
  chmod $PERM $REPLICATOR_PRODUCER_DELTA

  # ksqlDB Server runs locally and connects to Confluent Cloud
  KSQLDB_SERVER_DELTA=$DEST/ksqldb-server-ccloud.delta
  #echo "$KSQLDB_SERVER_DELTA"
  rm -f $KSQLDB_SERVER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQLDB_SERVER_DELTA
  echo -e "\n# ksqlDB Server specific configuration" >> $KSQLDB_SERVER_DELTA
  echo "producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.retries=2147483647" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.confluent.batch.expiry.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.request.timeout.ms=300000" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.max.block.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.replication.factor=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.internal.topic.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.sink.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo -e "\n# Confluent Schema Registry configuration for ksqlDB Server" >> $KSQLDB_SERVER_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQLDB_SERVER_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQLDB_SERVER_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQLDB_SERVER_DELTA

  # KSQL DataGen for Confluent Cloud
  KSQL_DATAGEN_DELTA=$DEST/ksql-datagen.delta
  #echo "$KSQL_DATAGEN_DELTA"
  rm -f $KSQL_DATAGEN_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQL_DATAGEN_DELTA
  echo -e "\n# KSQL DataGen specific configuration" >> $KSQL_DATAGEN_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQL_DATAGEN_DELTA
  echo -e "\n# Confluent Schema Registry configuration for KSQL DataGen" >> $KSQL_DATAGEN_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQL_DATAGEN_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQL_DATAGEN_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQL_DATAGEN_DELTA

  # Confluent Control Center runs locally, monitors Confluent Cloud, and uses Confluent Cloud cluster as the backstore
  C3_DELTA=$DEST/control-center-ccloud.delta
  #echo "$C3_DELTA"
  rm -f $C3_DELTA
  echo -e "\n# Confluent Control Center specific configuration" >> $C3_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $C3_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.controlcenter.streams.$line" >> $C3_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  # max.message.bytes is enforced to 8MB in Confluent Cloud
  echo "confluent.metrics.topic.max.message.bytes=8388608" >> $C3_DELTA
  echo -e "\n# Confluent Schema Registry configuration for Confluent Control Center" >> $C3_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "confluent.controlcenter.schema.registry.$line" >> $C3_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "confluent.controlcenter.$line" >> $C3_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $C3_DELTA

  # Confluent Metrics Reporter to Confluent Cloud
  METRICS_REPORTER_DELTA=$DEST/metrics-reporter.delta
  #echo "$METRICS_REPORTER_DELTA"
  rm -f $METRICS_REPORTER_DELTA
  echo "metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter" >> $METRICS_REPORTER_DELTA
  echo "confluent.metrics.reporter.topic.replicas=3" >> $METRICS_REPORTER_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.metrics.reporter.$line" >> $METRICS_REPORTER_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $METRICS_REPORTER_DELTA

  # Confluent REST Proxy to Confluent Cloud
  REST_PROXY_DELTA=$DEST/rest-proxy.delta
  #echo "$REST_PROXY_DELTA"
  rm -f $REST_PROXY_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $REST_PROXY_DELTA
        echo "client.$line" >> $REST_PROXY_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Schema Registry configuration for REST Proxy" >> $REST_PROXY_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' || ${line:0:36} == 'schema.registry.basic.auth.user.info' ]]; then
      echo "client.$line" >> $REST_PROXY_DELTA
    elif [[ ${line:0:19} == 'schema.registry.url' ]]; then
      echo "$line" >> $REST_PROXY_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $REST_PROXY_DELTA

  # Kafka Connect runs locally and connects to Confluent Cloud
  CONNECT_DELTA=$DEST/connect-ccloud.delta
  #echo "$CONNECT_DELTA"
  rm -f $CONNECT_DELTA
  cat <<EOF > $CONNECT_DELTA
# Configuration for embedded admin client
replication.factor=3
config.storage.replication.factor=3
offset.storage.replication.factor=3
status.storage.replication.factor=3

EOF
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $CONNECT_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  for prefix in "producer" "consumer" "producer.confluent.monitoring.interceptor" "consumer.confluent.monitoring.interceptor" ; do

  echo -e "\n# Configuration for embedded $prefix" >> $CONNECT_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "${prefix}.$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  done

  cat <<EOF >> $CONNECT_DELTA

# Confluent Schema Registry for Kafka Connect
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECT_DELTA

  # Kafka connector
  CONNECTOR_DELTA=$DEST/connector-ccloud.delta
  #echo "$CONNECTOR_DELTA"
  rm -f $CONNECTOR_DELTA
  cat <<EOF >> $CONNECTOR_DELTA
// Confluent Schema Registry for Kafka connectors
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECTOR_DELTA

  # AK command line tools
  AK_TOOLS_DELTA=$DEST/ak-tools-ccloud.delta
  #echo "$AK_TOOLS_DELTA"
  rm -f $AK_TOOLS_DELTA
  cp $CCLOUD_CONFIG_FILE $AK_TOOLS_DELTA
  chmod $PERM $AK_TOOLS_DELTA

  #log "Kafka Clients:"

  # Java (Producer/Consumer)
  JAVA_PC_CONFIG=$DEST/java_producer_consumer.delta
  #echo "$JAVA_PC_CONFIG"
  rm -f $JAVA_PC_CONFIG

  cat <<EOF >> $JAVA_PC_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(ProducerConfig.RETRIES_CONFIG, 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 300000);
props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_PC_CONFIG

  # Java (Streams)
  JAVA_STREAMS_CONFIG=$DEST/java_streams.delta
  #echo "$JAVA_STREAMS_CONFIG"
  rm -f $JAVA_STREAMS_CONFIG

  cat <<EOF >> $JAVA_STREAMS_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.streams.StreamsConfig;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(StreamsConfig.producerPrefix(ProducerConfig.RETRIES_CONFIG), 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(StreamsConfig.producerPrefix(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG), 300000);
props.put(StreamsConfig.producerPrefix(ProducerConfig.MAX_BLOCK_MS_CONFIG), 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_STREAMS_CONFIG

  # librdkafka
  LIBRDKAFKA_CONFIG=$DEST/librdkafka.delta
  #echo "$LIBRDKAFKA_CONFIG"
  rm -f $LIBRDKAFKA_CONFIG

  cat <<EOF >> $LIBRDKAFKA_CONFIG
bootstrap.servers="$BOOTSTRAP_SERVERS"
security.protocol=SASL_SSL
sasl.mechanisms=PLAIN
sasl.username="$CLOUD_KEY"
sasl.password="$CLOUD_SECRET"
schema.registry.url="$SCHEMA_REGISTRY_URL"
basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $LIBRDKAFKA_CONFIG

  # Python
  PYTHON_CONFIG=$DEST/python.delta
 # echo "$PYTHON_CONFIG"
  rm -f $PYTHON_CONFIG

  cat <<EOF >> $PYTHON_CONFIG
from confluent_kafka import Producer, Consumer, KafkaError

producer = Producer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})

consumer = Consumer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})
EOF
  chmod $PERM $PYTHON_CONFIG

  # .NET
  DOTNET_CONFIG=$DEST/dotnet.delta
  #echo "$DOTNET_CONFIG"
  rm -f $DOTNET_CONFIG

  cat <<EOF >> $DOTNET_CONFIG
using Confluent.Kafka;

var producerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { “plugin.library.paths”, “monitoring-interceptor”},
    // .... additional configuration settings
};

var consumerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { “plugin.library.paths”, “monitoring-interceptor”},
    // .... additional configuration settings
};
EOF
  chmod $PERM $DOTNET_CONFIG

  # Go
  GO_CONFIG=$DEST/go.delta
  #echo "$GO_CONFIG"
  rm -f $GO_CONFIG

  cat <<EOF >> $GO_CONFIG
import (
  "github.com/confluentinc/confluent-kafka-go/kafka"

producer, err := kafka.NewProducer(&kafka.ConfigMap{
           "bootstrap.servers": "$BOOTSTRAP_SERVERS",
          "broker.version.fallback": "0.10.0.0",
          "api.version.fallback.ms": 0,
          "sasl.mechanisms": "PLAIN",
          "security.protocol": "SASL_SSL",
          "sasl.username": "$CLOUD_KEY",
          "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })

consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
     "bootstrap.servers": "$BOOTSTRAP_SERVERS",
       "broker.version.fallback": "0.10.0.0",
       "api.version.fallback.ms": 0,
       "sasl.mechanisms": "PLAIN",
       "security.protocol": "SASL_SSL",
       "sasl.username": "$CLOUD_KEY",
       "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
       "session.timeout.ms": 6000,
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })
EOF
  chmod $PERM $GO_CONFIG

  # Node.js
  NODE_CONFIG=$DEST/node.delta
 # echo "$NODE_CONFIG"
  rm -f $NODE_CONFIG

  cat <<EOF >> $NODE_CONFIG
var Kafka = require('node-rdkafka');

var producer = new Kafka.Producer({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  });

var consumer = Kafka.KafkaConsumer.createReadStream({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  }, {}, {
    topics: '<topic name>',
    waitInterval: 0,
    objectMode: false
});
EOF
  chmod $PERM $NODE_CONFIG

  # C++
  CPP_CONFIG=$DEST/cpp.delta
  #echo "$CPP_CONFIG"
  rm -f $CPP_CONFIG

  cat <<EOF >> $CPP_CONFIG
#include <librdkafka/rdkafkacpp.h>

RdKafka::Conf *producerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (producerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // producerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    producerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Producer *producer = RdKafka::Producer::create(producerConfig, errstr);

RdKafka::Conf *consumerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (consumerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // consumerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    consumerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Consumer *consumer = RdKafka::Consumer::create(consumerConfig, errstr);
EOF
  chmod $PERM $CPP_CONFIG

  # ENV
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta
  ENV_CONFIG=$DELTA_CONFIGS_ENV
  echo "$DELTA_CONFIGS_ENV"
  rm -f $DELTA_CONFIGS_ENV

  cat <<EOF >> $ENV_CONFIG
export BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
export SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG"
export SASL_JAAS_CONFIG_PROPERTY_FORMAT="$SASL_JAAS_CONFIG_PROPERTY_FORMAT"
export REPLICATOR_SASL_JAAS_CONFIG="$REPLICATOR_SASL_JAAS_CONFIG"
export BASIC_AUTH_CREDENTIALS_SOURCE="$BASIC_AUTH_CREDENTIALS_SOURCE"
export SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL"
export CLOUD_KEY="$CLOUD_KEY"
export CLOUD_SECRET="$CLOUD_SECRET"
export KSQLDB_ENDPOINT="$KSQLDB_ENDPOINT"
export KSQLDB_BASIC_AUTH_USER_INFO="$KSQLDB_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $ENV_CONFIG

  return 0
}

# These are some duplicate functions from
#  helper.sh to decouple the script files.  In
#  the future we can work to remove this
#  duplication if necessary
function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
}
function ccloud::version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}


function check_arm64_support() {
  DIR="$1"
  DOCKER_COMPOSE_FILE="$2"
  set +e
  if [ `uname -m` = "arm64" ]
  then
    test=$(echo "$DOCKER_COMPOSE_FILE" | awk -F"/" '{ print $(NF-2)"/"$(NF-1) }')
    base_folder=$(echo $test | cut -d "/" -f 1)
    base_test=$(echo $test | cut -d "/" -f 2)
    if [ "$base_folder" == "reproduction-models" ]
    then
      base_test=${base_test#*-}
    fi

    grep "${base_test}" ${DIR}/../../scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
        logerror "🖥️ This example is not working with ARM64 !"
        log "Do you want to start test anyway ?"
        check_if_continue
        return
    fi

    grep "${base_test}" ${DIR}/../../scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        logwarn "🖥️ This example is working with ARM64 but requires emulation"
        return
    fi

    log "🖥️ This example should work natively with ARM64"
  fi
  set -e
}

function playground() {
  verbose_begin
  if [[ $(type -f playground 2>&1) =~ "not found" ]]
  then
    ../../scripts/cli/playground "$@"
  else
    $(which playground) "$@"
  fi
  verbose_end
}

function force_enable () {
  flag=$1
  env_variable=$2

  logwarn "💪 Forcing $flag ($env_variable env variable)"
  line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh$' $test_file | cut -d ":" -f 1 | tail -n1)
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
then
    trap 'rm -rf $tmp_dir' EXIT
else
    log "🐛📂 not deleting tmp dir $tmp_dir"
fi
  echo "# remove or comment those lines if you don't need it anymore" > $tmp_dir/tmp_force_enable
  echo "logwarn \"💪 Forcing $flag ($env_variable env variable) as it was set when reproduction model was created\"" >> $tmp_dir/tmp_force_enable
  echo "export $env_variable=true" >> $tmp_dir/tmp_force_enable
  cp $test_file $tmp_dir/tmp_file

  { head -n $(($line_final_source+1)) $tmp_dir/tmp_file; cat $tmp_dir/tmp_force_enable; tail -n  +$(($line_final_source+1)) $tmp_dir/tmp_file; } > $test_file
}

function load_env_variables () {
  for item in {ENABLE_CONTROL_CENTER,ENABLE_KSQLDB,ENABLE_RESTPROXY,ENABLE_JMX_GRAFANA,ENABLE_KCAT,ENABLE_CONDUKTOR,SQL_DATAGEN,ENABLE_KAFKA_NODES,ENABLE_CONNECT_NODES}
  do
    i=$(playground state get "flags.${item}")
    if [ "$i" != "" ]
    then
      log "⛳ exporting environment variable ${item}"
      export "${item}"=1
    fi
  done
}

function get_connector_paths () {
    # determining the docker-compose file from from test_file
    docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
    test_file_directory="$(dirname "${test_file}")"
    docker_compose_file="${test_file_directory}/${docker_compose_file}"

    if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
    then
      echo ""
    else
      connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    fi
}

function generate_connector_versions () {
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      return
  else
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        fi

        playground connector-plugin versions --connector-plugin $owner/$name --force-refresh
      done
  fi
}

readonly CONNECTOR_TYPE_FULLY_MANAGED="🌤️🤖fully managed"
readonly CONNECTOR_TYPE_CUSTOM="🌤️🛃custom"
readonly CONNECTOR_TYPE_SELF_MANAGED="⛈️👷self managed"
readonly CONNECTOR_TYPE_ONPREM="🌎onprem"

function get_connector_type () {
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
    if grep -q -e "fm-" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_FULLY_MANAGED"
    elif grep -q -e "custom-connector" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_CUSTOM"
    else
      echo ""
    fi
  else
    if grep -q -e "ccloud" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_SELF_MANAGED"
    elif [[ -n "$environment" ]] && [ "$environment" == "ccloud" ]
    then
      echo "$CONNECTOR_TYPE_SELF_MANAGED"
    else
      echo "$CONNECTOR_TYPE_ONPREM"
    fi
  fi
}

function handle_ccloud_connect_rest_api () {
  curl_request="$1"
  get_ccloud_connect
  if [[ -n "$verbose" ]]
  then
    log "🐞 curl command used"
    echo "$curl_request"
  fi
  eval "curl_output=\$($curl_request)"
  ret=$?
  if [ $ret -eq 0 ]
  then
      if [ "$curl_output" == "[]" ]
      then
        # logerror "No connector running"
        # exit 1
        echo ""
        return
      fi
      if echo "$curl_output" | jq 'if .error then .error | has("code") else has("error_code") end' 2> /dev/null | grep -q true
      then
        if echo "$curl_output" | jq '.error | has("code")' 2> /dev/null | grep -q true
        then
          code=$(echo "$curl_output" | jq -r .error.code)
          message=$(echo "$curl_output" | jq -r .error.message)
        else
          code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
        fi
        logerror "Command failed with error code $code"
        logerror "$message"
        exit 1
      elif echo "$curl_output" | jq 'has("errors")' 2> /dev/null | grep -q true
      then
        code=$(echo "$curl_output" | jq -r '.errors[0].status')
        message=$(echo "$curl_output" | jq -r '.errors[0].detail')
        logerror "Command failed with error code $code"
        logerror "$message"
        exit 1
      fi
  else
    logerror "❌ curl request failed with error code $ret!"
    exit 1
  fi
}

function handle_onprem_connect_rest_api () {
  curl_request="$1"
  if [[ -n "$verbose" ]]
  then
    log "🐞 curl command used"
    echo "$curl_request"
  fi
  eval "curl_output=\$($curl_request)"
  ret=$?
  if [ $ret -eq 0 ]
  then
      if [ "$curl_output" == "[]" ]
      then
        # logerror "No connector running"
        # exit 1
        echo ""
        return
      fi
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
        error_code=$(echo "$curl_output" | jq -r .error_code)
        message=$(echo "$curl_output" | jq -r .message)
        logerror "Command failed with error code $error_code"
        logerror "$message"
        exit 1
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

function display_ngrok_warning () {
  if [ -z "$NGROK_AUTH_TOKEN" ]
  then
      logerror "NGROK_AUTH_TOKEN is not set. Export it as environment variable or pass it as argument"
      logerror "Sign up at: https://dashboard.ngrok.com/signup"
      logerror "If you have already signed up, make sure your authtoken is installed."
      logerror "Your authtoken is available on your dashboard: https://dashboard.ngrok.com/get-started/your-authtoken"
      exit 1
  fi

  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    test_file=$(playground state get run.test_file)

    DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
    dir1=$(echo ${DIR_CLI%/*})
    cli_folder=$(echo ${dir1%/*})

    # trick to use different ngrok token
    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from $cli_folder/../../playground.ini does not exist!"
      exit 1
    fi
    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))

    if grep "$last_two_folders" ${cli_folder}/../../.github/workflows/ci.yml | grep -q "2️⃣"
    then
      log "😋 Using NGROK_CI_AUTH_TOKEN_BACKUP"
      export NGROK_AUTH_TOKEN=$NGROK_CI_AUTH_TOKEN_BACKUP
    fi
  fi

  if [ "$USER" == "vsaboulin" ]
  then
    return
  fi
  check_if_continue
}

function maybe_set_azure_subscription () {
  if [ ! -z "$AZURE_SUBSCRIPTION_NAME" ]
  then
    log "💙 AZURE_SUBSCRIPTION_NAME ($AZURE_SUBSCRIPTION_NAME) is set, searching for subscription id..."
    if [ ! -z "$GITHUB_RUN_NUMBER" ]
    then
      az account list --query "[?name=='$AZURE_SUBSCRIPTION_NAME']" | jq -r '.[].id'
    fi
    subscriptionId=$(az account list --query "[?name=='$AZURE_SUBSCRIPTION_NAME']" | jq -r '.[].id')
    if [ -z "$GITHUB_RUN_NUMBER" ]
    then
      log "💙 setting up account to use subscription $AZURE_SUBSCRIPTION_NAME ($subscriptionId)"
    fi
    az account set --subscription $subscriptionId
  else
    # check if confluent employee, in that case enforce AZURE_SUBSCRIPTION_NAME
    userEmail=$(az account show | jq -r '.user.name')
    if [[ $userEmail == *"confluent.io"* ]]
    then
      logerror "🔒 Confluent employee detected, please set AZURE_SUBSCRIPTION_NAME environment variable to be sure to use correct subscription !"
      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
        logerror "✨ Here is the list of subscriptions using az account list, please choose one accordingly (for GTS, it should be COPS)"
        az account list --query "[].{name:name, isDefault:isDefault, tenantId:tenantId}" | jq -r '.[] | "name: \(.name), isDefault: \(.isDefault), tenantId: \(.tenantId)"'
      fi
      exit 1
    fi

    default_subscription=$(az account list --query "[?isDefault].name" | jq -r '.[0]')
    log "💎 AZURE_SUBSCRIPTION_NAME is not set, using default subscription $default_subscription"
  fi
}

# src/lib/validations/validate_dir_exists.sh
validate_dir_exists() {
  [[ -d "$1" ]] || logerror "<$1> must be an existing directory"
}

# src/lib/validations/validate_editor_exists.sh
validate_editor_exists() {
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]
  then
    logerror "this script requires $cmd. Please install $cmd and run again."
  fi
}

# src/lib/validations/validate_file_exists.sh
validate_file_exists() {
  file="$1"
  [[ -f "$1" ]] || logerror "<$file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
}

# src/lib/validations/validate_file_exists_with_trick.sh
validate_file_exists_with_trick() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  [[ -f "$real_file" ]] || logerror "<$real_file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
}

# src/lib/validations/validate_integer.sh
validate_integer() {
  if [[ "$1" == "-1" ]] || [[ "$1" =~ ^[0-9]+$ ]]
  then
    return 0
  else
    logerror "must be an integer"
    return 1
  fi
}

# src/lib/validations/validate_minimal_cp_version.sh
validate_minimal_cp_version() {
  version="$1"
  if ! version_gt $version "4.9.99"
  then
      logerror "CP version (--tag) must be > 5.0.0"
  fi
}

# src/lib/validations/validate_not_empty.sh
validate_not_empty() {
  [[ -z "$1" ]] && logerror "must not be empty"
}

# :command.command_functions
# :command.function
playground_help_command() {
  # src/commands/help.sh
  command="${args[command]}"
  long_usage=yes

  if [[ -z "$command" ]]; then
    # No command argument, show the global help
    help_function=playground_usage
  else
    # Show the help for the requested command
    help_function="playground_${command}_usage"
  fi

  # Call the help function if it exists
  if [[ $(type -t "$help_function") ]]; then
    "$help_function"
  else
    echo "No help available for this command"
    exit 1
  fi

}

# :command.function
playground_status_command() {
  # src/commands/status.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  connector_type=$(playground state get run.connector_type)

  playground generate-fzf-find-files &
  last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
  filename=$(basename $test_file)
  last_folder=$(basename $(dirname $test_file))

  log "📊 Metrics"
  log "🚀 Number of examples ran so far: $(get_cli_metric nb_runs)"
  log "👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)"

  log "🚀 Running example "
  echo $last_two_folders/$filename

  playground open-docs --only-show-url

  if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
  then
      playground connector versions | grep -v "applying command to all connectors"
      playground connector open-docs --only-show-url
  fi

  playground connector status | grep -v "applying command to all connectors"
  playground connector show-config | grep -v "applying command to all connectors"
  playground connector show-config-parameters --only-show-file-path | grep -v "applying command to all connectors"

  playground topic list
}

# :command.function
playground_get_connector_list_command() {
  # src/commands/get-connector-list.sh
  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      get_ccloud_connect
      handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors\" --header \"authorization: Basic $authorization\""
  else
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl $security -s \"$connect_url/connectors\""
  fi

  echo "$curl_output" | jq -r '.[]' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
}

# :command.function
playground_generate_fzf_find_files_command() {
  # src/commands/generate-fzf-find-files.sh
  generate_fzf_find_files
}

# :command.function
playground_generate_tag_list_command() {
  # src/commands/generate-tag-list.sh
  function listAllTags() {

      local repo=${1}

      local page_size=${2:-100}

      [ -z "${repo}" ] && echo "Usage: listTags <repoName> [page_size]" 1>&2 && return 1

      local base_url="https://registry.hub.docker.com/v2/repositories/${repo}/tags"
      local page=1

      local res=$(curl "${base_url}?page_size=${page_size}&page=${page}" 2>/dev/null)

      local tags=$(echo ${res} | jq --raw-output '.results[].name')

      local all_tags="${tags}"

      local tag_count=$(echo ${res} | jq '.count')

      ((page_count=(${tag_count}+${page_size}-1)/${page_size}))  # ceil(tag_count / page_size)

      for page in $(seq 2 $page_count); do

          tags=$(curl "${base_url}?page_size=${page_size}&page=${page}" 2>/dev/null | jq --raw-output '.results[].name')

          all_tags="${all_tags}${tags}"

      done
      echo "${all_tags}" | sort

  }

  listAllTags "confluentinc/cp-server-connect-base" | grep -v "ubi8" | grep -v "arm64" | grep -v "amd64" | grep -v "latest" | grep -v "deb8" > $root_folder/scripts/cli/tag-list.txt
}

# :command.function
playground_generate_connector_plugin_list_command() {
  # src/commands/generate-connector-plugin-list.sh
  curl -s -S 'https://api.hub.confluent.io/api/plugins?per_page=100000' | jq '. | sort_by(.release_date) | reverse | .' > /tmp/allmanis.json

  jq -r '.[] | "\(.owner.username)/\(.name)"' /tmp/allmanis.json | sort | uniq > $root_folder/scripts/cli/confluent-hub-plugin-list.txt

  rm -f /tmp/allmanis.json
}

# :command.function
playground_generate_kafka_region_list_command() {
  # src/commands/generate-kafka-region-list.sh
  confluent kafka region list | awk -F'|' '{print $1"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "CloudID" | grep -v "\-\-\-" | grep -v '^/' > $root_folder/scripts/cli/confluent-kafka-region-list.txt

}

# :command.function
playground_get_connector_plugin_command() {
  # src/commands/get-connector-plugin.sh
  cur="${args[cur]}"

  get_plugin_list "$cur"
}

# :command.function
playground_get_ccloud_environment_list_command() {
  # src/commands/get-ccloud-environment-list.sh
  cur="${args[cur]}"

  get_ccloud_environment_list_with_fzf "$cur"
}

# :command.function
playground_get_ccloud_cluster_list_command() {
  # src/commands/get-ccloud-cluster-list.sh
  cur="${args[cur]}"

  get_ccloud_cluster_list_with_fzf "$cur"
}

# :command.function
playground_get_tag_list_command() {
  # src/commands/get-tag-list.sh
  cur="${args[cur]}"

  get_tag_list_with_fzf "$cur"
}

# :command.function
playground_get_kafka_region_list_command() {
  # src/commands/get-kafka-region-list.sh
  cur="${args[cur]}"

  get_confluent_kafka_region_list_with_fzf "$cur"
}

# :command.function
playground_get_topic_list_command() {
  # src/commands/get-topic-list.sh
  skip_connect_internal_topics="${args[--skip-connect-internal-topics]}"

  get_environment_used

  if [[ "$environment" == "ccloud" ]]
  then
    if [[ -n "$skip_connect_internal_topics" ]]
    then
      set +e
      confluent kafka topic list | grep -v "connect-" | grep -v "_confluent-monitoring" | grep -v "_confluent-command" | awk '{if(NR>2) print $1}'
      set -e
    else
      set +e
      confluent kafka topic list | awk '{if(NR>2) print $1}'
      set -e
    fi
  else
    # trick to be faster
    docker exec broker ls /var/lib/kafka/data > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
      if [[ -n "$skip_connect_internal_topics" ]]
      then
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "connect-" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      else
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      fi
    fi
  fi
}

# :command.function
playground_get_subject_list_command() {
  # src/commands/get-subject-list.sh
  get_sr_url_and_security
  deleted="${args[--deleted]}"

  if [[ -n "$deleted" ]]
  then
      curl $sr_security -s "${sr_url}/subjects?deleted=true" | jq -r '.[]'
  else
      curl $sr_security -s "${sr_url}/subjects" | jq -r '.[]'
  fi
}

# :command.function
playground_get_examples_list_with_fzf_command() {
  # src/commands/get-examples-list-with-fzf.sh
  without_repro="${args[--without-repro]}"
  sink_only="${args[--sink-only]}"
  ccloud_only="${args[--ccloud-only]}"

  connector_only="${args[--connector-only]}"
  repro_only="${args[--repro-only]}"
  environment_only="${args[--environment-only]}"
  fully_managed_connector_only="${args[--fully-managed-connector-only]}"
  ksql_only="${args[--ksql-only]}"
  schema_registry_only="${args[--schema-registry-only]}"
  rest_proxy_only="${args[--rest-proxy-only]}"
  other_playgrounds_only="${args[--other-playgrounds-only]}"

  cur="${args[cur]}"

  if [[ -n "$without_repro" ]] && [[ -n "$sink_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only ]
      then
          generate_get_examples_list_with_fzf_without_repro_sink_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only"
      return
  fi

  if [[ -n "$without_repro" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_without_repro ]
      then
          generate_get_examples_list_with_fzf_without_repro
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro"
      return
  fi

  if [[ -n "$ccloud_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only ]
      then
          generate_get_examples_list_with_fzf_ccloud_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only"
      return
  fi

  if [[ -n "$connector_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_connector_only ]
      then
          generate_get_examples_list_with_fzf_connector_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_connector_only"
      return
  fi

  if [[ -n "$repro_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only ]
      then
          generate_get_examples_list_with_fzf_repro_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_repro_only"
      return
  fi

  if [[ -n "$environment_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_environment_only ]
      then
          generate_get_examples_list_with_fzf_environment_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_environment_only"
      return
  fi

  if [[ -n "$fully_managed_connector_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only ]
      then
          generate_get_examples_list_with_fzf_fully_managed_connector_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only"
      return
  fi

  if [[ -n "$ksql_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only ]
      then
          generate_get_examples_list_with_fzf_ksql_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only"
      return
  fi

  if [[ -n "$schema_registry_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only ]
      then
          generate_get_examples_list_with_fzf_schema_registry_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only"
      return
  fi

  if [[ -n "$rest_proxy_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only ]
      then
          generate_get_examples_list_with_fzf_rest_proxy_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only"
      return
  fi

  if [[ -n "$other_playgrounds_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only ]
      then
          generate_get_examples_list_with_fzf_other_playgrounds_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only"
      return
  fi

  if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_all ]
  then
      generate_get_examples_list_with_fzf
  fi
  get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_all"
}

# :command.function
playground_get_zip_or_jar_with_fzf_command() {
  # src/commands/get-zip-or-jar-with-fzf.sh
  cur="${args[cur]}"
  type="${args[--type]}"

  get_zip_or_jar_with_fzf "$cur" "$type"
}

# :command.function
playground_get_any_file_with_fzf_command() {
  # src/commands/get-any-file-with-fzf.sh
  cur="${args[cur]}"

  find $root_folder -type f ! -path '*/\.*' > /tmp/get_any_files_with_fzf
  get_any_files_with_fzf "$cur"
}

# :command.function
playground_get_playground_repro_export_with_fzf_command() {
  # src/commands/get-playground-repro-export-with-fzf.sh
  cur="${args[cur]}"

  get_playground_repro_export_with_fzf "$cur"
}

# :command.function
playground_get_predefined_schemas_command() {
  # src/commands/get-predefined-schemas.sh
  cur="${args[cur]}"

  get_predefined_schemas_with_fzf "$cur"
}

# :command.function
playground_update_readme_command() {
  # src/commands/update-readme.sh
  tags="${args[--tags]}"

  set +e
  tmp_dir="/tmp/update-readme"
  rm -rf $tmp_dir
  mkdir -p "$tmp_dir"
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  cd ${root_folder}

  content_template_file=./docs/content-template.md
  content_file=./docs/content.md
  content_tmp_file=$tmp_dir/content.md
  badges_template_file=./docs/badges-template.md
  badges_file=./docs/badges.md
  badges_tmp_file=$tmp_dir/badges.md
  gh_msg_file=$tmp_dir/gh.txt
  gh_msg_file_intro=$tmp_dir/gh_intro.txt

  cp $content_template_file $content_file
  cp $badges_template_file $badges_file

  curl -s https://raw.githubusercontent.com/vdesabou/kafka-docker-playground-connect/master/README.md -o $tmp_dir/README.txt

  ci_folder="$tmp_dir/ci"
  log "Getting ci result files"
  rm -rf "$ci_folder"
  mkdir -p "$ci_folder"
  aws s3 cp --only-show-errors s3://kafka-docker-playground/ci/ "${ci_folder}/" --recursive --no-progress --region us-east-1

  test_list=$(grep "🚀" ${root_folder}/.github/workflows/ci.yml | cut -d '"' -f 2 | tr '\n' ' ')
  declare -a TEST_FAILED
  declare -a TEST_SUCCESS
  nb_total_tests=0
  nb_connector_tests=0
  nb_total_fail=0
  nb_total_success=0
  for test in $test_list
  do
    nb_tests=0
    nb_fail=0
    nb_success=0
    TEST_FAILED=()
    TEST_SUCCESS=()
    TEST_SKIPPED=()
    rm -f ${gh_msg_file}
    touch ${gh_msg_file}
    rm -f ${gh_msg_file_intro}
    touch ${gh_msg_file_intro}
    gh_issue_number=""
    if [ ! -d $test ]
    then
      # logwarn "####################################################"
      # logwarn "skipping test $test, not a directory"
      # logwarn "####################################################"
      continue
    fi
    log "################################"
    log "### 📁 ${test}"

    for script in ${test}/*.sh
    do
      script_name=$(basename ${script})
      if [[ "$script_name" = "stop.sh" ]]
      then
        continue
      fi

      # check for ignored scripts in scripts/tests-ignored.txt
      grep "$script_name" ${root_folder}/scripts/tests-ignored.txt > /dev/null
      if [ $? = 0 ]
      then
        log "####################################################"
        log "⏭ skipping $script_name in test $test"
        log "####################################################"
        continue
      fi

      # check for scripts containing "repro"
      if [[ "$script_name" == *"repro"* ]]
      then
        log "####################################################"
        log "⏭ skipping reproduction model $script_name in test $test"
        log "####################################################"
        continue
      fi

      connector_path=""
      if [[ "$test" == "connect"* ]]
      then
        # if it is a connector test, get connector_path
        docker_compose_file=$(grep "start-environment" "$script" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
        if [ "${docker_compose_file}" != "" ] && [ -f "${test}/${docker_compose_file}" ]
        then
          connector_path=$(grep "CONNECT_PLUGIN_PATH" "${test}/${docker_compose_file}" | grep -v KSQL_CONNECT_PLUGIN_PATH | cut -d "/" -f 5)
          # remove any extra comma at the end (when there are multiple connectors used, example S3 source)
          connector_path=$(echo "$connector_path" | cut -d "," -f 1)
        fi
      fi

      log "## 📄 ${script_name}"

      for image_version in $tags
      do
        let "nb_tests++"
        let "nb_total_tests++"
        image_version_no_dot=$(echo ${image_version} | sed 's/\.//g')
        time_day=""
        time_day_hour=""
        version=""
        release_date=""
        if [ "$connector_path" != "" ]
        then
          if [ "$connector_path" = "confluentinc-kafka-connect-jdbc" ]
          then
            if ! version_gt ${image_version} "5.9.0"
            then
              # for version less than 6.0.0, use JDBC with same version
              # see https://github.com/vdesabou/kafka-docker-playground/issues/221
              version=${image_version}
            else
              version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
              release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
            fi
          else
            version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
            release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
          fi
        fi
        if [ "$release_date" = "null" ]
        then
          release_date=""
        fi
        testdir=$(echo "$test" | sed 's/\//-/g')
        ci_file="${ci_folder}/${image_version}-${testdir}-${version}-${script_name}"

        if [ -f ${ci_file} ]
        then
          last_execution_time=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 2)
          status=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 3)
          gh_run_id=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 4)

          if [ ! -f $tmp_dir/${gh_run_id}_1.json ]
          then
            for i in {1..10}
            do

                # https://docs.github.com/en/rest/actions/workflow-runs?apiVersion=2022-11-28#get-a-workflow-run
                curl_output=$(curl -s -o $tmp_dir/${gh_run_id}_${i}.json -w %{http_code} -H "Accept: application/vnd.github+json" -H "X-GitHub-Api-Version: 2022-11-28"  -H "Authorization: Bearer $GH_TOKEN" "https://api.github.com/repos/vdesabou/kafka-docker-playground/actions/runs/${gh_run_id}/jobs?per_page=50&page=${i}")
                if [ $curl_output -ne 200 ]
                then
                    logerror "❌ curl request <https://api.github.com/repos/vdesabou/kafka-docker-playground/actions/runs/${gh_run_id}/jobs?per_page=50&page=${i}> failed with error code $curl_output!"
                    cat "/tmp/${gh_run_id}_${i}.json"
                    continue
                fi
            done
          fi

          v=$(echo $image_version | sed -e 's/\./[.]/g')
          for i in {1..10}
          do
            html_url=$(cat "$tmp_dir/${gh_run_id}_${i}.json" | jq ".jobs |= map(select(.name | test(\"${v}.*${test}\")))" | jq '[.jobs | .[] | {name: .name, html_url: .html_url }]' | jq '.[0].html_url' | sed -e 's/^"//' -e 's/"$//')
            if [ "$html_url" != "" ] && [ "$html_url" != "null" ]; then

                break
            fi
          done

          if [ "$html_url" = "" ] || [ "$html_url" = "null" ]
          then
            logerror "Could not retrieve job url! FIXTTHIS: NOT Forcing re-run for next time..."
            # s3_file="s3://kafka-docker-playground/ci/${image_version}-${testdir}-${version}-${script_name}"
            # aws s3 rm $s3_file --region us-east-1
          fi
        else
          logerror "result_file: ${ci_file} does not exist !"
          continue
        fi

        if [ "$last_execution_time" != "" ]
        then
          if [[ "$OSTYPE" == "darwin"* ]]
          then
            time_day=$(date -r $last_execution_time "+%Y-%m-%d")
            time_day_hour=$(date -r $last_execution_time "+%Y-%m-%d %H:%M")
          else
            time_day=$(date -d @$last_execution_time "+%Y-%m-%d")
            time_day_hour=$(date -d @$last_execution_time "+%Y-%m-%d %H:%M")
          fi
        fi

        connector_version=""
        if [ "$version" != "" ]
        then
          if [ "$release_date" != "" ]
          then
            connector_version=" 🔢 Connector v$version (📅 release date $release_date)"
          else
            connector_version=" 🔢 Connector v$version"
          fi
        fi
        if [ "$status" == "failure" ]
        then
          let "nb_fail++"
          let "nb_total_fail++"
          TEST_FAILED[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-red)]($html_url)"
          echo -e "🔥 CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "🔥 CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        elif [[ "$status" = known_issue* ]]
        then
          let "nb_success++"
          let "nb_total_success++"
          known_issue_gh_issue_number=$(echo "$status" | cut -d "#" -f 2)
          TEST_SUCCESS[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/known%20issue-CP%20$image_version-orange)](https://github.com/vdesabou/kafka-docker-playground/issues/$known_issue_gh_issue_number)"

          echo -e "💀 known issue 🐞 [#${known_issue_gh_issue_number}](https://github.com/vdesabou/kafka-docker-playground/issues/${known_issue_gh_issue_number}) CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "💀 known issue 🐞 [#${known_issue_gh_issue_number}](https://github.com/vdesabou/kafka-docker-playground/issues/${known_issue_gh_issue_number}) CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url"
        elif [ "$status" == "skipped" ]
        then
          let "nb_success++"
          let "nb_total_success++"
          TEST_SKIPPED[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/skipped-CP%20$image_version-lightgrey)]($html_url)"
          echo -e "⏭ SKIPPED CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "⏭ SKIPPED CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        else
          let "nb_success++"
          let "nb_total_success++"
          TEST_SUCCESS[$image_version_no_dot]="$html_url"
          echo -e "👍 CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "👍 CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        fi
      done #end image_version
    done #end script

    # GH issues
    if [ "$html_url" != "" ]
    then
      t=$(echo ${testdir} | sed 's/-/\//')
      title="🔥 ${t}"
      log "Number of successful tests: $nb_success/${nb_tests}"
      if [ ${nb_fail} -gt 0 ]
      then
        gh issue list --limit 500 | grep "$title" > /dev/null
        if [ $? != 0 ]
        then
          echo -e "🆕💥 New issue !\n" >> ${gh_msg_file_intro}
          msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
          log "Creating GH issue with title $title"
          gh issue create --title "$title" --body "$msg" --assignee vdesabou --label "new 🆕"
        else
          echo -e "🤦‍♂️💥 Still failing !\n" >> ${gh_msg_file_intro}
          msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
          log "GH issue with title $title already exist, adding comment..."
          issue_number=$(gh issue list --limit 500 | grep "$title" | awk '{print $1;}')
          gh issue comment ${issue_number} --body "$msg"
          gh issue edit ${issue_number} --add-label "CI failing 🔥" --remove-label "new 🆕"
        fi
        gh_issue_number=$(gh issue list --limit 500 | grep "$title" | awk '{print $1;}')
      fi
      if [ ${nb_success} -eq ${nb_tests} ]
      then
        # if all scripts in tests are now successful, close the issue
        gh issue list --limit 500 | grep "$title" > /dev/null
        if [ $? = 0 ]
        then
          issue_number=$(gh issue list --limit 500 | grep "$title" | head -1 | awk '{print $1;}')
          echo -e "👍✅ Issue fixed !\n" >> ${gh_msg_file_intro}
          msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
          gh issue comment ${issue_number} --body "$msg"
          log "Closing GH issue #${issue_number} with title $title"
          gh issue close ${issue_number}
        fi
      fi
    fi

    ci=""
    ci_nb_fail=0
    ci_nb_skipped=0
    nb_image_versions=0
    for image_version in $tags
    do
      let "nb_image_versions++"
      image_version_no_dot=$(echo ${image_version} | sed 's/\.//g')
      if [ "${TEST_FAILED[$image_version_no_dot]}" != "" ]
      then
        gh_issue_number=$(echo $gh_issue_number|tr -d '\n')
        if [ "${gh_issue_number}" != "" ]
        then
          ci="$ci [![issue $gh_issue_number](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-red)](https://github.com/vdesabou/kafka-docker-playground/issues/$gh_issue_number)"
        else
          ci="$ci ${TEST_FAILED[$image_version_no_dot]}"
        fi
        let "ci_nb_fail++"
      elif [ "${TEST_SKIPPED[$image_version_no_dot]}" != "" ]
      then
        ci="$ci ${TEST_SKIPPED[$image_version_no_dot]}"
        let "ci_nb_skipped++"
      elif [ "${TEST_SUCCESS[$image_version_no_dot]}" != "" ]
      then
        ci="$ci [![CP $image_version](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-green)](${TEST_SUCCESS[$image_version_no_dot]})"
      else
        logerror "TEST_SUCCESS, TEST_SKIPPED and TEST_FAILED are all empty !"
      fi
    done

    if [ ${ci_nb_fail} -eq 0 ] && [ ${ci_nb_skipped} -eq 0 ]
    then
        ci="[![CI ok](https://img.shields.io/badge/$nb_success/$nb_tests-ok!-green)]($html_url)"
    elif [ ${ci_nb_fail} -eq ${nb_image_versions} ]
    then
        ci="[![CI fail](https://img.shields.io/badge/$nb_success/$nb_tests-fail!-red)](https://github.com/vdesabou/kafka-docker-playground/issues/$gh_issue_number)"
    fi

    if [ "$connector_path" != "" ]
    then
      version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      license=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 4 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      owner=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 5 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      documentation_url=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 7 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//' | sed 's/.*(\(.*\))/\1/')
      if [ "$release_date" = "null" ]
      then
        release_date="unknown"
      fi

      # if [ "$license" = "Confluent Software Evaluation License" ]
      # then
      #   type="![license](https://img.shields.io/badge/-confluent%20subscription-black)"
      # elif [ "$license" = "Apache License 2.0" ] || [ "$license" = "Apache 2.0" ] || [ "$license" = "Apache License, Version 2.0" ] || [ "$license" = "The Apache License, Version 2.0" ]
      # then
      #   type="![license](https://img.shields.io/badge/-open%20source-black)"
      # else
      #   license=$(echo $licence | tr '[:upper:]' '[:lower:]')
      #   #typeencoded=$(urlencode $license)
      #   typeencoded=$(echo "$licence" | sed -e 's/ /%20/g')
      #   type="![license](https://img.shields.io/badge/-$typeencoded-black)"
      # fi
      owner_badge=""
      if [ "$owner" != "" ]
      then
        if [[ "$owner" != *"Confluent"* ]]
        then
          ownerencoded=$(echo "$owner" | sed -e 's/ /%20/g')
          owner_badge="![owner](https://img.shields.io/badge/-$ownerencoded-blue)"
        fi
      fi

      versionencoded=$(urlencode $version)
      versionencoded=$(echo $versionencoded | tr "-" "_")
      release_date_encoded=$(urlencode $release_date)
      release_date_encoded=$(echo $release_date_encoded | tr "-" "_")
      connector_badge="[![version](https://img.shields.io/badge/v-$versionencoded%20($release_date_encoded)-pink)]($documentation_url)"

      # M1 Mac arm64 support
      arm64=""
      grep "${test}" ${root_folder}/scripts/arm64-support-with-emulation.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-emulation%20required-orange)"
      fi

      grep "${test}" ${root_folder}/scripts/arm64-support-none.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-not%20working-red)"
      fi

      if [ "$arm64" == "" ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-native%20support-green)"
      fi

      let "nb_connector_tests++"
      sed -e "s|:${test}:|\&nbsp; $connector_badge $owner_badge $arm64 $ci |g" \
          $content_file > $content_tmp_file

      cp $content_tmp_file $content_file
    else
      arm64=""
      grep "${test}" ${root_folder}/scripts/arm64-support-with-emulation.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-emulation%20required-orange)"
      fi

      grep "${test}" ${root_folder}/scripts/arm64-support-none.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-not%20working-red)"
      fi

      if [ "$arm64" == "" ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-native%20support-green)"
      fi

      sed -e "s|:${test}:|\&nbsp; $arm64 $ci |g" \
          $content_file > $content_tmp_file

      cp $content_tmp_file $content_file
    fi
  done #end test_list

  cp_version_tested=""
  for image_version in $tags
  do
    cp_version_tested="$cp_version_tested%20$image_version"
  done

  tests_color="green"
  if [ $nb_total_fail -gt 0 ]; then
    tests_color="red"
  fi
  if [[ "$OSTYPE" == "darwin"* ]]
  then
    last_run=$(date "+%Y-%m-%d %H:%M")
  else
    last_run=$(date "+%Y-%m-%d %H:%M")
  fi
  last_run=${last_run// /%20}
  last_run=${last_run//-/--}

  # handle shields badges
  sed -e "s|:nb_total_success:|$nb_total_success|g" \
      -e "s|:nb_total_tests:|$nb_total_tests|g" \
      -e "s|:nb_connector_tests:|$nb_connector_tests|g" \
      -e "s|:cp_version_tested:|$cp_version_tested|g" \
      -e "s|:tests_color:|$tests_color|g" \
      -e "s|:last_run:|$last_run|g" \
      $badges_file > $badges_tmp_file
  cp $badges_tmp_file $badges_file

  # Create docs/introduction.md
  cat ./docs/introduction-header.md > ./docs/introduction.md
  cat $badges_file >> ./docs/introduction.md
  echo "" >> ./docs/introduction.md
  cat ./docs/introduction-footer.md >> ./docs/introduction.md

}

# :command.function
playground_bashly_reload_command() {
  # src/commands/bashly-reload.sh
  cd $root_folder/scripts/cli
  bashly generate
  rm -f $root_folder/scripts/cli/completions.bash
  bashly add completions_script
  cd - > /dev/null
}

# :command.function
playground_state_show_command() {
  # src/commands/state/show.sh
  # Using the standard library (lib/ini.sh) to show the entire config file
  if [ ! -f "$root_folder/playground.ini" ]
  then
      logerror "$root_folder/playground.ini does not exist !"
      logerror "Make sure to always use the CLI to run examples"
      exit 1
  fi
  ini_load $root_folder/playground.ini
  ini_show
}

# :command.function
playground_state_get_command() {
  # src/commands/state/get.sh
  # Using the standard library (lib/ini.sh) to show a value from the config
  if [ ! -f "$root_folder/playground.ini" ]
  then
      logerror "$root_folder/playground.ini does not exist !"
      logerror "Make sure to always use the CLI to run examples"
      exit 1
  fi
  ini_load $root_folder/playground.ini

  key="${args[key]:-}"
  value=${ini[$key]:-}

  if [[ "$value" ]]
  then
    echo "$value"
  else
    echo ""
  fi
}

# :command.function
playground_state_set_command() {
  # src/commands/state/set.sh
  # Using the standard library (lib/ini.sh) to store a value to the config
  if [ ! -f $root_folder/playground.ini ]
  then
      touch $root_folder/playground.ini
  fi
  set -e
  ini_load $root_folder/playground.ini

  key="${args[key]}"
  value="${args[value]}"

  ini["$key"]="$value"
  ini_save $root_folder/playground.ini
}

# :command.function
playground_state_del_command() {
  # src/commands/state/del.sh
  # Using the standard library (lib/ini.sh) to delete a value from the config
  if [ ! -f "$root_folder/playground.ini" ]
  then
      logerror "$root_folder/playground.ini does not exist !"
      logerror "Make sure to always use the CLI to run examples"
      exit 1
  fi
  set -e
  ini_load $root_folder/playground.ini

  key="${args[key]}"
  unset "ini[$key]"

  ini_save $root_folder/playground.ini

}

# :command.function
playground_config_show_command() {
  # src/commands/config/show.sh
  # Using the standard library (lib/ini.sh) to show the entire config file
  if [ ! -f "$root_folder/playground_config.ini" ]
  then
      logerror "$root_folder/playground_config.ini does not exist !"
      logerror "Make sure to always use the CLI to run examples"
      exit 1
  fi
  ini_load $root_folder/playground_config.ini
  ini_show
}

# :command.function
playground_config_get_command() {
  # src/commands/config/get.sh
  # Using the standard library (lib/ini.sh) to show a value from the config
  if [ ! -f "$root_folder/playground_config.ini" ]
  then
      # set defaults
      playground config set editor code > /dev/null 2>&1
      playground config set clipboard true > /dev/null 2>&1
      playground config set folder_zip_or_jar ~ > /dev/null 2>&1
  fi
  ini_load $root_folder/playground_config.ini

  key="${args[key]:-}"
  value=${ini[$key]:-}

  if [[ "$value" ]]
  then
    echo "$value"
  else
    echo ""
  fi
}

# :command.function
playground_config_set_command() {
  # src/commands/config/set.sh
  # Using the standard library (lib/ini.sh) to store a value to the config
  if [ ! -f $root_folder/playground_config.ini ]
  then
      touch $root_folder/playground_config.ini
  fi
  set -e
  ini_load $root_folder/playground_config.ini

  key="${args[key]}"
  value="${args[value]}"

  ini["$key"]="$value"
  ini_save $root_folder/playground_config.ini
}

# :command.function
playground_config_editor_command() {
  # src/commands/config/editor.sh
  log "🔖 configuring editor with ${args[editor]}"
  playground config set editor "${args[editor]}"
}

# :command.function
playground_config_folder_zip_or_jar_command() {
  # src/commands/config/folder_zip_or_jar.sh
  # Convert the space delimited string to an array
  folders=''
  eval "folders=(${args[folder]:-})"

  folder_list=""
  for i in "${folders[@]}"
  do
      folder_list="$folder_list,$i"
  done

  log "📁 configuring folder_zip_or_jar with $folder_list"
  playground config set folder_zip_or_jar "$folder_list"
}

# :command.function
playground_config_clipboard_command() {
  # src/commands/config/clipboard.sh
  if [[ "$OSTYPE" != "darwin"* ]]
  then
      logerror "❌ clipboard is only working on MacOS"
      exit 1
  fi

  log "📋 configuring clipboard with ${args[enabled]}"
  playground config set clipboard "${args[enabled]}"
}

# :command.function
playground_run_command() {
  # src/commands/run.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  environment="${args[--environment]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"

  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_rest_proxy="${args[--enable-rest-proxy]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  cluster_type="${args[--cluster-type]}"
  cluster_cloud="${args[--cluster-cloud]}"
  cluster_region="${args[--cluster-region]}"
  cluster_environment="${args[--cluster-environment]}"
  cluster_name="${args[--cluster-name]}"
  cluster_creds="${args[--cluster-creds]}"
  cluster_schema_registry_creds="${args[--cluster-schema-registry-creds]}"
  force_interactive_re_run="${args[--force-interactive-re-run]}"
  force_interactive_repro="${args[--force-interactive-repro]}"

  interactive_mode=0

  if [[ -n "$force_interactive_repro" ]]
  then
    interactive_mode=1
  fi

  declare -a array_flag_list=()
  if [[ -n "$force_interactive_re_run" ]]
  then
    interactive_mode=1
  fi

  if [[ ! -n "$test_file" ]]
  then
    interactive_mode=1
    display_interactive_menu_categories
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ $test_file == *"ccloud"* ]]
  then
    verify_installed "confluent"
  fi

  playground state set run.test_file "$test_file"
  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")

  docs_available=1
  set +e
  playground open-docs --only-show-url > /dev/null 2>&1
  if [ $? -eq 1 ]
  then
    docs_available=0
  fi
  set -e
  if [[ -n "$tag" ]]
  then
    if [[ $tag == *"@"* ]]
    then
      tag=$(echo "$tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--tag=$tag")
    export TAG=$tag
  fi

  if [[ -n "$environment" ]]
  then
    get_connector_paths
    if [ "$connector_paths" == "" ] && [ "$environment" != "plaintext" ]
    then
      logerror "❌ using --environment is only supported with connector examples"
      exit 1
    fi

    if [ "$environment" != "plaintext" ]
    then
      array_flag_list+=("--environment=$environment")
      export PLAYGROUND_ENVIRONMENT=$environment
    fi
  fi

  if [[ -n "$connector_tag" ]]
  then
    if [ "$connector_tag" == " " ]
    then
      get_connector_paths
      if [ "$connector_paths" == "" ]
      then
          logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
          exit 1
      else
          connector_tags=""
          for connector_path in ${connector_paths//,/ }
          do
            full_connector_name=$(basename "$connector_path")
            owner=$(echo "$full_connector_name" | cut -d'-' -f1)
            name=$(echo "$full_connector_name" | cut -d'-' -f2-)

            if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
            then
              # happens when plugin is not coming from confluent hub
              logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
            fi

            ret=$(choose_connector_tag "$owner/$name")
            connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

            if [ -z "$connector_tags" ]; then
              connector_tags="$connector_tag"
            else
              connector_tags="$connector_tags,$connector_tag"
            fi
          done

          connector_tag="$connector_tags"
      fi
    fi

    array_flag_list+=("--connector-tag=$connector_tag")
    export CONNECTOR_TAG="$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-zip=$connector_zip")
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-jar=$connector_jar")
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-ksqldb is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-ksqldb")
    export ENABLE_KSQLDB=true
  fi

  if [[ -n "$enable_rest_proxy" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-rest-proxy is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-rest-proxy")
    export ENABLE_RESTPROXY=true
  fi

  if [[ -n "$enable_c3" ]]
  then
    array_flag_list+=("--enable-control-center")
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    array_flag_list+=("--enable-conduktor")
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-multiple-broker is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-multiple-broker")
    export ENABLE_KAFKA_NODES=true
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-multiple-connect-workers is not supported with ccloud examples"
      exit 1
    fi

    array_flag_list+=("--enable-multiple-connect-workers")
    export ENABLE_CONNECT_NODES=true

    # determining the docker-compose file from from test_file
    docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_file="${test_file_directory}/${docker_compose_file}"
    if [ -f $docker_compose_file ]
    then
      cp $docker_compose_file /tmp/playground-backup-docker-compose.yml
      yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
      yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
      cp /tmp/playground-backup-docker-compose.yml $docker_compose_file
    fi
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-jmx-grafana"
      exit 1
    fi
    array_flag_list+=("--enable-jmx-grafana")
    export ENABLE_JMX_GRAFANA=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    array_flag_list+=("--enable-kcat")
    export ENABLE_KCAT=true
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    array_flag_list+=("--enable-sql-datagen")
    export SQL_DATAGEN=true
  fi

  if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_name" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
  then
    playground state set ccloud.suggest_use_previous_example_ccloud "0"
    if [ ! -z "$CLUSTER_TYPE" ]
    then
      log "🙈 ignoring environment variable CLUSTER_TYPE as one of the flags is set"
      unset CLUSTER_TYPE
    fi
    if [ ! -z "$CLUSTER_CLOUD" ]
    then
      log "🙈 ignoring environment variable CLUSTER_CLOUD as one of the flags is set"
      unset CLUSTER_CLOUD
    fi
    if [ ! -z "$CLUSTER_REGION" ]
    then
      log "🙈 ignoring environment variable CLUSTER_REGION as one of the flags is set"
      unset CLUSTER_REGION
    fi
    if [ ! -z "$ENVIRONMENT" ]
    then
      log "🙈 ignoring environment variable ENVIRONMENT as one of the flags is set"
      unset ENVIRONMENT
    fi
    if [ ! -z "$CLUSTER_NAME" ]
    then
      log "🙈 ignoring environment variable CLUSTER_NAME as one of the flags is set"
      unset CLUSTER_NAME
    fi
    if [ ! -z "$CLUSTER_CREDS" ]
    then
      log "🙈 ignoring environment variable CLUSTER_CREDS as one of the flags is set"
      unset CLUSTER_CREDS
    fi

    if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
    then
      log "🙈 ignoring environment variable SCHEMA_REGISTRY_CREDS as one of the flags is set"
      unset SCHEMA_REGISTRY_CREDS
    fi
  else
    playground state set ccloud.suggest_use_previous_example_ccloud "1"
  fi

  if [[ -n "$cluster_type" ]]
  then
    array_flag_list+=("--cluster-type $cluster_type")
    export CLUSTER_TYPE=$cluster_type
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_TYPE" ]
    then
      export CLUSTER_TYPE="basic"
    fi
  fi

  if [[ -n "$cluster_cloud" ]]
  then
    array_flag_list+=("--cluster-cloud $cluster_cloud")
    export CLUSTER_CLOUD=$cluster_cloud
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_CLOUD" ]
    then
      export CLUSTER_CLOUD="aws"
    fi
  fi

  if [[ -n "$cluster_region" ]]
  then
    array_flag_list+=("--cluster-region $cluster_region")
    export CLUSTER_REGION=$cluster_region
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_REGION" ]
    then
      case "${CLUSTER_CLOUD}" in
        aws)
          export CLUSTER_REGION="eu-west-2"
        ;;
        azure)
          export CLUSTER_REGION="westeurope"
        ;;
        gcp)
          export CLUSTER_REGION="europe-west2"
        ;;
      esac
    fi
  fi

  if [[ -n "$cluster_environment" ]]
  then
    if [[ $cluster_environment == *"@"* ]]
    then
      cluster_environment=$(echo "$cluster_environment" | cut -d "@" -f 2)
    fi
    if [[ $cluster_environment == *"/"* ]]
    then
      cluster_environment=$(echo "$cluster_environment" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
    fi
    array_flag_list+=("--cluster-environment $cluster_environment")
    export ENVIRONMENT=$cluster_environment
  fi

  if [[ -n "$cluster_name" ]]
  then
    if [[ $cluster_name == *"@"* ]]
    then
      cluster_name=$(echo "$cluster_name" | cut -d "@" -f 2)
    fi
    if [[ $cluster_name == *"/"* ]]
    then
      cluster_name=$(echo "$cluster_name" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
    fi
    array_flag_list+=("--cluster-name $cluster_name")
    export CLUSTER_NAME=$cluster_name
  fi

  if [[ -n "$cluster_creds" ]]
  then
    array_flag_list+=("--cluster-creds $cluster_creds")
    export CLUSTER_CREDS=$cluster_creds
  fi

  if [[ -n "$cluster_schema_registry_creds" ]]
  then
    array_flag_list+=("--cluster-schema-registry-creds $cluster_schema_registry_creds")
    export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
  fi

  if [[ -n "$open" ]]
  then
    editor=$(playground config get editor)
    if [ "$editor" != "" ]
    then
      log "📖 Opening ${test_file} using configured editor $editor"
      $editor ${test_file}
      check_if_continue
    else
        if [[ $(type code 2>&1) =~ "not found" ]]
        then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
            exit 1
        else
            log "📖 Opening ${test_file} with code (default) - you can change editor by using playground config editor <editor>"
            code ${test_file}
            check_if_continue
        fi
    fi
  fi

  if [ $interactive_mode == 1 ]
  then
    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi
    RED='\033[0;31m'
    YELLOW='\033[0;33m'
    CYAN='\033[0;36m'
    GREEN='\033[0;32m'
    NC='\033[0m' # No Color

    if [[ -n "$force_interactive_repro" ]]
    then
      MENU_LETS_GO="🚀 Run the reproduction model !" #0
    else
      MENU_LETS_GO="🚀 Run the example !" #0
    fi

    MENU_PROBLEM="❌ The example cannot be executed, check error(s) 👉" #1
    readonly MENU_OPEN_FILE="📖 Open the file in text editor"
    set +e
    if [[ $(type -f open 2>&1) =~ "not found" ]]
    then
      MENU_OPEN_DOCS="🌐 Show link to the docs"
    else
      MENU_OPEN_DOCS="🌐 Open the docs in browser"
    fi
    set -e
    # readonly MENU_SEPARATOR="--------------------------------------------------" #4

    MENU_TAG="🎯 CP version $(printf '%*s' $((${MAX_LENGTH}-13-${#MENU_TAG})) ' ') --tag" #5
    MENU_CONNECTOR_TAG="🔗 Connector version $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_CONNECTOR_TAG})) ' ') --connector-tag"
    MENU_CONNECTOR_ZIP="🤐 Connector zip $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_ZIP})) ' ') --connector-zip"
    MENU_CONNECTOR_JAR="🤎 Connector jar $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_JAR})) ' ') --connector-jar"
    MENU_ENVIRONMENT="🔐 Environment $(printf '%*s' $((${MAX_LENGTH}-14-${#MENU_ENVIRONMENT})) ' ') --environment"

    readonly MENU_SEPARATOR="--------------------------------------------------" #10

    MENU_ENABLE_KSQLDB="🎏 Enable ksqlDB $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_ENABLE_KSQLDB})) ' ') --enable-ksqldb" #11
    MENU_ENABLE_C3="💠 Enable Control Center $(printf '%*s' $((${MAX_LENGTH}-24-${#MENU_ENABLE_C3})) ' ') --enable-control-center"
    MENU_ENABLE_CONDUKTOR="🐺 Enable Conduktor Platform $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_ENABLE_CONDUKTOR})) ' ') --enable-conduktor"
    MENU_ENABLE_RP="🧲 Enable Rest Proxy $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_ENABLE_RP})) ' ') --enable-rest-proxy"

    MENU_ENABLE_GRAFANA="📊 Enable Grafana $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_ENABLE_GRAFANA})) ' ') --enable-jmx-grafana"
    MENU_ENABLE_BROKERS="3️⃣  Enabling multiple brokers $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_ENABLE_BROKERS})) ' ') --enable-multiple-broker"
    MENU_ENABLE_CONNECT_WORKERS="🥉 Enabling multiple connect workers $(printf '%*s' $((${MAX_LENGTH}-36-${#MENU_ENABLE_CONNECT_WORKERS})) ' ') --enable-multiple-connect-workers"
    MENU_ENABLE_KCAT="🐈 Enabling kcat $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_ENABLE_KCAT})) ' ') --enable-kcat"
    MENU_ENABLE_SQL_DATAGEN="🌪️  Enable SQL Datagen injection $(printf '%*s' $((${MAX_LENGTH}-33-${#MENU_ENABLE_SQL_DATAGEN})) ' ') --enable-sql-datagen" #19

    readonly MENU_DISABLE_KSQLDB="❌🎏 Disable ksqlDB" #20
    readonly MENU_DISABLE_C3="❌💠 Disable Control Center"
    readonly MENU_DISABLE_CONDUKTOR="❌🐺 Disable Conduktor Platform"
    readonly MENU_DISABLE_RP="❌🧲 Disable Rest Proxy"
    readonly MENU_DISABLE_GRAFANA="❌📊 Disable Grafana"
    readonly MENU_DISABLE_BROKERS="❌3️⃣ Disabling multiple brokers"
    readonly MENU_DISABLE_CONNECT_WORKERS="❌🥉 Disabling multiple connect workers"
    readonly MENU_DISABLE_KCAT="❌🐈 Disabling kcat"
    readonly MENU_DISABLE_SQL_DATAGEN="❌🌪️ Disable SQL Datagen injection" #27

    readonly MENU_SEPARATOR_FEATURES="--------------------options-----------------------"

    MENU_CLUSTER_TYPE="🔋 Cluster type $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_TYPE})) ' ') --cluster-type" #29
    MENU_CLUSTER_CLOUD="🌤  Cloud provider $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_CLUSTER_CLOUD})) ' ') --cluster-cloud"
    MENU_CLUSTER_REGION="🗺  Cloud region $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_REGION})) ' ') --cluster-region"
    MENU_CLUSTER_ENVIRONMENT="🌐 Environment id $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_CLUSTER_ENVIRONMENT})) ' ') --cluster-environment"

    MENU_CLUSTER_NAME="🎰 Cluster name $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_NAME})) ' ') --cluster-name"
    MENU_CLUSTER_CREDS="🔒 Kafka api key & secret $(printf '%*s' $((${MAX_LENGTH}-25-${#MENU_CLUSTER_CREDS})) ' ') --cluster-creds"
    MENU_CLUSTER_SR_CREDS="🔰 Schema registry api key & secret $(printf '%*s' $((${MAX_LENGTH}-35-${#MENU_CLUSTER_SR_CREDS})) ' ') --cluster-schema-registry-creds"

    readonly MENU_SEPARATOR_CLOUD="-----------------confluent cloud------------------" #36

    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    connector_example=0
    get_connector_paths
    if [ "$connector_paths" != "" ]
    then
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        else
          connector_example=1
        fi
      done
    fi

    sql_datagen=0
    if [[ $test_file == *"connect-debezium-sqlserver"* ]] || [[ $test_file == *"connect-debezium-mysql"* ]] || [[ $test_file == *"connect-debezium-postgresql"* ]] || [[ $test_file == *"connect-debezium-oracle"* ]] || [[ $test_file == *"connect-cdc-oracle"* ]] || [[ $test_file == *"connect-jdbc-sqlserver"* ]] || [[ $test_file == *"connect-jdbc-mysql"* ]] || [[ $test_file == *"connect-jdbc-postgresql"* ]] || [[ $test_file == *"connect-jdbc-oracle"* ]]

    then
      sql_datagen=1
    fi

    stop=0
    while [ $stop != 1 ]
    do
      has_error=0
      options=("$MENU_LETS_GO" "$MENU_PROBLEM" "$MENU_OPEN_FILE" "$MENU_OPEN_DOCS" "$MENU_SEPARATOR" "$MENU_TAG" "$MENU_CONNECTOR_TAG" "$MENU_CONNECTOR_ZIP" "$MENU_CONNECTOR_JAR" "$MENU_ENVIRONMENT" "$MENU_SEPARATOR" "$MENU_ENABLE_KSQLDB" "$MENU_ENABLE_C3" "$MENU_ENABLE_CONDUKTOR" "$MENU_ENABLE_RP" "$MENU_ENABLE_GRAFANA" "$MENU_ENABLE_BROKERS" "$MENU_ENABLE_CONNECT_WORKERS" "$MENU_ENABLE_KCAT" "$MENU_ENABLE_SQL_DATAGEN" "$MENU_DISABLE_KSQLDB" "$MENU_DISABLE_C3" "$MENU_DISABLE_CONDUKTOR" "$MENU_DISABLE_RP" "$MENU_DISABLE_GRAFANA" "$MENU_DISABLE_BROKERS" "$MENU_DISABLE_CONNECT_WORKERS" "$MENU_DISABLE_KCAT" "$MENU_DISABLE_SQL_DATAGEN" "$MENU_SEPARATOR_FEATURES" "$MENU_CLUSTER_TYPE" "$MENU_CLUSTER_CLOUD" "$MENU_CLUSTER_REGION" "$MENU_CLUSTER_ENVIRONMENT" "$MENU_CLUSTER_NAME" "$MENU_CLUSTER_CREDS" "$MENU_CLUSTER_SR_CREDS" "$MENU_SEPARATOR_CLOUD" "$MENU_GO_BACK")

      if [[ $test_file == *"ccloud"* ]] || [ "$PLAYGROUND_ENVIRONMENT" == "ccloud" ]
      then
        if [[ $test_file == *"fully-managed"* ]]
        then
          for((i=5;i<30;i++)); do
            unset "options[$i]"
          done
        fi
        unset 'options[14]'
        unset 'options[15]'
        unset 'options[16]'
        unset 'options[17]'

        unset 'options[23]'
        unset 'options[24]'
        unset 'options[25]'
        unset 'options[26]'

        if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
        then
          if [ ! -z "$CLUSTER_TYPE" ]
          then
            unset CLUSTER_TYPE
          fi
          if [ ! -z "$CLUSTER_CLOUD" ]
          then
            unset CLUSTER_CLOUD
          fi
          if [ ! -z "$CLUSTER_REGION" ]
          then
            unset CLUSTER_REGION
          fi
          if [ ! -z "$ENVIRONMENT" ]
          then
            unset ENVIRONMENT
          fi
          if [ ! -z "$CLUSTER_NAME" ]
          then
            unset CLUSTER_NAME
            cluster_name=""
          fi
          if [ ! -z "$CLUSTER_CREDS" ]
          then
            unset CLUSTER_CREDS
          fi

          if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
          then
            unset SCHEMA_REGISTRY_CREDS
          fi
        fi
        if [ ! -z "$CLUSTER_NAME" ] || [[ -n "$cluster_name" ]]
        then
          if [ ! -z "$CLUSTER_NAME" ]
          then
            cluster_name=$CLUSTER_NAME
          fi
          #
          # CLUSTER_NAME is set
          #
          ccloud_preview="🎯 ${YELLOW}cluster-name is set, your existing ccloud cluster will be used...${NC}\n\n"
          ccloud_preview="${ccloud_preview}🎰 ${YELLOW}cluster-name=$cluster_name${NC}\n"

          if [ -z $ENVIRONMENT ]

          then
            ccloud_preview="${ccloud_preview}❌ 🌐${RED}environment is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🌐 ${YELLOW}environment=$ENVIRONMENT${NC}\n"
          fi

          if [ -z $CLUSTER_CLOUD ]

          then
            ccloud_preview="${ccloud_preview}❌  🌤${RED}cluster-cloud is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🌤 ${YELLOW}cluster-cloud=$CLUSTER_CLOUD${NC}\n"
          fi

          if [ -z $CLUSTER_REGION ]

          then
            ccloud_preview="${ccloud_preview}❌ 🗺${RED}cluster-region is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🗺  ${YELLOW}cluster-region=$CLUSTER_REGION${NC}\n"
          fi

          if [ -z $CLUSTER_CREDS ]

          then
            ccloud_preview="${ccloud_preview}❌ 🔒${RED}cluster-creds is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z $SCHEMA_REGISTRY_CREDS ]

          then
            ccloud_preview="${ccloud_preview}🔒 ${YELLOW}cluster-schema-registry-creds is missing, new credentials will be created${NC}\n"
          else
            ccloud_preview="${ccloud_preview}🔒 ${YELLOW}cluster-schema-registry-creds are set${NC}\n"
          fi
        else # CLUSTER_NAME is set
          #
          # CLUSTER_NAME is not set
          #
          ccloud_preview="✨ ${YELLOW}cluster-name is not set, a new ccloud cluster will be created...${NC}\n\n"

          if [ -z $ENVIRONMENT ] && [[ ! -n "$cluster_environment" ]]
          then
            ccloud_preview="${ccloud_preview}🌐 ${CYAN}environment is missing, new environment will be created${NC}\n"
          else
            if [ ! -z "$ENVIRONMENT" ]
            then
              cluster_environment=$ENVIRONMENT
            fi
            ccloud_preview="${ccloud_preview}🌐 ${YELLOW}cluster-environment=$cluster_environment${NC}\n"
          fi

          if [ -z $CLUSTER_TYPE ] && [[ ! -n "$cluster_type" ]]
          then
            ccloud_preview="${ccloud_preview}🔋 ${CYAN}cluster-type is missing, basic will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_TYPE" ]
            then
              cluster_type=$CLUSTER_TYPE
            fi
            ccloud_preview="${ccloud_preview}🔋 ${YELLOW}cluster-type=$cluster_type${NC}\n"
          fi

          if [ -z $CLUSTER_CLOUD ] && [[ ! -n "$cluster_cloud" ]]
          then
            ccloud_preview="${ccloud_preview}🌤  ${CYAN}cluster-cloud is missing, aws will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_CLOUD" ]
            then
              cluster_cloud=$CLUSTER_CLOUD
            fi
            ccloud_preview="${ccloud_preview}🌤 ${YELLOW}cluster-cloud=$cluster_cloud${NC}\n"
          fi

          if [ -z $CLUSTER_REGION ] && [[ ! -n "$cluster_region" ]]
          then
            ccloud_preview="${ccloud_preview}🗺 ${CYAN}cluster-region is missing, default region for provider will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_REGION" ]
            then
              cluster_region=$CLUSTER_REGION
            fi
            ccloud_preview="${ccloud_preview}🗺  ${YELLOW}cluster-region=$cluster_region${NC}\n"
          fi
        fi
      else # end of ccloud
        unset 'options[30]'
        unset 'options[31]'
        unset 'options[32]'
        unset 'options[33]'
        unset 'options[34]'
        unset 'options[35]'
        unset 'options[36]'
        unset 'options[37]'

        unset 'options[39]'
        unset 'options[40]'
        unset 'options[41]'
        unset 'options[42]'
      fi

      if [ $connector_example == 0 ]
      then
        unset 'options[6]'
        unset 'options[7]'
        unset 'options[8]'
        unset 'options[9]'
      fi

      if [ $docs_available == 0 ]
      then
        unset 'options[3]'
      fi

      if [ $sql_datagen == 0 ]
      then
        unset 'options[19]'
      fi

      if [ ! -z $ENABLE_KSQLDB ]
      then
        unset 'options[11]'
      else
        unset 'options[20]'
      fi
      if [ ! -z $ENABLE_CONTROL_CENTER ]
      then
        unset 'options[12]'
      else
        unset 'options[21]'
      fi
      if [ ! -z $ENABLE_CONDUKTOR ]
      then
        unset 'options[13]'
      else
        unset 'options[22]'
      fi
      if [ ! -z $ENABLE_RESTPROXY ]
      then
        unset 'options[14]'
      else
        unset 'options[23]'
      fi
      if [ ! -z $ENABLE_JMX_GRAFANA ]
      then
        unset 'options[15]'
      else
        unset 'options[24]'
      fi
      if [ ! -z $ENABLE_KAFKA_NODES ]
      then
        unset 'options[16]'
      else
        unset 'options[25]'
      fi
      if [ ! -z $ENABLE_CONNECT_NODES ]
      then
        unset 'options[17]'
      else
        unset 'options[26]'
      fi
      if [ ! -z $ENABLE_KCAT ]
      then
        unset 'options[18]'
      else
        unset 'options[27]'
      fi
      if [ ! -z $SQL_DATAGEN ]
      then
        unset 'options[19]'
      else
        unset 'options[28]'
      fi

      missing_env=""
      declare -a missing_env_list=()

      # generic check
      for mandatory_environment_variable in $(grep "Export it as environment variable or pass it as argument" $test_file | cut -d "\"" -f2 | cut -d " " -f 1)
      do
        if [ ! -v $mandatory_environment_variable ]
        then
          missing_env="${missing_env}❌ ${RED}${mandatory_environment_variable} is missing!${NC}\n"
          unset 'options[0]'
          has_error=1

          missing_env_list+=("$mandatory_environment_variable")
        else
          if [[ $mandatory_environment_variable == *"PASSWORD"* ]] || [[ $mandatory_environment_variable == *"SECRET"* ]] || [[ $mandatory_environment_variable == *"TOKEN"* ]] || [[ $mandatory_environment_variable == *"KEY"* ]]
          then
            missing_env="${missing_env}🔑 ${GREEN}${mandatory_environment_variable} is set${NC}\n"
          else
            missing_env="${missing_env}🔑 ${GREEN}${mandatory_environment_variable}=${!mandatory_environment_variable}${NC}\n"
          fi
        fi
      done

      if [[ $test_file == *"aws"* ]]
      then
        if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
        then
          if [ ! -f "$HOME/.aws/credentials" ]
          then
            missing_env="${missing_env}❌ ${RED}$HOME/.aws/credentials is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z "$AWS_ACCESS_KEY_ID" ]
          then
            missing_env="${missing_env}❌ ${RED}AWS_ACCESS_KEY_ID is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("AWS_ACCESS_KEY_ID")
          fi

          if [ -z "$AWS_SECRET_ACCESS_KEY" ]
          then
            missing_env="${missing_env}❌ ${RED}AWS_SECRET_ACCESS_KEY is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("AWS_SECRET_ACCESS_KEY")
          fi
        fi

        if [ -f "$HOME/.aws/credentials" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}$HOME/.aws/credentials is present${NC}\n"
        fi

        if [ ! -z "$AWS_ACCESS_KEY_ID" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}${NC}\n"
        fi

        if [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}AWS_SECRET_ACCESS_KEY is set${NC}\n"
        fi
      fi

      if [[ $test_file == *"gcp"* ]]
      then
        if [ ! -f "$test_file_directory/keyfile.json" ] && [ -z "$GCP_KEYFILE_CONTENT" ]
        then
          if [ ! -f "$test_file_directory/keyfile.json" ]
          then
            missing_env="${missing_env}❌ ${RED}$test_file_directory/keyfile.json is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z "$GCP_KEYFILE_CONTENT" ]
          then
            missing_env="${missing_env}❌ ${RED}GCP_KEYFILE_CONTENT is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("GCP_KEYFILE_CONTENT")
          fi
        fi

        if [ -f "$test_file_directory/keyfile.json" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}$test_file_directory/keyfile.json is present${NC}\n"
        fi

        if [ ! -z "$GCP_KEYFILE_CONTENT" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}GCP_KEYFILE_CONTENT is set${NC}\n"
        fi
      fi

      if [ ${#missing_env_list[@]} -gt 0 ]
      then
        oldifs=$IFS
        IFS=$',' missing_env_list_string="${missing_env_list[*]}"
        IFS=$oldifs

        if [ ${#missing_env_list[@]} -eq 1 ]
        then
          MENU_PROBLEM="❌ ${missing_env_list_string} is missing! Click here to fix it"
        else
          MENU_PROBLEM="❌ ${missing_env_list_string} are missing! Click here to fix it"
        fi

        options[1]="$MENU_PROBLEM"
      fi

      if [ $has_error == 0 ]
      then
        unset 'options[1]'
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs

      preview="${ccloud_preview}\n${missing_env}\n🚀 number of examples ran so far: $(get_cli_metric nb_runs)\n\n⛳ flag list:\n$flag_string\n"
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"$preview\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_PROBLEM"* ]]
      then
        for mandatory_environment_variable in ${missing_env_list[*]}
        do
          if [ ! -v $mandatory_environment_variable ]
          then
            set +e
            mandatory_environment_variable_value=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the value for environment variable $mandatory_environment_variable" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
            set -e

            export $mandatory_environment_variable="$mandatory_environment_variable_value"
          fi
        done
      fi

      if [[ $res == *"$MENU_OPEN_FILE"* ]]
      then
        editor=$(playground config get editor)
        if [ "$editor" != "" ]
        then
          log "📖 Opening ${test_file} using configured editor $editor"
          $editor ${test_file}
        else
            if [[ $(type code 2>&1) =~ "not found" ]]
            then
                logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                exit 1
            else
                log "📖 Opening ${test_file} with code (default) - you can change editor by using playground config editor <editor>"
                code ${test_file}
            fi
        fi
      fi

      if [[ $res == *"$MENU_OPEN_DOCS"* ]]
      then
        if [[ $(type -f open 2>&1) =~ "not found" ]]
        then
          playground open-docs --only-show-url
        else
          playground open-docs
        fi
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground run
      fi

      if [[ $res == *"$MENU_ENABLE_KSQLDB"* ]]
      then
        array_flag_list+=("--enable-ksqldb")
        export ENABLE_KSQLDB=true
        interactive_enable_ksqldb="true"
      fi
      if [[ $res == *"$MENU_DISABLE_KSQLDB"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-ksqldb"}")
        unset ENABLE_KSQLDB
        interactive_enable_ksqldb=""
      fi

      if [[ $res == *"$MENU_ENABLE_C3"* ]]
      then
        array_flag_list+=("--enable-control-center")
        export ENABLE_CONTROL_CENTER=true
        interactive_enable_c3="true"
      fi
      if [[ $res == *"$MENU_DISABLE_C3"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-control-center"}")
        unset ENABLE_CONTROL_CENTER
        interactive_enable_c3=""
      fi

      if [[ $res == *"$MENU_ENABLE_RP"* ]]
      then
        array_flag_list+=("--enable-rest-proxy")
        export ENABLE_RESTPROXY=true
        interactive_enable_rp="true"
      fi
      if [[ $res == *"$MENU_DISABLE_RP"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-rest-proxy"}")
        unset ENABLE_RESTPROXY
        interactive_enable_rp=""
      fi

      if [[ $res == *"$MENU_ENABLE_CONDUKTOR"* ]]
      then
        array_flag_list+=("--enable-conduktor")
        export ENABLE_CONDUKTOR=true
        interactive_enable_conduktor="true"
      fi

      if [[ $res == *"$MENU_DISABLE_CONDUKTOR"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-conduktor"}")
        unset ENABLE_CONDUKTOR
        interactive_enable_conduktor=""
      fi

      if [[ $res == *"$MENU_ENABLE_GRAFANA"* ]]
      then
        array_flag_list+=("--enable-jmx-grafana")
        export ENABLE_JMX_GRAFANA=true
        interactive_enable_grafana="true"

      fi
      if [[ $res == *"$MENU_DISABLE_GRAFANA"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-jmx-grafana"}")
        unset ENABLE_JMX_GRAFANA
        interactive_enable_grafana=""
      fi

      if [[ $res == *"$MENU_ENABLE_BROKERS"* ]]
      then
        array_flag_list+=("--enable-multiple-broker")
        export ENABLE_KAFKA_NODES=true
        interactive_enable_broker="true"
      fi

      if [[ $res == *"$MENU_DISABLE_BROKERS"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-multiple-broker"}")
        unset ENABLE_KAFKA_NODES
        interactive_enable_broker=""
      fi

      if [[ $res == *"$MENU_ENABLE_CONNECT_WORKERS"* ]]
      then
        array_flag_list+=("--enable-multiple-connect-workers")
        export ENABLE_CONNECT_NODES=true
        interactive_enable_connect="true"

        # determining the docker-compose file from from test_file
        docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
        docker_compose_file="${test_file_directory}/${docker_compose_file}"
        if [ -f $docker_compose_file ]
        then
          cp $docker_compose_file /tmp/playground-backup-docker-compose.yml
          yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
          yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
          cp /tmp/playground-backup-docker-compose.yml $docker_compose_file
        fi
      fi

      if [[ $res == *"$MENU_DISABLE_CONNECT_WORKERS"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-multiple-connect-workers"}")
        unset ENABLE_CONNECT_NODES
        interactive_enable_connect=""
        if [ -f /tmp/playground-backup-docker-compose.yml ]
        then
          mv /tmp/playground-backup-docker-compose.yml $docker_compose_file
        fi
      fi

      if [[ $res == *"$MENU_ENABLE_KCAT"* ]]
      then
        array_flag_list+=("--enable-kcat")
        export ENABLE_KCAT=true
        interactive_enable_kcat="true"
      fi

      if [[ $res == *"$MENU_DISABLE_KCAT"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-kcat"}")
        unset ENABLE_KCAT
        interactive_enable_kcat=""
      fi

      if [[ $res == *"$MENU_ENABLE_SQL_DATAGEN"* ]]
      then
        array_flag_list+=("--enable-sql-datagen")
        export SQL_DATAGEN=true
        interactive_enable_sql="true"
      fi
      if [[ $res == *"$MENU_DISABLE_SQL_DATAGEN"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-sql-datagen"}")
        unset SQL_DATAGEN
        interactive_enable_sql=""
      fi

      if [[ $res == *"$MENU_ENVIRONMENT"* ]]
      then
        maybe_remove_flag "--environment"

        options=(plaintext ccloud 2way-ssl kerberos kraft-external-plaintext kraft-plaintext ldap-authorizer-sasl-plain ldap-sasl-plain rbac-sasl-plain sasl-plain sasl-scram sasl-ssl ssl_kerberos)
        environment=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="select an environment" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)

        array_flag_list+=("--environment=$environment")
        export PLAYGROUND_ENVIRONMENT=$environment
      fi

      if [[ $res == *"$MENU_TAG"* ]]
      then
        maybe_remove_flag "--tag"

        tag=$(playground get-tag-list)
        if [[ $tag == *"@"* ]]
        then
          tag=$(echo "$tag" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--tag=$tag")
        export TAG=$tag
      fi

      if [[ $res == *"$MENU_CONNECTOR_TAG"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        connector_tags=""
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          fi

          ret=$(choose_connector_tag "$owner/$name")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

          if [ -z "$connector_tags" ]; then
            connector_tags="$connector_tag"
          else
            connector_tags="$connector_tags,$connector_tag"
          fi
        done

        connector_tag="$connector_tags"
        array_flag_list+=("--connector-tag=$connector_tag")
        export CONNECTOR_TAG="$connector_tag"
      fi

      if [[ $res == *"$MENU_CONNECTOR_ZIP"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        maybe_remove_flag "--connector-jar"
        cd $test_file_directory
        connector_zip=$(playground get-zip-or-jar-with-fzf --type zip)
        if [[ $connector_zip == *"@"* ]]
        then
          connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--connector-zip=$connector_zip")
        export CONNECTOR_ZIP=$connector_zip
      fi

      if [[ $res == *"$MENU_CONNECTOR_JAR"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-jar"
        cd $test_file_directory
        connector_jar=$(playground get-zip-or-jar-with-fzf --type jar)
        if [[ $connector_jar == *"@"* ]]
        then
          connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--connector-jar=$connector_jar")
        export CONNECTOR_JAR=$connector_jar
      fi

      if [[ $res == *"$MENU_CLUSTER_TYPE"* ]]
      then
        maybe_remove_flag "--cluster-type"
        options=(basic standard dedicated)
        cluster_type=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔋" --header="select a cluster type" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)
        array_flag_list+=("--cluster-type $cluster_type")
      fi

      if [[ $res == *"$MENU_CLUSTER_CLOUD"* ]]
      then
        maybe_remove_flag "--cluster-cloud"
        options=(aws gcp azure)
        cluster_cloud=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔋" --header="select a cluster type" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)
        array_flag_list+=("--cluster-cloud $cluster_cloud")
      fi

      if [[ $res == *"$MENU_CLUSTER_REGION"* ]]
      then
        maybe_remove_flag "--cluster-region"
        cluster_region=$(playground get-kafka-region-list $cluster_cloud)

        if [[ $cluster_region == *"@"* ]]
        then
          cluster_region=$(echo "$cluster_region" | cut -d "@" -f 2)
        fi
        cluster_region=$(echo "$cluster_region" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
        array_flag_list+=("--cluster-region $cluster_region")
      fi

      if [[ $res == *"$MENU_CLUSTER_ENVIRONMENT"* ]]
      then
        maybe_remove_flag "--cluster-environment"
        cluster_environment=$(playground get-ccloud-environment-list)

        if [[ $cluster_environment == *"@"* ]]
        then
          cluster_environment=$(echo "$cluster_environment" | cut -d "@" -f 2)
        fi
        if [[ $cluster_environment == *"/"* ]]
        then
          cluster_environment=$(echo "$cluster_environment" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
        fi
        array_flag_list+=("--cluster-environment $cluster_environment")
      fi

      if [[ $res == *"$MENU_CLUSTER_NAME"* ]]
      then
        maybe_remove_flag "--cluster-name"
        cluster_name=$(playground get-ccloud-cluster-list)

        if [[ $cluster_name == *"@"* ]]
        then
          cluster_name=$(echo "$cluster_name" | cut -d "@" -f 2)
        fi
        if [[ $cluster_name == *"/"* ]]
        then
          cluster_name=$(echo "$cluster_name" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
        fi
        array_flag_list+=("--cluster-name $cluster_name")
      fi

      if [[ $res == *"$MENU_CLUSTER_CREDS"* ]]
      then
        maybe_remove_flag "--cluster-creds"
        set +e
        cluster_creds=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the Kafka api key and secret to use, it should be separated with colon (example: <API_KEY>:<API_KEY_SECRET>)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        array_flag_list+=("--cluster-creds $cluster_creds")
      fi

      if [[ $res == *"$MENU_CLUSTER_SR_CREDS"* ]]
      then
        maybe_remove_flag "--cluster-schema-registry-creds"
        set +e
        cluster_schema_registry_creds=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the Schema Registry api key and secret to use, it should be separated with colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        array_flag_list+=("--cluster-schema-registry-creds $cluster_schema_registry_creds")
      fi
    done # end while loop stop

    if [ "$interactive_enable_ksqldb" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-ksqldb ENABLE_KSQLDB
      fi
    fi

    if [ "$interactive_enable_rp" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-rest-proxy ENABLE_RESTPROXY
      fi
    fi

    if [ "$interactive_enable_c3" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-control-center ENABLE_CONTROL_CENTER
      fi
    fi

    if [ "$interactive_enable_conduktor" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-conduktor ENABLE_CONDUKTOR
      fi
    fi

    if [ "$interactive_enable_broker" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-multiple-broker ENABLE_KAFKA_NODES
      fi
    fi

    if [ "$interactive_enable_connect" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-multiple-connect-workers ENABLE_CONNECT_NODES
      fi
    fi

    if [ "$interactive_enable_grafana" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
      fi
    fi

    if [ "$interactive_enable_kcat" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-kcat ENABLE_KCAT
      fi
    fi

    if [ "$interactive_enable_sql" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-sql-datagen SQL_DATAGEN
      fi
    fi

    if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_name" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
    then
      playground state set ccloud.suggest_use_previous_example_ccloud "0"

      if [[ -n "$cluster_type" ]]
      then
        export CLUSTER_TYPE=$cluster_type
      fi

      # default
      if [ -z "$CLUSTER_TYPE" ]
      then
        export CLUSTER_TYPE="basic"
      fi

      if [[ -n "$cluster_cloud" ]]
      then
        export CLUSTER_CLOUD=$cluster_cloud
      fi

      # default
      if [ -z "$CLUSTER_CLOUD" ]
      then
        export CLUSTER_CLOUD="aws"
      fi

      if [[ -n "$cluster_region" ]]
      then
        export CLUSTER_REGION=$cluster_region
      fi

      # default
      if [ -z "$CLUSTER_REGION" ]
      then
        case "${CLUSTER_CLOUD}" in
          aws)
            export CLUSTER_REGION="eu-west-2"
          ;;
          azure)
            export CLUSTER_REGION="westeurope"
          ;;
          gcp)
            export CLUSTER_REGION="europe-west2"
          ;;
        esac
      fi

      if [[ -n "$cluster_type" ]]
      then
        export CLUSTER_TYPE=$cluster_type
      fi

      if [[ -n "$cluster_environment" ]]
      then
        export ENVIRONMENT=$cluster_environment
      fi

      if [[ -n "$cluster_name" ]]
      then
        export CLUSTER_NAME=$cluster_name
      fi

      if [[ -n "$cluster_creds" ]]
      then
        export CLUSTER_CREDS=$cluster_creds
      fi

      if [[ -n "$cluster_schema_registry_creds" ]]
      then
        export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
      fi
    else
      playground state set ccloud.suggest_use_previous_example_ccloud "1"
    fi
  fi # end of interactive_mode

  IFS=' ' flag_list="${array_flag_list[*]}"
  array_declaration=$(declare -p array_flag_list)
  encoded_array=$(echo "$array_declaration" | base64)
  playground state set run.array_flag_list_base64 "$encoded_array"

  if [ "$flag_list" != "" ]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      log "🚀⛅ Running ccloud example with flags"
    else
      log "🚀 Running example with flags"
    fi
    log "⛳ Flags used are $flag_list"
  else
    if [[ $test_file == *"ccloud"* ]]
    then
      log "🚀⛅ Running ccloud example without any flags"
    else
      log "🚀 Running example without any flags"
    fi
  fi
  set +e
  # playground container kill-all
  set -e
  playground state set run.connector_type "$(get_connector_type | tr -d '\n')"
  playground state set run.test_file "$test_file"
  echo "" >> "$root_folder/playground-run-history"
  echo "playground run -f $test_file $flag_list" >> "$root_folder/playground-run-history"

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
      then
          echo "playground run -f $test_file $flag_list" | pbcopy
          log "📋 command to run again example has been copied to the clipboard (disable with 'playground config set clipboard false')"
      fi
  fi

  increment_cli_metric nb_runs
  log "🚀 Number of examples ran so far: $(get_cli_metric nb_runs)"

  log "####################################################"
  log "🚀 Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  function cleanup {
    if [[ -n "$enable_multiple_connect_workers" ]]
    then
      if [ -f /tmp/playground-backup-docker-compose.yml ]
      then
        mv /tmp/playground-backup-docker-compose.yml $docker_compose_file
      fi
    fi
    rm /tmp/playground-run-command-used
    echo ""
    sleep 3
    set +e

    connector_type=$(playground state get run.connector_type)

    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
      if [ "$connector_name" != "" ]
      then
        playground connector status --connector "$connector_name"
      fi
    elif [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
    then
      sleep 1 #playground connector status
    fi

    # playground open-docs --only-show-url

    if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
    then
      playground connector versions
      playground connector open-docs --only-show-url
    fi
    set -e
  }
  trap cleanup EXIT

  playground generate-fzf-find-files &
  generate_connector_versions > /dev/null 2>&1 &
  touch /tmp/playground-run-command-used
  bash $filename
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  set +e
  # keep those lists up to date
  playground generate-tag-list > /dev/null 2>&1 &
  playground generate-connector-plugin-list > /dev/null 2>&1 &
  playground generate-kafka-region-list > /dev/null 2>&1 &
  set -e
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "✅ RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "🔥 RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_re_run_command() {
  # src/commands/re-run.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then
    logerror "❌ file $test_file retrieved from $root_folder/playground.ini does not exist!"
    exit 1
  fi

  declare -a array_flag_list=()
  encoded_array="$(playground state get run.array_flag_list_base64)"
  eval "$(echo "$encoded_array" | base64 --decode)"
  IFS=' ' flag_list="${array_flag_list[*]}"

  log "⚡ re-run with playground run -f \"$test_file\" $flag_list"
  playground run -f "$test_file" $flag_list --force-interactive-re-run
}

# :command.function
playground_history_command() {
  # src/commands/history.sh
  if [ ! -f $root_folder/playground-run-history ]
  then
      logerror "❌ history could not be found !"
      logerror "$root_folder/playground-run-history does not exist"
      exit 1
  fi

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
      fzf_option_wrap="--preview-window=40%,wrap"
      fzf_option_pointer="--pointer=👉"
      fzf_option_rounded="--border=rounded"
  else
      fzf_options=""
      fzf_option_pointer=""
      fzf_option_rounded=""
  fi

  awk '!seen[$0]++' $root_folder/playground-run-history > /tmp/tmp
  res=$(tac /tmp/tmp| sed '/^$/d' | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🏰" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter "kafka-docker-playground" --with-nth "2,3,4" $fzf_option_wrap $fzf_option_pointer)

  # Prompt the user to edit the res variable
  read -e -p "" -i "$res" edited_res

  # Use the edited value if it is not empty
  if [[ -n "$edited_res" ]]; then
    res="$edited_res"
  fi

  # log "🚀 Are you sure you want to run:"
  # echo "$res"
  #check_if_continue
  $res
}

# :command.function
playground_start_environment_command() {
  # src/commands/start-environment.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  environment="${args[--environment]}"
  docker_compose_override_file="${args[--docker-compose-override-file]}"
  wait_for_control_center="${args[--wait-for-control-center]}"

  if [ "$environment" = "ccloud" ]
  then
    test_file="$root_folder/ccloud/environment/start.sh"
  else
    test_file="$root_folder/environment/$environment/start.sh"
  fi
  test_file_directory="$(dirname "${test_file}")"

  set +e
  playground container kill-all
  set -e

  if [[ -n "$wait_for_control_center" ]]
  then
    export WAIT_FOR_CONTROL_CENTER=1
  fi

  cd $test_file_directory
  if [ -f $docker_compose_override_file ]
  then
    $test_file "$docker_compose_override_file"
  else
    $test_file
  fi
}

# :command.function
playground_switch_ccloud_command() {
  # src/commands/switch-ccloud.sh
  log "🌩️ switch to ccloud environment"

  for item in {ENVIRONMENT,CLUSTER_NAME,CLUSTER_CLOUD,CLUSTER_REGION,CLUSTER_CREDS,SCHEMA_REGISTRY_CREDS}
  do
      i=$(playground state get "ccloud.${item}")
      if [ "$i" == "" ]
      then
          logerror "ccloud.${item} is missing"
          logerror "a ccloud example was probably not executed before"
          exit 1
      fi
  done

  ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)
  CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)
  CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)
  CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)
  CLUSTER_CREDS=$(playground state get ccloud.CLUSTER_CREDS)
  SCHEMA_REGISTRY_CREDS=$(playground state get ccloud.SCHEMA_REGISTRY_CREDS)

  playground state set run.environment_before_switch "$(playground state get run.environment)"
  playground state set run.connector_type_before_switch "$(playground state get run.connector_type)"
  playground state set run.connector_type "$CONNECTOR_TYPE_FULLY_MANAGED"

  log "🔌 boostrapping ccloud environment"
  bootstrap_ccloud_environment
}

# :command.function
playground_switch_back_command() {
  # src/commands/switch-back.sh
  environment_before_switch=$(playground state get run.environment_before_switch)
  if [ "$environment_before_switch" == "" ]
  then
      logerror "switch-ccloud was probably not executed before"
      exit 1
  fi
  connector_type_before_switch=$(playground state get run.connector_type_before_switch)

  if [ "$connector_type_before_switch" != "" ]
  then
      log "💺 Switch back to previous environment ($environment_before_switch) with $connector_type_before_switch connector"
  else
      log "💺 Switch back to previous environment ($environment_before_switch)"
  fi

  playground state set run.environment "$environment_before_switch"
  playground state del run.environment_before_switch
  playground state set run.connector_type "$connector_type_before_switch"
  playground state del run.connector_type_before_switch

  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
  filename=$(basename $test_file)

  log "🚀 Running example "
  echo $last_two_folders/$filename
}

# :command.function
playground_update_version_command() {
  # src/commands/update-version.sh
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"

  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
  test_file_directory="$(dirname "${test_file}")"
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  docker_compose_file_available=1
  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    docker_compose_file_available=0
  fi

  current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)

  if [ "$current_tag" == "" ]
  then
    logerror "❌ Could not retrieve current cp version (--tag or TAG) being used"
    exit 1
  fi

  declare -a array_flag_list=()
  if [[ -n "$tag" ]]
  then
    if [[ $tag == *"@"* ]]
    then
      tag=$(echo "$tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--tag=$tag")
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    if [ "$connector_tag" == " " ]
    then
      get_connector_paths
      if [ "$connector_paths" == "" ]
      then
          logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
          exit 1
      else
          connector_tags=""
          for connector_path in ${connector_paths//,/ }
          do
            full_connector_name=$(basename "$connector_path")
            owner=$(echo "$full_connector_name" | cut -d'-' -f1)
            name=$(echo "$full_connector_name" | cut -d'-' -f2-)

            if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
            then
              # happens when plugin is not coming from confluent hub
              logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
            fi

            ret=$(choose_connector_tag "$owner/$name")
            connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

            if [ -z "$connector_tags" ]; then
              connector_tags="$connector_tag"
            else
              connector_tags="$connector_tags,$connector_tag"
            fi
          done

          connector_tag="$connector_tags"
      fi
    fi

    array_flag_list+=("--connector-tag=$connector_tag")
    export CONNECTOR_TAG="$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-zip=$connector_zip")
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-jar=$connector_jar")
    export CONNECTOR_JAR=$connector_jar
  fi

  IFS=' ' flag_list="${array_flag_list[*]}"
  if [ "$flag_list" == "" ]
  then
    docs_available=1
    set +e
    playground open-docs --only-show-url > /dev/null 2>&1
    if [ $? -eq 1 ]
    then
      docs_available=0
    fi
    set -e

    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi

    connector_example=0
    current_versions=""
    get_connector_paths
    if [ "$connector_paths" != "" ]
    then
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        else

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
            current_version=$(cat $manifest_file | jq -r '.version')
            # release_date=$(cat $manifest_file | jq -r '.release_date')

            if [ -z "$current_versions" ]; then
              current_versions="$current_version"
            else
              current_versions="$current_versions,$current_version"
            fi
          else
            change_detected=1
          fi
          connector_example=1
        fi
      done
    fi

    # readonly MENU_LETS_GO="🚀 Run the example !" #0
    readonly MENU_OPEN_FILE="📖 Open the file in text editor"
    set +e
    if [[ $(type -f open 2>&1) =~ "not found" ]]
    then
      MENU_OPEN_DOCS="🌐 Show link to the docs"
    else
      MENU_OPEN_DOCS="🌐 Open the docs in browser"
    fi
    set -e
    readonly MENU_SEPARATOR="--------------------------------------------------" #3
    MENU_TAG="🎯 CP version (current $current_tag) $(printf '%*s' $((${MAX_LENGTH}-29-${#MENU_TAG})) ' ') --tag" #4
    MENU_CONNECTOR_TAG="🔗 Connector version (current $current_versions) $(printf '%*s' $((${MAX_LENGTH}-44-${#MENU_CONNECTOR_TAG})) ' ') --connector-tag"
    MENU_CONNECTOR_ZIP="🤐 Connector zip $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_ZIP})) ' ') --connector-zip"
    MENU_CONNECTOR_JAR="🤎 Connector jar $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_JAR})) ' ') --connector-jar"

    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    stop=0
    change_detected=0
    while [ $stop != 1 ]
    do
      if [ $change_detected -eq 0 ]
      then
        MENU_LETS_GO="❌ No version change detected !" #0
      else
        MENU_LETS_GO="🚀 Run the example !" #0
      fi
      options=("$MENU_LETS_GO" "$MENU_OPEN_FILE" "$MENU_OPEN_DOCS" "$MENU_SEPARATOR" "$MENU_TAG" "$MENU_CONNECTOR_TAG" "$MENU_CONNECTOR_ZIP" "$MENU_CONNECTOR_JAR" "$MENU_GO_BACK")

      if [[ $test_file == *"ccloud"* ]] || [ "$PLAYGROUND_ENVIRONMENT" == "ccloud" ]
      then
        if [[ $test_file == *"fully-managed"* ]]
        then
          unset 'options[4]'
          unset 'options[5]'
          unset 'options[6]'
          unset 'options[7]'
        fi
      fi

      if [ $connector_example == 0 ] || [ $docker_compose_file_available == 0 ]
      then
        unset 'options[5]'
        unset 'options[6]'
        unset 'options[7]'
      fi

      if [ $docs_available == 0 ]
      then
        unset 'options[2]'
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs

      preview="\n🚀 number of examples ran so far: $(get_cli_metric nb_runs)\n\n⛳ flag list:\n$flag_string\n"
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"$preview\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_OPEN_FILE"* ]]
      then
        editor=$(playground config get editor)
        if [ "$editor" != "" ]
        then
          log "📖 Opening ${test_file} using configured editor $editor"
          $editor ${test_file}
        else
            if [[ $(type code 2>&1) =~ "not found" ]]
            then
                logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                exit 1
            else
                log "📖 Opening ${test_file} with code (default) - you can change editor by using playground config editor <editor>"
                code ${test_file}
            fi
        fi
      fi

      if [[ $res == *"$MENU_OPEN_DOCS"* ]]
      then
        if [[ $(type -f open 2>&1) =~ "not found" ]]
        then
          playground open-docs --only-show-url
        else
          playground open-docs
        fi
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground update-versions
      fi

      if [[ $res == *"$MENU_TAG"* ]]
      then
        tag=$(playground get-tag-list)
        if [[ $tag == *"@"* ]]
        then
          tag=$(echo "$tag" | cut -d "@" -f 2)
        fi

        if [ "$current_tag" != "$tag" ]
        then
          change_detected=1
          maybe_remove_flag "--tag"
          array_flag_list+=("--tag=$tag")
          export TAG=$tag
        fi
      fi

      if [[ $res == *"$MENU_CONNECTOR_TAG"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        connector_tags=""
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          fi

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
            current_version=$(cat $manifest_file | jq -r '.version')
            # release_date=$(cat $manifest_file | jq -r '.release_date')
          else
            change_detected=1
          fi

          ret=$(choose_connector_tag "$owner/$name")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

          if [ "$current_version" != "$connector_tag" ]
          then
            change_detected=1
          fi

          if [ -z "$connector_tags" ]; then
            connector_tags="$connector_tag"
          else
            connector_tags="$connector_tags,$connector_tag"
          fi
        done

        connector_tag="$connector_tags"
        array_flag_list+=("--connector-tag=$connector_tag")
        export CONNECTOR_TAG="$connector_tag"
      fi

      if [[ $res == *"$MENU_CONNECTOR_ZIP"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        maybe_remove_flag "--connector-jar"
        connector_zip=$(playground get-zip-or-jar-with-fzf --type zip)
        if [[ $connector_zip == *"@"* ]]
        then
          connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
        fi
        change_detected=1
        array_flag_list+=("--connector-zip=$connector_zip")
        export CONNECTOR_ZIP=$connector_zip
      fi

      if [[ $res == *"$MENU_CONNECTOR_JAR"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-jar"
        connector_jar=$(playground get-zip-or-jar-with-fzf --type jar)
        if [[ $connector_jar == *"@"* ]]
        then
          connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
        fi
        change_detected=1
        array_flag_list+=("--connector-jar=$connector_jar")
        export CONNECTOR_JAR=$connector_jar
      fi
    done # end while loop stop
  fi

  tag_changed=0
  IFS=' ' flag_list="${array_flag_list[*]}"
  if [[ -n "$tag" ]]
  then
    current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)

    if [ "$current_tag" == "" ]
    then
      logerror "❌ Could not retrieve current cp version (--tag or TAG) being used"
      exit 1
    fi

    if [ "$current_tag" == "$tag" ]
    then
      logwarn "--tag=$tag is same as current tag, ignoring..."
      array_flag_list=("${array_flag_list[@]/"--tag"}")
    else
      tag_changed=1
    fi
  fi

  if [ $docker_compose_file_available == 1 ]
  then
    export DOCKER_COMPOSE_FILE_UPDATE_VERSION="$docker_compose_file"
  fi

  IFS=' ' flag_list="${array_flag_list[*]}"
  if [ "$flag_list" != "" ]
  then
    log "✨ Loading new version(s) based on flags ⛳ $flag_list"
  else
    log "✨ Loading new version(s) without any flags ⛳"
  fi

  if [ $tag_changed -eq 1 ]
  then
      log "💣 Detected confluent version change, restarting containers"
      playground container recreate --ignore-current-versions
  else
      # in case there is a change in docker-compose...
      playground container recreate
  fi

  if [[ -n "$connector_tag" ]] || [[ -n "$connector_zip" ]] || [[ -n "$connector_jar" ]]
  then
      if [ $tag_changed -eq 0 ]
      then
          log "🧩 a connector flag is set: restarting connect container to make sure new version(s) are used"
          playground container restart --container connect
      fi
      sleep 5

      wait_container_ready

      sleep 10

      playground connector versions
  else
      sleep 4

      wait_container_ready
  fi
}

# :command.function
playground_open_command() {
  # src/commands/open.sh
  test_file="${args[--file]}"

  if [[ -n "$test_file" ]]
  then
    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi
  else
    test_file=$(playground state get run.test_file)

    if [ ! -f $test_file ]
    then

        logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
        exit 1
    fi
  fi

  editor=$(playground config get editor)
  if [ "$editor" != "" ]
  then
    log "📖 Opening ${test_file} using configured editor $editor"
    $editor ${test_file}
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
      exit 1
    else
      log "📖 Opening ${test_file} with code (default) - you can change editor by using playground config editor <editor>"
      code ${test_file}
    fi
  fi
}

# :command.function
playground_stop_command() {
  # src/commands/stop.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi
  filename=$(basename -- "$test_file")
  test_file_directory="$(dirname "${test_file}")"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT

  log "🛑 Stopping example $filename in dir $test_file_directory"
  docker_command=$(playground state get run.docker_command)
  echo "$docker_command" > $tmp_dir/tmp

  sed -e "s|up -d|down -v --remove-orphans|g" \
      $tmp_dir/tmp > $tmp_dir/tmp2

  sed -e "s|--quiet-pull||g" \
      $tmp_dir/tmp2 > $tmp_dir/playground-command-stop

  bash $tmp_dir/playground-command-stop
}

# :command.function
playground_remove_all_docker_images_command() {
  # src/commands/remove-all-docker-images.sh
  log "🧨 Remove all docker images (including docker volumes)"
  check_if_continue

  set +e
  playground container kill-all
  docker image rm $(docker image list | grep -v "oracle/database"  | grep -v "db-prebuilt" | awk 'NR>1 {print $3}') -f
  docker system prune -a -f
  docker volume rm $(docker volume ls -qf dangling=true)
}

# :command.function
playground_open_docs_command() {
  # src/commands/open-docs.sh
  only_show_url="${args[--only-show-url]}"
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  readme_file="$(dirname $test_file)/README.md"
  if [ ! -f $readme_file ]
  then

      logerror "README file $readme_file does not exist"
      exit 1
  fi

  string=$(grep "Quickly test " $readme_file)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
      short_url=$(echo $url | cut -d '#' -f 1)
      if [[ -n "$only_show_url" ]]
      then
          log "🌐 documentation is available at:"
          echo "$short_url"
      else
          log "🌐 opening documentation $short_url"
          open "$short_url"
      fi
  else
      logerror "Could not find documentation link in README file $readme_file"
      exit 1
  fi
}

# :command.function
playground_cleanup_cloud_resources_command() {
  # src/commands/cleanup-cloud-resources.sh
  user="${args[--user]}"
  force="${args[--force]}"
  # Convert the space delimited string to an array
  eval "resources=(${args[--resource]})"

  set +e
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ ! -n "$user" ]]
  then
      user="${USER}"
  fi

  function cleanup_aws () {
      if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
      then
          logerror "ERROR: either the file $HOME/.aws/credentials is not present or environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are not set!"
          exit 1
      else
          if [ ! -z "$AWS_ACCESS_KEY_ID" ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
          then
              log "💭 Using environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
              export AWS_ACCESS_KEY_ID
              export AWS_SECRET_ACCESS_KEY
          else
              if [ -f $HOME/.aws/credentials ]
              then
                  logwarn "💭 AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are set based on $HOME/.aws/credentials"
                  export AWS_ACCESS_KEY_ID=$( grep "^aws_access_key_id" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )
                  export AWS_SECRET_ACCESS_KEY=$( grep "^aws_secret_access_key" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )

              fi
          fi
          if [ -z "$AWS_REGION" ]
          then
              AWS_REGION=$(aws configure get region | tr '\r' '\n')
              if [ "$AWS_REGION" == "" ]
              then
                  logerror "ERROR: either the file $HOME/.aws/config is not present or environment variables AWS_REGION is not set!"
                  exit 1
              fi
          fi
      fi

      log "Cleanup AWS Kinesis streams"
      for stream in $(aws kinesis list-streams --region $AWS_REGION | jq '.StreamNames[]' -r)
      do
          if [[ $stream = *pg${user}* ]]
          then
              log "Removing AWS Kinesis stream $stream"
              check_if_skip "aws kinesis delete-stream --stream-name $stream --region $AWS_REGION"
          fi
      done

      log "Cleanup AWS SQS queues"
      for queue in $(aws sqs list-queues --region $AWS_REGION | jq '.QueueUrls[]' -r)
      do
          if [[ $queue = *pg${user}* ]]
          then
              log "Removing AWS SQS queue $queue"
              check_if_skip "aws sqs delete-queue --queue-url ${queue}"
          fi
      done

      log "Cleanup AWS Lambda functions"
      for function in $(aws lambda list-functions --region $AWS_REGION | jq '.Functions[].FunctionName' -r)
      do
          if [[ $function = *pglambdafunction* ]] || [[ $function = *pg${user}* ]]
          then
              log "Removing AWS Lambda function $function"
              check_if_skip "aws lambda delete-function --function-name ${function}"
          fi
      done

      log "Cleanup AWS Lambda IAM roles"
      for role in $(aws iam list-roles --region $AWS_REGION | jq '.Roles[].RoleName' -r)
      do
          if [[ $role = *pglambdarole* ]] || [[ $role = *pg${user}* ]]
          then
              log "Removing AWS Lambda role $role"
              check_if_skip "aws iam delete-role --role-name ${role}"
          fi
      done

      log "Cleanup AWS CloudWatch log group"
      for log_group in $(aws logs describe-log-groups --region $AWS_REGION | jq '.logGroups[].logGroupName' -r)
      do
          if [[ $log_group = *myloggroup* ]] || [[ $log_group = *pg${user}* ]]
          then
              for log_stream in $(aws logs describe-log-streams --log-group-name $log_group --region $AWS_REGION | jq '.logStreams[].logStreamName' -r)
              do
                  log "Removing AWS CloudWatch log stream $log_stream for log group $log_group"
                  check_if_skip "aws logs delete-log-stream --log-group-name ${log_group} --log-stream-name ${log_stream}"
              done

              log "Removing AWS CloudWatch log group $log_group"
              check_if_skip "aws logs delete-log-group --log-group-name ${log_group}"
          fi
      done

      log "Cleanup AWS Redshift clusters"
      for cluster in $(aws redshift describe-clusters --region $AWS_REGION | jq '.Clusters[].ClusterIdentifier' -r)
      do
          if [[ $cluster = pg${user}redshift* ]]
          then
              log "Delete AWS Redshift $cluster"
              check_if_skip "aws redshift delete-cluster --cluster-identifier $cluster --skip-final-cluster-snapshot --region $AWS_REGION"
              sleep 60
              log "Delete AWS security group sg$cluster"
              check_if_skip "aws ec2 delete-security-group --group-name sg$cluster --region $AWS_REGION"
          fi
      done

      log "Cleanup AWS DynamoDB tables"
      for dynamo_table in $(aws dynamodb list-tables --region $AWS_REGION | jq '.TableNames[].TableName' -r)
      do
          if [[ $dynamo_table = *pg${user}* ]]
          then
              log "Removing AWS dynamodb table $dynamo_table"
              check_if_skip "aws dynamodb delete-table --table-name ${dynamo_table}"
          fi
      done
  }

  function cleanup_azure () {
      if [ ! -z "$AZ_USER" ] && [ ! -z "$AZ_PASS" ]
      then
          az logout
          az login -u "$AZ_USER" -p "$AZ_PASS" > /dev/null 2>&1
      fi

      maybe_set_azure_subscription

      log "Cleanup Azure Resource groups"
      for group in $(az group list --query '[].name' --output tsv)
      do
      if [[ $group = pg${user}* ]]
      then
          if [ ! -z "$GITHUB_RUN_NUMBER" ]
          then
          job=$(echo $GITHUB_RUN_NUMBER | cut -d "." -f 1)
          if [[ $group = pg$user$job* ]]
          then
              log "Skipping current github actions $job"
              continue
          fi
          fi
          log "Deleting Azure resource group $group"
          check_if_skip "az group delete --name $group --yes --no-wait"
      fi
      done
  }

  function cleanup_gcp () {
      log "Cleanup GCP GCS buckets"
      GCP_KEYFILE="$tmp_dir/keyfile.json"
      echo -e "$GCP_KEYFILE_CONTENT" | sed 's/\\"/"/g' > ${GCP_KEYFILE}
      docker rm -f gcloud-config-cleanup-resources > /dev/null 2>&1
      docker run -i -v ${GCP_KEYFILE}:/tmp/keyfile.json --name gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud auth activate-service-account --project ${GCP_PROJECT} --key-file /tmp/keyfile.json > /dev/null 2>&1

      for bucket in $(docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gsutil ls)
      do
          if [[ $bucket = *kafkadockerplaygroundbucket${user}* ]]
          then
              log "Removing GCS bucket $bucket"
              check_if_skip "docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gsutil -m rm -r $bucket"
          fi
      done

      log "Cleanup GCP BQ datasets"
      for dataset in $(docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest bq --project_id "$GCP_PROJECT" ls)
      do
          if [[ $dataset = *pg${user}* ]]
          then
              log "Remove GCP BQ dataset $dataset"
              check_if_skip "docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest bq --project_id \"$GCP_PROJECT\" rm -r -f -d \"$dataset\""
          fi
      done

      GCP_SPANNER_INSTANCE="spanner-instance-$USER"
      GCP_SPANNER_DATABASE="spanner-db-$USER"
      log "Deleting Spanner database $GCP_SPANNER_DATABASE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud spanner databases delete $GCP_SPANNER_DATABASE --instance $GCP_SPANNER_INSTANCE --project $GCP_PROJECT << EOF > /dev/null 2>&1
Y
EOF
      log "Deleting Spanner instance $GCP_SPANNER_INSTANCE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud spanner instances delete $GCP_SPANNER_INSTANCE --project $GCP_PROJECT  << EOF > /dev/null 2>&1
Y
EOF

      GCP_BIGTABLE_INSTANCE="bigtable-$USER"
      log "Delete BigTable table kafka_big_query_stats"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest cbt -project $GCP_PROJECT -instance $GCP_BIGTABLE_INSTANCE deletetable kafka_big_query_stats

      log "Deleting BigTable instance $GCP_BIGTABLE_INSTANCE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud bigtable instances delete $GCP_BIGTABLE_INSTANCE --project $GCP_PROJECT << EOF > /dev/null 2>&1
Y
EOF
  }

  function cleanup_ccloud () {
      cleanup_confluent_cloud_resources

      if [ ! -z "$AWS_DATABRICKS_CLUSTER_NAME" ]
      then
          log "AWS_DATABRICKS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_DATABRICKS_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AWS_DATABRICKS_CLUSTER_NAME
          export CLUSTER_REGION=$AWS_DATABRICKS_CLUSTER_REGION
          export CLUSTER_CLOUD=$AWS_DATABRICKS_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AWS_DATABRICKS_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$AWS_CLUSTER_NAME" ]
      then
          log "AWS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AWS_CLUSTER_NAME
          export CLUSTER_REGION=$AWS_CLUSTER_REGION
          export CLUSTER_CLOUD=$AWS_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AWS_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$GCP_CLUSTER_NAME" ]
      then
          log "GCP_CLUSTER_NAME environment variable is set, forcing the cluster $GCP_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$GCP_CLUSTER_NAME
          export CLUSTER_REGION=$GCP_CLUSTER_REGION
          export CLUSTER_CLOUD=$GCP_CLUSTER_CLOUD
          export CLUSTER_CREDS=$GCP_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$AZURE_CLUSTER_NAME" ]
      then
          log "AZURE_CLUSTER_NAME environment variable is set, forcing the cluster $AZURE_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AZURE_CLUSTER_NAME
          export CLUSTER_REGION=$AZURE_CLUSTER_REGION
          export CLUSTER_CLOUD=$AZURE_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AZURE_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi
  }

  function cleanup_salesforce () {
      if [ ! -z $SALESFORCE_USERNAME ]
      then
          log "Cleanup Salesforce Leads on account with $SALESFORCE_USERNAME"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME\" -p \"$SALESFORCE_PASSWORD\" -r \"$SALESFORCE_INSTANCE\" -s \"$SALESFORCE_SECURITY_TOKEN\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME\" -q \"SELECT Id FROM Lead\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME\" -s Lead -f /tmp/out.csv"

          log "Cleanup Salesforce Contacts on account with $SALESFORCE_USERNAME"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME\" -p \"$SALESFORCE_PASSWORD\" -r \"$SALESFORCE_INSTANCE\" -s \"$SALESFORCE_SECURITY_TOKEN\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME\" -q \"SELECT Id FROM Contact\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME\" -s Contact -f /tmp/out.csv"
      fi

      if [ ! -z $SALESFORCE_USERNAME_ACCOUNT2 ]
      then
          log "Cleanup Salesforce Leads on account with $SALESFORCE_USERNAME_ACCOUNT2"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME_ACCOUNT2\" -p \"$SALESFORCE_PASSWORD_ACCOUNT2\" -r \"$SALESFORCE_INSTANCE_ACCOUNT2\" -s \"$SALESFORCE_SECURITY_TOKEN_ACCOUNT2\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -q \"SELECT Id FROM Lead\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -s Lead -f /tmp/out.csv"

          log "Cleanup Salesforce Contacts on account with $SALESFORCE_USERNAME_ACCOUNT2"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME_ACCOUNT2\" -p \"$SALESFORCE_PASSWORD_ACCOUNT2\" -r \"$SALESFORCE_INSTANCE_ACCOUNT2\" -s \"$SALESFORCE_SECURITY_TOKEN_ACCOUNT2\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -q \"SELECT Id FROM Contact\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -s Contact -f /tmp/out.csv"
      fi
  }

  for resource in "${resources[@]}"
  do
      case "${resource}" in

          "aws")
              cleanup_aws
          ;;
          "gcp")
              cleanup_gcp
          ;;
          "azure")
              cleanup_azure
          ;;
          "ccloud")
              cleanup_ccloud
          ;;
          "salesforce")
              cleanup_salesforce
          ;;
          *)
              logerror "default (none of above)"
          ;;
      esac
  done

  # always exit with success
  exit 0

}

# :command.function
playground_repro_export_command() {
  # src/commands/repro/export.sh
  all="${args[--all]}"

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "❌ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  output_filename="playground_repro_export.tgz"
  final_archive=$repro_dir/$output_filename
  if [ -f $final_archive ]
  then
      rm -rf $final_archive
  fi
  set +e
  if [[ -n "$all" ]]
  then
      if [ -d .git ]
      then
          new_files=$(git status --porcelain 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "💫 detected new files:"
              echo "$new_files"
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "📤 Exported archive is available: $final_archive"
              else
                  logerror "❌ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "❌ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $output_folder"
          tar cvfz "$output_filename" * > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "📤 Exported archive is available: $final_archive"
          else
              logerror "❌ export failed as archive could not be created !"
              exit 1
          fi
      fi
  else
      # copy only current example
      test_file=$(playground state get run.test_file)

      if [ ! -f $test_file ]
      then

          logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
          exit 1
      fi

      test_file_directory="$(dirname "${test_file}")"
      base1="${test_file_directory##*/}" # connect-connect-aws-s3-sink
      dir1="${test_file_directory%/*}" # reproduction-models
      dir2="${dir1##*/}/$base1" # reproduction-models/connect-connect-aws-s3-sink

      if [[ "$dir2" != ${output_folder}* ]]
      then
          logerror "example <$dir2> is not from OUTPUT_FOLDER ${output_folder} folder, only examples in there can be exported"
          exit 1
      fi

      if [ -d .git ]
      then
          cd $test_file_directory

          new_files=$(git status --porcelain . 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "💫 detected new files:"
              echo "$new_files"
              cd - >/dev/null
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "📤 Exported archive is available: $final_archive"
              else
                  logerror "❌ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "❌ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $test_file_directory"
          tar cvfz "$output_filename" $test_file_directory > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "📤 Exported archive is available: $final_archive"
          else
              logerror "❌ export failed as archive could not be created !"
              exit 1
          fi
      fi
  fi

}

# :command.function
playground_repro_import_command() {
  # src/commands/repro/import.sh
  file="${args[--file]}"

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "❌ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  if [[ $file == *"@"* ]]
  then
    file=$(echo "$file" | cut -d "@" -f 2)
  fi

  filename=$(basename $file)

  if [ "playground_repro_export.tgz" != ${filename} ]
  then
      logerror "file $file is not named playground_repro_export.tgz"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  log "📥 Installing $file"
  tar xvfz $file
}

# :command.function
playground_repro_bootstrap_command() {
  # src/commands/repro/bootstrap.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  test_file="${args[--file]}"
  description="${args[--description]}"
  producer="${args[--producer]}"
  nb_producers="${args[--nb-producers]}"
  add_custom_smt="${args[--custom-smt]}"

  eval "pipeline_array=(${args[--pipeline]})"

  schema_file_key="${args[--producer-schema-key]}"
  schema_file_value="${args[--producer-schema-value]}"

  if [[ ! -n "$test_file" ]]
  then
    display_interactive_menu_categories 1

    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi

    declare -a array_flag_list=()
    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi
    readonly MENU_LETS_GO="🏭 Create the reproduction model !" #0

    MENU_ENABLE_CUSTOM_SMT="🔧 Add custom SMT $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_ENABLE_CUSTOM_SMT})) ' ') --custom-smt"

    readonly MENU_DISABLE_CUSTOM_SMT="❌🔧 Disable custom SMT" #3
    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    stop=0
    description=""
    while [ $stop != 1 ]
    do
      length=${#pipeline_array[@]}
      if ((length > 0))
      then
        MENU_PIPELINE="🔖 Add another sink to pipeline $(printf '%*s' $((${MAX_LENGTH}-32-${#MENU_PIPELINE})) ' ') --pipeline"
      else
        MENU_PIPELINE="🔖 Create pipeline with sink $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_PIPELINE})) ' ') --pipeline"
      fi

      options=("$MENU_LETS_GO" "$MENU_PIPELINE" "$MENU_ENABLE_CUSTOM_SMT" "$MENU_DISABLE_CUSTOM_SMT" "$MENU_GO_BACK")

      connector_example=0
      get_connector_paths
      if [ "$connector_paths" != "" ]
      then
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          else
            connector_example=1
          fi
        done
      fi

      if [ $connector_example == 0 ]
      then
        for((i=1;i<4;i++)); do
          unset "options[$i]"
        done
      else
        if [[ $test_file == *"sink"* ]]
        then
          unset 'options[1]'
        fi
      fi

      if [ ! -z $CUSTOM_SMT ]
      then
        unset 'options[2]'
      else
        unset 'options[3]'
      fi

      if [ "$description" == "" ]
      then
        maybe_remove_flag "--description"
        set +e
        description=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="💭 " --header="enter a description for this repro model (it cannot be empty !)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        if [ "$description" == "" ]
        then
          continue
        fi
        array_flag_list+=("--description=$description")
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🛠 " --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)\n\n🛠️  Number of repro models available: $(get_cli_metric nb_existing_reproduction_models)\n\n⛳ flag list:\n$flag_string\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground repro bootstrap
      fi

      if [[ $res == *"$MENU_ENABLE_CUSTOM_SMT"* ]]
      then
        array_flag_list+=("--custom-smt")
        export CUSTOM_SMT=true
        add_custom_smt="true"
      fi
      if [[ $res == *"$MENU_DISABLE_CUSTOM_SMT"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--custom-smt"}")
        unset CUSTOM_SMT
        add_custom_smt=""
      fi

      if [[ $res == *"$MENU_PIPELINE"* ]]
      then
        sink_file=$(playground get-examples-list-with-fzf --without-repro --sink-only )
        if [[ $sink_file == *"@"* ]]
        then
          sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--pipeline=$sink_file")
        pipeline_array+=("$sink_file")
      fi
    done # end while loop stop
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "❌ test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ "$(dirname $test_file)" != /* ]]
  then
    logerror "❌ do not use relative path for test file!"
    exit 1
  fi

  if [ "$nb_producers" == "" ]
  then
    nb_producers=1
  fi

  if [[ -n "$schema_file_key" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "❌ --producer-schema-key is set but not --producer"
      exit 1
    fi

    if [[ "$producer" != *"with-key" ]]
    then
      logerror "❌ --producer-schema-key is set but --producer is not set with <with-key>"
      exit 1
    fi
  fi

  if [[ -n "$schema_file_value" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "❌ --producer-schema-value is set but not --producer"
      exit 1
    fi
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  topic_name="customer-$producer"
  topic_name=$(echo $topic_name | tr '-' '_')
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"
  filename="${filename%.*}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  length=${#pipeline_array[@]}
  if ((length > 0))
  then
    if [[ "$base1" != *source ]]
    then
      logerror "example <$base1> must be source connector example when building a pipeline !"
      exit 1
    fi

    if [[ "$dir2" != connect* ]]
    then
      logerror "example <$dir2> is not from connect folder, only connect in connect folder are supported"
      exit 1
    fi
  fi

  if [ "$producer" != "none" ]
  then
    if [[ "$base1" != *sink ]]
    then
      logerror "example <$base1> must be sink connector example when using a java producer !"
      exit 1
    fi
  fi

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
    log "📂 Output folder is $output_folder (set with OUTPUT_FOLDER environment variable)"
  else
    output_folder="reproduction-models"
    log "📂 Output folder is default $output_folder (you can change it by setting OUTPUT_FOLDER environment variable)"
  fi

  repro_dir=$root_folder/$output_folder/$final_dir
  mkdir -p $repro_dir
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  description_kebab_case="${description// /-}"
  description_kebab_case=$(echo "$description_kebab_case" | tr '[:upper:]' '[:lower:]')
  repro_test_file="$repro_dir/$filename-repro-$description_kebab_case.$extension"

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  log "✨ Creating file $repro_test_file"
  rm -f $repro_test_file
  cp $test_file $repro_test_file

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    set +e
    grep 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' "$test_file"
    if [ $? -eq 0 ]
    then
      # it means it is an environment example
      # need to create the docker-compose file
      docker_compose_file=""
      docker_compose_test_file="$repro_dir/docker-compose.repro-$description_kebab_case.yml"
      log "✨ Creating empty file $docker_compose_test_file"

      echo "---" > $docker_compose_test_file
      echo "version: '3.5'" >> $docker_compose_test_file
      echo "" >> $docker_compose_test_file
      echo "# override the services here, example " >> $docker_compose_test_file
      echo "# services:" >> $docker_compose_test_file
      echo "#    connect:" >> $docker_compose_test_file
      echo "#      environment:" >> $docker_compose_test_file
      echo "#        CONNECT_BOOTSTRAP_SERVERS: \"broker:9092\"" >> $docker_compose_test_file

      docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
      cp $test_file $tmp_dir/tmp_file
      line=$(grep -n 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' $test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line-1)) $tmp_dir/tmp_file; echo "DOCKER_COMPOSE_FILE_OVERRIDE=../../$output_folder/$final_dir/$docker_compose_test_file_name"; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      docker_compose_file=""
      logwarn "📁 Could not determine docker-compose override file from $test_file !"
    fi
    set -e
  fi

  if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    extension="${filename##*.}"
    filename="${filename%.*}"

    docker_compose_test_file="$repro_dir/$filename.repro-$description_kebab_case.$extension"
    log "✨ Creating file $docker_compose_test_file"
    rm -f $docker_compose_test_file
    cp ${docker_compose_file} $docker_compose_test_file

    docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
  fi

  if [ "${docker_compose_file}" != "" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    sed -e "s|$filename|$docker_compose_test_file_name|g" \
      $test_file > $repro_test_file
  fi

  set +e
  echo "#!/bin/bash" > $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "# 🗓️ date: `date`" >> $tmp_dir/intro
  echo "# 👤 author: `whoami`" >> $tmp_dir/intro
  echo "# 💡 description: $description" >> $tmp_dir/intro
  if [[ $description =~ ^[0-9]{6} ]]
  then
    numbers="${BASH_REMATCH[0]}"
    echo "# 🔮 ticket: https://confluent.zendesk.com/agent/tickets/$numbers" >> $tmp_dir/intro
  fi
  echo "# 🙋 how to use: https://github.com/confluentinc/kafka-docker-playground-internal/tree/master#how-to-use" >> $tmp_dir/intro
  string=$(grep "Quickly test " README.md)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
    short_url=$(echo $url | cut -d '#' -f 1)
    echo "# 🌐 documentation: $short_url" >> $tmp_dir/intro
  fi
  echo "# 🐳 playground website: https://kafka-docker-playground.io" >> $tmp_dir/intro
  echo "# 💬 comments:" >> $tmp_dir/intro
  echo "#" >> $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "" >> $tmp_dir/intro

  cat $tmp_dir/intro > $tmp_dir/tmp_file
  cat $repro_test_file | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  mv $tmp_dir/tmp_file $repro_test_file

  for file in README.md docker-compose*.yml keyfile.json stop.sh .gitignore sql-datagen
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      ln -sf ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  if [ "$producer" != "none" ]
  then
    case "${producer}" in
      avro)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      avro-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      none)
      ;;
      *)
        logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
        exit 1
      ;;
    esac
    original_topic_name=$(grep "\"topics\"" $repro_test_file | cut -d "\"" -f 4 | head -1)
    if [ "$original_topic_name" != "" ]
    then
      tmp=$(echo $original_topic_name | tr '-' '\-')
      sed -e "s|$tmp|$topic_name|g" \
          $repro_test_file > /tmp/tmp

      mv /tmp/tmp $repro_test_file
      # log "✨ Replacing topic $original_topic_name with $topic_name"
    fi

    for((i=1;i<=$nb_producers;i++)); do
      # looks like there is a maximum size for hostname in docker (container init caused: sethostname: invalid argument: unknown)
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}
      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      rm -rf $producer_hostname
      mkdir -p $repro_dir/$producer_hostname/
      cp -Ra ${test_file_directory}/../../other/schema-format-$producer/producer/* $repro_dir/$producer_hostname/

      if [[ -n "$schema_file_key" ]]
      then

        editor=$(playground config get editor)
        if [ "$editor" != "" ]
        then
          log "✨ Copy and paste the schema you want to use for the key, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/key_schema
          else
            $editor $tmp_dir/key_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
            exit 1
          else
            log "✨ Copy and paste the schema you want to use for the key, save and close the file to continue"
            code --wait $tmp_dir/key_schema
          fi
        fi
        case "${producer}" in
          avro-with-key)
            original_namespace=$(cat $tmp_dir/key_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi
            # replace record name with MyKey
            jq '.name = "MyKey"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/mykey.avsc
          ;;
          json-schema-with-key)
            # replace title name with ID
            jq '.title = "ID"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.json
          ;;
          protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/key_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/key_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|IdImpl|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with IdImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/key_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"IdImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      if [[ -n "$schema_file_value" ]]
      then

        editor=$(playground config get editor)
        if [ "$editor" != "" ]
        then
          log "✨ Copy and paste the schema you want to use for the value, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/value_schema
          else
            $editor $tmp_dir/value_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
            exit 1
          else
            log "✨ Copy and paste the schema you want to use for the value, save and close the file to continue"
            code --wait $tmp_dir/value_schema
          fi
        fi

        case "${producer}" in
          avro|avro-with-key)
            original_namespace=$(cat $tmp_dir/value_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi
            # replace record name with Customer
            jq '.name = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/customer.avsc
          ;;
          json-schema|json-schema-with-key)
            # replace title name with Customer
            jq '.title = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.json
          ;;
          protobuf|protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/value_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/value_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|CustomerImpl|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with CustomerImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/value_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"CustomerImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      # update docker compose with producer container
      if [[ "$dir1" = *connect ]]
      then
          cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:9092
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 1
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
      fi

      if [[ "$dir1" = *ccloud ]]
      then
          cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: \$BOOTSTRAP_SERVERS
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      KAFKA_SASL_MECHANISM: "PLAIN"
      KAFKA_SASL_JAAS_CONFIG: \$SASL_JAAS_CONFIG
      KAFKA_SECURITY_PROTOCOL: "SASL_SSL"
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 3
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: \$SCHEMA_REGISTRY_URL
      KAFKA_BASIC_AUTH_CREDENTIALS_SOURCE: \$BASIC_AUTH_CREDENTIALS_SOURCE
      KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: \$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
      EXTRA_ARGS:

    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
      fi
    done

    if [ "${docker_compose_file}" != "" ]
    then
      cp $docker_compose_test_file $tmp_dir/tmp_file
      line=$(grep -n 'services:' $docker_compose_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/producer; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $docker_compose_test_file

    else

      logwarn "As docker-compose override file could not be determined, you will need to add this manually:"
      cat $tmp_dir/producer
    fi

    for((i=1;i<=$nb_producers;i++)); do
      log "✨ Adding Java $producer producer in $repro_dir/$producer_hostname"
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      list="$list $producer_hostname"

    done
      cat << EOF > $tmp_dir/build_producer
for component in $list
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
    # log "✨ Adding command to build jar for $producer_hostname to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ] || [ "$line_kafka_cli_producer" == "" ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $repro_test_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi
    set -e
    if [ $kafka_cli_producer_error = 1 ]
    then
      cat << EOF >> $tmp_dir/java_producer
# 🚨🚨🚨 FIXTHIS: move it to the correct place 🚨🚨🚨
EOF
    fi

    for((i=1;i<=$nb_producers;i++)); do
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi
      get_producer_run_heredoc
    done
    if [ $kafka_cli_producer_error = 1 ]
    then
      cat << EOF >> $tmp_dir/java_producer
# 🚨🚨🚨 FIXTHIS: move it to the correct place 🚨🚨🚨
EOF
    fi
    # log "✨ Adding command to run producer to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file

    if [ $kafka_cli_producer_error == 1 ]
    then
        { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file
    else
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } > $repro_test_file
    fi

    # deal with converters

    sink_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    if [ "$sink_value_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing value.converter
      grep -vwE "\"value.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector value.converter to use same as producer:"
    cat $tmp_dir/value_converter

    if [ "$sink_key_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing key.converter
      grep -vwE "\"key.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector key.converter to use same as producer:"
    cat $tmp_dir/key_converter
  fi

  if [[ -n "$add_custom_smt" ]]
  then
    custom_smt_name=""
    custom_smt_name="MyCustomSMT-$description_kebab_case"
    custom_smt_name=${custom_smt_name:0:18}
    mkdir -p $repro_dir/$custom_smt_name/
    cp -Ra ../../other/custom-smt/MyCustomSMT/* $repro_dir/$custom_smt_name/
      cat << EOF > $tmp_dir/build_custom_smt
for component in $custom_smt_name
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF

    # log "✨ Adding command to build jar for $custom_smt_name to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    get_connector_paths
    if [ "$connector_paths" == "" ]
    then
        logwarn "❌ skipping as it is not an example with connector, but --custom-smt is set"
        exit 1
    else
      #  Loop on all connectors in CONNECT_PLUGIN_PATH and install custom SMT jar in lib folder
      for connector_path in ${connector_paths//,/ }
      do
        echo "log \"📂 Copying custom jar to connector folder $connector_path/lib/\"" >> $tmp_dir/build_custom_docker_cp_smt
        echo "docker cp $repro_dir/$custom_smt_name/target/MyCustomSMT-1.0.0-SNAPSHOT-jar-with-dependencies.jar connect:$connector_path/lib/" >> $tmp_dir/build_custom_docker_cp_smt
      done
      echo "log \"♻️ Restart connect worker to load\"" >> $tmp_dir/build_custom_docker_cp_smt
      echo "docker restart connect" >> $tmp_dir/build_custom_docker_cp_smt
      echo "sleep 45" >> $tmp_dir/build_custom_docker_cp_smt
    fi

    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line+2)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_docker_cp_smt; tail -n +$(($line+2)) $tmp_dir/tmp_file; } > $repro_test_file

    existing_transforms=$(grep "\"transforms\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$existing_transforms" == "" ]
    then
      echo "              \"transforms\": \"MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      log "🤖 Connector is using existing transforms $existing_transforms, the new custom SMT will be added to the list."

      # remove existing transforms
      grep -vwE "\"transforms\"" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      echo "              \"transforms\": \"MyCustomSMT,$existing_transforms\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    fi

  fi
  for sink_file in "${pipeline_array[@]}"; do
    if [[ -n "$sink_file" ]]
    then
      if [[ $sink_file == *"@"* ]]
      then
        sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
      fi
      test_sink_file_directory="$(dirname "${sink_file}")"

      # docker-compose part
      # determining the docker-compose file from from test_file
      docker_compose_sink_file=$(grep "start-environment" "$sink_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
      docker_compose_sink_file="${test_sink_file_directory}/${docker_compose_sink_file}"
      cp $docker_compose_test_file /tmp/1.yml
      cp $docker_compose_sink_file /tmp/2.yml
      yq ". *= load(\"/tmp/1.yml\")" /tmp/2.yml > $docker_compose_test_file

      connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
      sink_connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_sink_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
      if [ "$sink_connector_paths" == "" ]
      then
        logerror "cannot find CONNECT_PLUGIN_PATH in  ${docker_compose_sink_file}"
        exit 1
      else
        tmp_new_connector_paths="$connector_paths,$sink_connector_paths"
        new_connector_paths=$(echo "$tmp_new_connector_paths" | sed 's/ //g')
        cp $docker_compose_test_file /tmp/1.yml

        yq -i ".services.connect.environment.CONNECT_PLUGIN_PATH = \"$new_connector_paths\"" /tmp/1.yml
        cp /tmp/1.yml $docker_compose_test_file
      fi


      # sh part

      line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $repro_test_file | cut -d ":" -f 1 | tail -n1)
      line_final_environment=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)
      line_sink_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $sink_file | cut -d ":" -f 1 | tail -n1)

      line_sink_environment=$(grep -n 'playground start-environment' $sink_file | cut -d ":" -f 1 | tail -n1)

      # get converter info
      source_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
      if [ "$source_key_converter" == "" ]
      then
        log "💱 Source connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
      else
        if [ "$source_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          source_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
          if [ "$source_key_json_converter_schemas_enable" == "" ]
          then
            log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=true"
          else
            log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=$source_key_json_converter_schemas_enable"
          fi
        else
          log "💱 Source connector is using key.converter $source_key_converter"
        fi
      fi

      source_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
      if [ "$source_value_converter" == "" ]
      then
        log "💱 Source connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
      else
        if [ "$source_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          source_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
          if [ "$source_value_json_converter_schemas_enable" == "" ]
          then
            log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=true"
          else
            log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=$source_value_json_converter_schemas_enable"
          fi
        else
          log "💱 Source connector is using value.converter $source_value_converter"
        fi
      fi

      sink_key_converter=$(grep "\"key.converter\"" $sink_file | cut -d '"' -f 4)
      if [ "$sink_key_converter" == "" ]
      then
        log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
      else
        if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
          if [ "$sink_key_json_converter_schemas_enable" == "" ]
          then
            log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
          else
            log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
          fi
        else
          log "💱 Sink connector is using key.converter $sink_key_converter"
        fi
      fi

      sink_value_converter=$(grep "\"value.converter\"" $sink_file | cut -d '"' -f 4)
      if [ "$sink_value_converter" == "" ]
      then
        log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
      else
        if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
          if [ "$sink_value_json_converter_schemas_enable" == "" ]
          then
            log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
          else
            log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
          fi
        else
          log "💱 Sink connector is using value.converter $sink_value_converter"
        fi
      fi

      sed -n "$(($line_sink_source+1)),$(($line_sink_environment-1))p" $sink_file > $tmp_dir/pre_sink
      cp $repro_test_file $tmp_dir/tmp_file

      { head -n $(($line_final_environment-1)) $tmp_dir/tmp_file; cat $tmp_dir/pre_sink; tail -n +$line_final_environment $tmp_dir/tmp_file; } > $repro_test_file

      sed -n "$(($line_sink_environment+1)),$ p" $sink_file > $tmp_dir/tmp_file

      # deal with converters
      set +e
      if [ "$source_value_converter" == "" ] && [ "$sink_value_converter" == "" ]
      then
        # do nothing
        :
      else
        grep "\"value.converter" $repro_test_file > $tmp_dir/source_value_converter
        if [ "$sink_value_converter" == "" ]
        then
          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        else
          # remove existing value.converter
          grep -vwE "\"value.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        fi
        log "🔮 Changing Sink connector value.converter to use same as source:"
        cat $tmp_dir/source_value_converter
      fi
      if [ "$source_key_converter" == "" ] && [ "$sink_key_converter" == "" ]
      then
        # do nothing
        :
      else
        grep "\"key.converter" $repro_test_file > $tmp_dir/source_key_converter
        if [ "$sink_key_converter" == "" ]
        then
          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        else
          # remove existing key.converter
          grep -vwE "\"key.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        fi
        log "🔮 Changing Sink connector key.converter to use same as source:"
        cat $tmp_dir/source_key_converter
      fi
      set -e
      # need to remove cli which produces and change topic
      kafka_cli_producer_error=0
      kafka_cli_producer_eof=0
      line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)
      if [ $? != 0 ]
      then
          logwarn "Could not find kafka cli producer!"
          kafka_cli_producer_error=1
      fi
      set +e
      egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | grep EOF > /dev/null
      if [ $? = 0 ]
      then
          kafka_cli_producer_eof=1

          sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $tmp_dir/tmp_file > /tmp/tmp
          tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
          if [ $tmp == "" ]
          then
            logwarn "Could not determine EOF for kafka cli producer!"
            kafka_cli_producer_error=1
          fi
          line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
      fi

      if [ $kafka_cli_producer_error == 0 ]
      then
        if [ $kafka_cli_producer_eof == 0 ]
        then
          line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
        fi
        { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } >  $tmp_dir/tmp_file2
        cat  $tmp_dir/tmp_file2 >> $repro_test_file
      fi
      set -e

      awk -F'--topic ' '{print $2}' $repro_test_file > $tmp_dir/tmp
      sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
      original_topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

      if [ "$original_topic_name" != "" ]
      then
        cp $repro_test_file $tmp_dir/tmp_file
        line=$(grep -n '"topics"' $repro_test_file | cut -d ":" -f 1 | tail -n1)

        echo "              \"topics\": \"$original_topic_name\"," > $tmp_dir/topic_line
        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/topic_line; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
      else

        logwarn "Could not find original topic name! "
        logwarn "You would need to change topics config for sink by yourself."
      fi
    fi
  done

  cat $repro_test_file > $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# 🧠 below is a list of cli commands that are helpful at the end of an example" >> $tmp_dir/tmp_file
  echo "# 🧠 for full documentation, visit https://kafka-docker-playground.io/#/cli !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 🕵️ to check logs (see https://kafka-docker-playground.io/#/cli?id=%f0%9f%95%b5%ef%b8%8f-logs)" >> $tmp_dir/tmp_file
  echo "# Example: check logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --open" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 😴 use this command if you want to wait for a specific message to appear in logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --wait-for-log \"<text to search>\" --max-wait 600" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 🐢 use this command if you want to wait for connector consumer lag to be zero" >> $tmp_dir/tmp_file
  echo "# playground connector show-lag" >> $tmp_dir/tmp_file

  echo "exit 0" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# 🚀 below is a list of snippets that can help you to build your example !" >> $tmp_dir/tmp_file
  echo "# 🚀 for full documentation, visit https://kafka-docker-playground.io/#/ !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  if [[ "$base1" == *sink ]]
  then
    cat $root_folder/scripts/cli/snippets/sink.sh | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  fi

  mv $tmp_dir/tmp_file $repro_test_file

  chmod u+x $repro_test_file
  repro_test_filename=$(basename -- "$repro_test_file")

  log "🌟 command to run generated example"
  echo "playground run -f $repro_dir/$repro_test_filename"

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
      then
          echo "playground run -f $repro_dir/$repro_test_filename"| pbcopy
          log "📋 command to run generated example has been copied to the clipboard (disable with 'playground config set clipboard false')"
      fi
  fi

  playground state set run.test_file "$repro_dir/$repro_test_filename"
  playground state set run.connector_type "$(get_connector_type | tr -d '\n')"

  editor=$(playground config get editor)
  if [ "$editor" != "" ]
  then
    log "📖 Opening ${repro_test_filename} using configured editor $editor"
    $editor $repro_dir/$repro_test_filename
  else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
          logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
          exit 1
      else
          log "📖 Opening ${repro_test_filename} with code (default) - you can change editor by using playground config editor <editor>"
          code $repro_dir/$repro_test_filename
      fi
  fi

  increment_cli_metric nb_reproduction_models
  log "👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)"

  nb=$(find $root_folder -name *repro*.sh | wc -l)
  set_cli_metric nb_existing_reproduction_models $nb
  log "🛠️ Number of repro models available: $(get_cli_metric nb_existing_reproduction_models)"

  playground generate-fzf-find-files &
  playground open-docs --only-show-url
  playground run -f $repro_dir/$repro_test_filename --force-interactive-repro $flag_list
}

# :command.function
playground_get_docker_compose_command() {
  # src/commands/get-docker-compose.sh
  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi
  echo "$docker_command" > /tmp/tmp
  sed -e "s|up -d|config|g" \
      /tmp/tmp > /tmp/playground-command-config

  bash /tmp/playground-command-config

}

# :command.function
playground_schema_get_command() {
  # src/commands/schema/get.sh
  subject="${args[--subject]}"
  id="${args[--id]}"
  deleted="${args[--deleted]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  #log "tmp_dir is $tmp_dir"

  if [[ -n "$id" ]]
  then
      if [[ -n "$verbose" ]]
      then
          log "🐞 curl command used"
          echo "curl $sr_security -s "${sr_url}/schemas/ids/${id}""
      fi

      curl_output=$(curl $sr_security -s "${sr_url}/schemas/ids/${id}")
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              message=$(echo "$curl_output" | jq -r .message)
              logerror "❌ Command failed with error code $error_code"
              logerror "$message"
              exit 1
          else
              versions=$(curl $sr_security -s "${sr_url}/schemas/ids/${id}")
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output" | jq .
      exit 0
  fi

  if [[ ! -n "$subject" ]]
  then
      log "✨ --subject flag was not provided, applying command to all subjects"
      if [[ -n "$deleted" ]]
      then
          subject=$(playground get-subject-list)
          echo "$subject" > $tmp_dir/subjects-all
          log "🧟 deleted subjects are included"
          subject=$(playground get-subject-list --deleted)
          echo "$subject" > $tmp_dir/subjects-deleted-tmp

          sort $tmp_dir/subjects-all $tmp_dir/subjects-deleted-tmp | uniq -u > $tmp_dir/subjects-deleted
      else
          subject=$(playground get-subject-list)
      fi
      if [ "$subject" == "" ]
      then
          logerror "❌ No subject found !"
          exit 1
      fi
  fi

  maybe_include_deleted=""
  if [[ -n "$deleted" ]]
  then
      maybe_include_deleted="?deleted=true"
  fi

  found=0
  items=($subject)
  for subject in ${items[@]}
  do
      if [[ -n "$verbose" ]]
      then
          log "🐞 curl command used"
          echo "curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted""
      fi

      curl_output=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted")
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              message=$(echo "$curl_output" | jq -r .message)
              if [ "$error_code" == "40401" ]
              then
                  continue
              fi
          else
              versions=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted")
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi

      for version in $(echo "${versions}" | jq -r '.[]')
      do
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .schemaType)
          id=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .id)
          case "${schema_type}" in
          JSON|null)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted" | jq .)
          ;;
          PROTOBUF)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted")
          ;;
          esac

          if [ -f $tmp_dir/subjects-deleted ] && grep "${subject}" $tmp_dir/subjects-deleted
          then
              log "🧟 (deleted) subject ${subject} 💯 version ${version} (id $id)"
          else
              log "🔰 subject ${subject} 💯 version ${version} (id $id)"
          fi
          found=1

          if [[ -n "$verbose" ]]
          then
              log "🐞 curl command used"
              echo "curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted""
          fi
          echo "${schema}"
      done
  done

  if [[ -n "$subject" ]]
  then
      if [ $found -eq 0 ]
      then
          logerror "❌ No schema found !"
          exit 1
      fi
  fi
}

# :command.function
playground_schema_register_command() {
  # src/commands/schema/register.sh
  subject="${args[--subject]}"
  schema="${args[--schema]}"
  id="${args[--id]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  #log "tmp_dir is $tmp_dir"
  schema_file=$tmp_dir/value_schema

  if [ "$schema" = "-" ]
  then
      schema_content=$(cat "$schema")
      echo "$schema_content" > $schema_file
  else
      if [[ $schema == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$schema" | cut -d "@" -f 2)
          cp $argument_schema_file $schema_file
      elif [ -f "$schema" ]
      then
          cp $schema $schema_file
      else
          schema_content=$schema
          echo "$schema_content" > $schema_file
      fi
  fi

  if grep -q "\"references\"\s*:" $schema_file
  then
      :
  elif grep -q "proto3" $schema_file
  then
      log "🔮 schema was identified as protobuf"
      schema_type=PROTOBUF
  elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
  then
      log "🔮 schema was identified as json schema"
      schema_type=JSON
  elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
  then
      log "🔮 schema was identified as avro"
      schema_type=AVRO
  else
      logerror "❌ no known schema could be identified"
      exit 1
  fi

  if grep -q "\"references\"\s*:" $schema_file
  then
      log "🔮 schema was identified with references, sending as is"
      json_new=$(cat $schema_file | tr -d '\n' | tr -s ' ')
  else
      json="{\"schemaType\":\"$schema_type\"}"
      content=$(cat $schema_file | tr -d '\n' | tr -s ' ')
      json_new=$(echo $json | jq --arg content "$content" '. + { "schema": $content }')
  fi

  if [[ -n "$id" ]]
  then
      function set_back_read_write {
          set +e
          curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "READWRITE"}' > /dev/null 2>&1
          set -e
      }
      trap set_back_read_write EXIT

      log "Deleting 🫵 id ${id} for subject 🔰 ${subject} permanently"
      playground schema delete --subject "${subject}" --id ${id} --permanent > /dev/null 2>&1

      log "Setting mode to IMPORT"
      curl_output=$(curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "IMPORT"}' | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"

      log "⏺️☢️ Registering schema to subject ${subject} with id $id"
      json_new_force_id=$(echo $json_new | jq --arg id "$id" '. + { "id": $id }')
      curl_output=$(curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new_force_id" | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"

      log "Setting mode to READWRITE"
      curl_output=$(curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "READWRITE"}' | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"
      exit 0
  fi

  # check if schema already exists
  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#post--subjects-(string-%20subject)
  curl_output=$(curl $sr_security --request POST -s "${sr_url}/subjects/${subject}" \
  --header 'Content-Type: application/vnd.schemaregistry.v1+json' \
  --data "$json_new" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
          then
              message=$(echo "$curl_output" | jq -r .message)
              logerror "Command failed with error code $error_code"
              logerror "$message"
              exit 1
          fi
      else
          id=$(echo "$curl_output" | jq -r .id)
          version=$(echo "$curl_output" | jq -r .version)
          log "🚪 Skipping as schema already exists with id $id (version $version)"
          exit 0
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi

  log "⏺️ Registering schema to subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new""
  fi
  curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new" | jq .

}

# :command.function
playground_schema_get_compatibility_command() {
  # src/commands/schema/get-compatibility.sh
  subject="${args[--subject]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🛡️ Get compatibility for subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/config/${subject}""
  fi
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/config/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_compatibility_command() {
  # src/commands/schema/set-compatibility.sh
  subject="${args[--subject]}"
  compatibility="${args[--compatibility]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🛡️ Set compatibility for subject ${subject} to $compatibility"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${subject}""
  fi
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_get_mode_command() {
  # src/commands/schema/get-mode.sh
  subject="${args[--subject]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🔏 Get mode for subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/mode/${subject}""
  fi
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/mode/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_mode_command() {
  # src/commands/schema/set-mode.sh
  subject="${args[--subject]}"
  mode="${args[--mode]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🔏 Set mode for subject ${subject} to $mode"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"mode\": \"$mode\"}" "${sr_url}/mode/${subject}""
  fi
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"mode\": \"$mode\"}" "${sr_url}/mode/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_delete_command() {
  # src/commands/schema/delete.sh
  subject="${args[--subject]}"
  version="${args[--version]}"
  id="${args[--id]}"
  permanent="${args[--permanent]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  if [[ -n "$version" ]]
  then
      if [[ ! -n "$subject" ]]
      then
          logerror "❌ --version is set without --subject being set"
          exit 1
      fi
  fi

  if [[ -n "$id" ]]
  then
      if [[ ! -n "$subject" ]]
      then
          logerror "❌ --id is set without --subject being set"
          exit 1
      fi
  fi

  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#delete--subjects-(string-%20subject)-versions-(versionId-%20version)
  if [[ -n "$subject" ]]
  then
      if [[ -n "$version" ]]
      then
          log "🧟 Soft deleting 💯 version ${version} from subject 🔰 ${subject}"
          if [[ -n "$verbose" ]]
          then
              log "🐞 curl command used"
              echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}""
          fi
          curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}" | jq .
          if [[ -n "$permanent" ]]
          then
              log "💀 Hard deleting 💯 version ${version} from subject 🔰 ${subject}"
              if [[ -n "$verbose" ]]
              then
                  log "🐞 curl command used"
                  echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}?permanent=true""
              fi
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}?permanent=true" | jq .
          fi
      else
          if [[ -n "$version" ]]
          then
              log "🧟 Soft deleting 🫵 id ${id} for subject 🔰 ${subject}"
              if [[ -n "$verbose" ]]
              then
                  log "🐞 curl command used"
                  echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${id}""
              fi
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${id}" | jq .
              if [[ -n "$permanent" ]]
              then
                  log "💀 Hard deleting 🫵 id ${id} for subject 🔰 ${subject}"
                  if [[ -n "$verbose" ]]
                  then
                      log "🐞 curl command used"
                      echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${id}?permanent=true""
                  fi
                  curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${id}?permanent=true" | jq .
              fi
          else
              logwarn "--version is not set, deleting all versions !"
              log "🧟 Soft deleting subject 🔰 ${subject}"
              if [[ -n "$verbose" ]]
              then
                  log "🐞 curl command used"
                  echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}""
              fi
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}" | jq .
              if [[ -n "$permanent" ]]
              then
                  log "💀 Hard deleting subject 🔰 ${subject}"
                  if [[ -n "$verbose" ]]
                  then
                      log "🐞 curl command used"
                      echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}?permanent=true""
                  fi
                  curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}?permanent=true" | jq .
              fi
          fi
      fi
  fi
}

# :command.function
playground_debug_install_vscode_extension_command() {
  # src/commands/debug/install-vscode-extension.sh
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  extension_dir=$tmp_dir/extension

  mkdir $extension_dir
  cd $extension_dir

  log "🪄 Installing Shell Script Command Completion extension"

  curl -s -L https://tetradresearch.gallery.vsassets.io/_apis/public/gallery/publisher/tetradresearch/extension//vscode-h2o/latest/assetbyname/Microsoft.VisualStudio.Services.VSIXPackage -o extension.zip
  unzip extension.zip > /dev/null 2>&1

  if [ ! -f extension/out/cacheFetcher.js ]
  then
    logerror "❌ cacheFetcher.js is not present !"
    exit 1
  fi

  if grep 'https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/${kind}/json/${name}.json' extension/out/cacheFetcher.js
  then
      sed -i -E -e "s|https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/\${kind}/json/\${name}.json|https://raw.githubusercontent.com/vdesabou/kafka-docker-playground/master/scripts/cli/playground.json|g" extension/out/cacheFetcher.js > /dev/null 2>&1
      zip -r extension.zip extension > /dev/null 2>&1
      mv extension.zip extension.vsix

      set +e
      code --uninstall-extension extension.vsix > /dev/null 2>&1

      code --install-extension extension.vsix > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "👏 extension is now installed"
      else
          logerror "❌ Failed to install Shell Script Command Completion extension"
      fi
  else
    logerror "❌ cannot retrieve experimental url"
    exit 1
  fi

}

# :command.function
playground_debug_enable_remote_debugging_command() {
  # src/commands/debug/enable-remote-debugging.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  container="${args[--container]}"

  log "Enable remote debugging for $container"

  # For ccloud case
  if [ -f $root_folder/.ccloud/env.delta ]
  then
       source $root_folder/.ccloud/env.delta
  fi

  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi
  echo "$docker_command" > /tmp/tmp
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  cat << EOF > $tmp_dir/docker-compose-remote-debugging.yml
version: '3.5'
services:
  $container:
    environment:
      # https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging
      KAFKA_DEBUG: 'true'
      # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
EOF

  sed -e "s|up -d|-f $tmp_dir/docker-compose-remote-debugging.yml up -d|g" \
      /tmp/tmp > /tmp/playground-command-debugging

  load_env_variables
  bash /tmp/playground-command-debugging

  log "If you use Visual Studio Code:"
  log "Edit .vscode/launch.json with"

  log "
  {
      \"version\": \"0.2.0\",
      \"configurations\": [

          {
              \"type\": \"java\",
              \"name\": \"Debug $component container\",
              \"request\": \"attach\",
              \"hostName\": \"127.0.0.1\",
              \"port\": 5005,
              \"timeout\": 30000
          }
      ]
  }
  "

  log "See https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging"
}

# :command.function
playground_debug_testssl_command() {
  # src/commands/debug/testssl.sh
  arguments="${args[arguments]}"

  log "🔐 Testing TLS/SSL encryption with arguments $arguments"
  docker run --quiet --rm -ti  drwetter/testssl.sh $arguments
}

# :command.function
playground_debug_generate_diagnostics_command() {
  # src/commands/debug/generate-diagnostics.sh
  container="${args[--container]}"
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ "$container" == "connect" ]] || [[ "$container" == "broker" ]]
  then
      log "⛑️ Creating diagnostics bundle for container ${container}"
      log "⏳ please wait..."
  else
      logerror "❌ only connect and broker containers are supported"
      exit 1
  fi

  docker exec $container curl -L https://packages.confluent.io/tools/diagnostics-bundle/diagnostics-bundle-1.0.0.jar -o /tmp/diagnostics-bundle-1.0.0.jar > /dev/null 2>&1

  fifo_path="$tmp_dir/collect_fifo"
  mkfifo "$fifo_path"

  set +e
  docker exec $container java -jar /tmp/diagnostics-bundle-1.0.0.jar collect > "$fifo_path" 2>&1 &

  # Loop through each line in the named pipe
  while read -r line
  do
      echo "$line"
      echo "$line" >> $tmp_dir/result.log

  done < "$fifo_path"

  nb=$(grep -c "Diagnostics output has been zipped and written to" $tmp_dir/result.log)
  if [ $nb -eq 0 ]
  then
      logerror "❌ Failed to generate bundle"
      cat $tmp_dir/result.log
      exit 1
  fi
  bundle_file=$(cat $tmp_dir/result.log | grep "Diagnostics output has been zipped and written to" | cut -d ":" -f 4 | sed 's/ //g')
  bundle_file_filename=$(basename -- "$bundle_file")
  log "⛑️ diagnostics bundle is available at ${bundle_file_filename}"
  docker cp ${container}:${bundle_file} ${bundle_file_filename}
}

# :command.function
playground_debug_thread_dump_command() {
  # src/commands/debug/thread-dump.sh
  container="${args[--container]}"
  filename="/tmp/thread-dump-$container-`date '+%Y-%m-%d-%H-%M-%S'`.log"

  set +e
  docker exec $container type jstack > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ jstack is not installed on container $container"
      exit 1
  fi
  set -e
  log "🎯 Taking thread dump on container ${container} for pid 1"
  docker exec $container jstack 1 > "$filename" 2>&1
  if [ $? -eq 0 ]
  then
      editor=$(playground config get editor)
      if [ "$editor" != "" ]
      then
          log "📖 Opening ${filename} using configured editor $editor"
          $editor ${filename}
      else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
              exit 1
          else
              log "📖 Opening ${filename} with code (default) - you can change editor by using playground config editor <editor>"
              code ${filename}
          fi
      fi
  else
      logerror "❌ Failed to take thread dump"
  fi
}

# :command.function
playground_debug_heap_dump_command() {
  # src/commands/debug/heap-dump.sh
  container="${args[--container]}"
  filename="heap-dump-$container-`date '+%Y-%m-%d-%H-%M-%S'`.hprof"

  set +e
  docker exec $container type jmap > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ jmap is not installed on container $container"
      exit 1
  fi
  set -e
  log "🎯 Taking heap dump on container ${container} for pid 1"
  docker exec $container jmap -dump:live,format=b,file=/tmp/${filename} 1
  if [ $? -eq 0 ]
  then
      log "👻 heap dump is available at ${filename}"
      docker cp ${container}:/tmp/${filename} ${filename}
      # if [[ $(type -f wireshark 2>&1) =~ "not found" ]]
      # then
      #     logwarn "🦈 wireshark is not installed, grab it at https://www.wireshark.org/"
      #     exit 0
      # else
      #     log "🦈 Opening ${filename} with wireshark"
      #     wireshark ${filename}
      # fi

  else
      logerror "❌ Failed to take heap dump"
  fi

}

# :command.function
playground_debug_tcp_dump_command() {
  # src/commands/debug/tcp-dump.sh
  container="${args[--container]}"
  port="${args[--port]}"
  duration="${args[--duration]}"
  filename="tcp-dump-$container-$port-`date '+%Y-%m-%d-%H-%M-%S'`.pcap"

  set +e
  docker exec $container which tcpdump > /dev/null 2>&1
  if [ $? != 0 ]
  then
    logwarn "tcpdump is not installed on container $container, attempting to install it"
    docker exec --privileged --user root $container bash -c "rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm" > /dev/null 2>&1
    docker exec --privileged --user root $container bash -c "curl http://mirror.centos.org/centos/8-stream/AppStream/x86_64/os/Packages/tcpdump-4.9.3-1.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm" > /dev/null 2>&1

    if [ "$container" == "ngrok" ]
    then
      playground container exec -c ngrok --command "adduser --force-badname --system --no-create-home _apt" --root > /dev/null 2>&1
    fi
    docker exec --privileged --user root $container bash -c "apt-get update && echo tcpdump | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*" > /dev/null 2>&1
  fi
  docker exec $container which tcpdump > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ tcpdump could not be installed"
      exit 1
  fi
  set -e

  set +e
  docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
  set -e

  if [[ -n "$port" ]]
  then
    log "🕵️‍♂️ Taking tcp dump on container ${container} and port ${port} for ${duration} seconds..."
    docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename} port ${port}"
  else
    log "🕵️‍♂️ Taking tcp dump on container ${container} and all ports for ${duration} seconds..."
    docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename}"
  fi

  if [ $? -eq 0 ]
  then
      playground container get-ip-addresses
      sleep $duration
      set +e
      docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
      set -e
      log "🌶️ tcp dump is available at ${filename}"
      docker cp ${container}:/tmp/${filename} ${filename}
      if [[ $(type -f wireshark 2>&1) =~ "not found" ]]
      then
          logwarn "🦈 wireshark is not installed, grab it at https://www.wireshark.org/"
          exit 0
      else
          log "🦈 Opening ${filename} with wireshark"
          wireshark ${filename}
      fi

  else
      logerror "❌ Failed to take tcp dump"
  fi

}

# :command.function
playground_debug_block_traffic_command() {
  # src/commands/debug/block-traffic.sh
  container="${args[--container]}"
  port="${args[--port]}"
  destination="${args[--destination]}"
  action="${args[--action]}"

  set +e
  docker exec $container type iptables > /dev/null 2>&1
  if [ $? != 0 ]
  then
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "Could not find current CP version from docker ps"
          exit 1
      fi
      logwarn "iptables is not installed on container $container, attempting to install it"
      if [[ "$tag" == *ubi8 ]] || version_gt $tag "5.9.0"
      then
        docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' iptables"
      else
        docker exec --privileged --user root $container bash -c "apt-get update && echo iptables | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
      fi
  fi
  docker exec $container type iptables > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ iptables could not be installed"
      exit 1
  fi
  set -e

  ip_pattern="^([0-9]{1,3}\.){3}[0-9]{1,3}$"

  function get_container_ip() {
      local container_ip=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "$1")
      if [ $? -eq 0 ]
      then
          echo "$container_ip"
      fi
  }

  function get_ip_by_nslookup() {
      local ip_address=$(nslookup "$1" | awk '/^Address: / { print $2 }')
      if [ $? -eq 0 ]
      then
          echo "$ip_address"
      fi
  }

  ip=""
  if [[ $destination =~ $ip_pattern ]]
  then
      ip=$destination
  else
      ip_address=$(get_container_ip "$destination")
      if [[ -n $ip_address ]]
      then
          ip=$ip_address
      else
          log "🌐 Using nslookup to get IP address..."
          ip_address=$(get_ip_by_nslookup "$destination")
          if [[ -n $ip_address ]]
          then
              ip=$ip_address
          else
              logerror "❌ Unable to retrieve IP address for $destination using nslookup"
              exit 1
          fi
      fi
  fi

  case "${action}" in
      start)
          action="A"
          if [[ -n "$port" ]]
          then
              log "🚫 Blocking traffic on container ${container} and port ${port} for destination ${destination} (${ip})"
          else
              log "🚫 Blocking traffic on container ${container} for all ports for destination ${destination} (${ip})"
          fi
      ;;
      stop)
          action="D"

          if [[ -n "$port" ]]
          then
              log "🟢 Unblocking traffic on container ${container} and port ${port} for destination ${destination} (${ip})"
          else
              log "🟢 Unblocking traffic on container ${container} for all ports from destination ${destination} (${ip})"
          fi
      ;;
      *)
          logerror "should not happen"
          exit 1
      ;;
  esac

  if [[ -n "$port" ]]
  then
    docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} --sport ${port} -j DROP"
  else
    docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} -j DROP"
  fi

  log "Output of command iptables-save"
  docker exec --privileged --user root ${container} bash -c "iptables-save"

}

# :command.function
playground_debug_flight_recorder_command() {
  # src/commands/debug/flight-recorder.sh
  container="${args[--container]}"
  action="${args[--action]}"
  filename="flight-recorder-$container-`date '+%Y-%m-%d-%H-%M-%S'`.jfr"

  set +e
  docker exec $container type jcmd > /dev/null 2>&1
  if [ $? != 0 ]
  then
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "Could not find current CP version from docker ps"
          exit 1
      fi

      logwarn "jcmd is not installed on container $container, attempting to install it"

      if [[ "$tag" == *ubi8 ]] || version_gt $tag "5.9.0"
      then
        docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' openjdk"
      else
        docker exec --privileged --user root $container bash -c "apt-get update && echo openjdk | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
      fi
  fi
  docker exec $container type jcmd > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ jcmd could not be installed"
      exit 1
  fi
  set -e

  case "${action}" in
      start)
          set +e
          output=$(docker exec ${container} jcmd 1 JFR.check)
          echo "$output" | grep "running" | grep "dump1"
          if [ $? -eq 0 ]
          then
              logwarn "🛩️ flight recorder is already started !"
              exit 0
          fi
          set -e

          docker cp ${root_folder}/scripts/cli/all.jfc ${container}:/tmp/all.jfc > /dev/null 2>&1
          docker exec ${container} jcmd 1 JFR.start name=dump1 filename=/tmp/${filename} settings=/tmp/all.jfc
          if [ $? -eq 0 ]
          then
              log "🛩️ flight recorder is now started"
          else
              logerror "❌ Failed to start flight recorder"
          fi
      ;;
      stop)
          set +e
          output=$(docker exec ${container} jcmd 1 JFR.check)
          echo "$output" | grep "running" | grep "dump1"
          if [ $? -ne 0 ]
          then
              logerror "🛩️ flight recorder is not started !"
              exit 1
          fi
          set -e
          docker exec ${container} jcmd 1 JFR.stop name=dump1 filename=/tmp/${filename}
          if [ $? -eq 0 ]
          then
              log "🛩️ flight recorder is available at ${filename}"
              log "use JDK Mission Control JMC (https://jdk.java.net/jmc/) to open it"
              docker cp ${container}:/tmp/${filename} ${filename}
          else
              logerror "❌ Failed to stop flight recorder"
          fi
      ;;
      *)
          logerror "should not happen"
          exit 1
      ;;
  esac
}

# :command.function
playground_debug_log_level_get_command() {
  # src/commands/debug/log-level/get.sh
  get_connect_url_and_security

  package="${args[--package]}"

  if [[ -n "$package" ]]
  then
    log "🧬 Get log level for package $package"
    curl $security -s "$connect_url/admin/loggers/$package"
  else
    log "🧬 Get log level for all packages"
    curl $security -s "$connect_url/admin/loggers" | jq .
  fi
}

# :command.function
playground_debug_log_level_set_command() {
  # src/commands/debug/log-level/set.sh
  get_connect_url_and_security

  package="${args[--package]}"
  level="${args[--level]}"

  current_level=$(curl $security -s "$connect_url/admin/loggers/$package" | jq -r '.level')

  if [ "$current_level" != "$level" ]
  then
      log "🧬 Set log level for package $package to $level"
      curl $security -s --request PUT \
      --url "$connect_url/admin/loggers/$package" \
      --header 'Accept: application/json' \
      --header 'Content-Type: application/json' \
      --data "{
      \"level\": \"$level\"
      }" | jq .

      playground debug log-level get -p "$package"
  else
      log "🧬⏭️ Skipping as log level for package $package was already set to $level"
  fi
}

# :command.function
playground_get_jmx_metrics_command() {
  # src/commands/get-jmx-metrics.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  container="${args[--container]}"
  domain="${args[--domain]}"
  open="${args[--open]}"

  case "${container}" in
    zookeeper|broker|schema-registry|connect|connect2|connect3)
    ;;
    *)
      logerror "ERROR: container name not valid ! Should be one of zookeeper, broker, schema-registry, connect, connect2 or connect3"
      exit 1
    ;;
  esac

  get_jmx_metrics "$container" "$domain" "$open"
}

# :command.function
playground_container_get_properties_command() {
  # src/commands/container/get-properties.sh
  container="${args[--container]}"

  log "Displaying properties file for $container"

  docker exec -i "$container" sh << EOF
ps -ef | grep properties | grep java | grep -v grep | awk '{ print \$NF }' > /tmp/propertie_file
propertie_file=\$(cat /tmp/propertie_file)
if [ ! -f \$propertie_file ]
then
  logerror 'ERROR: Could not determine properties file!'
  exit 1
fi
cat \$propertie_file | grep -v None | grep . | sort
EOF
}

# :command.function
playground_container_recreate_command() {
  # src/commands/container/recreate.sh
  ignore_current_versions="${args[--ignore-current-versions]}"

  export IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  if [[ ! -n "$ignore_current_versions" ]]
  then
    # keep TAG and CONNECT_TAG
    export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
    export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  fi

  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi

  get_environment_used
  if [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
  fi

  echo "$docker_command" > /tmp/playground-command
  log "💫 Recreate container(s)"
  bash /tmp/playground-command
}

# :command.function
playground_container_get_ip_addresses_command() {
  # src/commands/container/get-ip-addresses.sh
  log "Get IP address of running containers"
  docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
}

# :command.function
playground_container_kill_all_command() {
  # src/commands/container/kill-all.sh
  log "💀 Kill all docker containers"
  docker rm -f $(docker ps -qa) > /dev/null 2>&1
}

# :command.function
playground_container_logs_command() {
  # src/commands/container/logs.sh
  container="${args[--container]}"
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"

  if [[ -n "$open" ]]
  then
    filename="/tmp/${container}-`date '+%Y-%m-%d-%H-%M-%S'`.log"
    docker container logs "$container" > "$filename" 2>&1
    if [ $? -eq 0 ]
    then
      editor=$(playground config get editor)
      if [ "$editor" != "" ]
      then
          log "📖 Opening ${filename} using configured editor $editor"
          $editor ${filename}
      else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
              exit 1
          else
              log "📖 Opening ${filename} with code (default) - you can change editor by using playground config editor <editor>"
              code ${filename}
          fi
      fi
    else
      logerror "Failed to get logs using container logs $container"
    fi
  elif [[ -n "$log" ]]
  then
    wait_for_log "$log" "$container" "$max_wait"
  else

    docker container logs --tail=200 -f "$container"
  fi
}

# :command.function
playground_container_ssh_command() {
  # src/commands/container/ssh.sh
  container="${args[--container]}"
  shell="${args[--shell]}"

  docker exec -it "$container" "$shell"
}

# :command.function
playground_container_exec_command() {
  # src/commands/container/exec.sh
  container="${args[--container]}"
  command="${args[--command]}"
  root="${args[--root]}"
  shell="${args[--shell]}"

  if [[ -n "$root" ]]
  then
    log "Executing command as root in container $container with $shell"
    docker exec --privileged --user root $container $shell -c "$command"
  else
    log "Executing command in container $container with $shell"
    docker exec $container $shell -c "$command"
  fi
}

# :command.function
playground_container_restart_command() {
  # src/commands/container/restart.sh
  container="${args[--container]}"

  log "Restarting docker container ${container}"
  docker restart ${container}
}

# :command.function
playground_container_pause_command() {
  # src/commands/container/pause.sh
  container="${args[--container]}"

  log "Pausing docker container ${container}"
  docker pause ${container}
}

# :command.function
playground_container_resume_command() {
  # src/commands/container/resume.sh
  container="${args[--container]}"

  log "Resuming docker container ${container}"
  docker unpause ${container}
}

# :command.function
playground_container_kill_command() {
  # src/commands/container/kill.sh
  container="${args[--container]}"

  log "Killing docker container ${container}"
  docker kill ${container}
}

# :command.function
playground_topic_get_number_records_command() {
  # src/commands/topic/get-number-records.sh
  topic="${args[--topic]}"

  get_security_broker "--command-config"

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  get_environment_used

  items=($topic)
  for topic in ${items[@]}
  do
      log "💯 Get number of records in topic $topic"
      set +e
      playground topic describe --topic $topic > /tmp/result.log 2>/tmp/result.log
      grep "does not exist" /tmp/result.log > /dev/null 2>&1
      if [ $? == 0 ]
      then
          logwarn "topic $topic does not exist !"
          continue
      fi
      set +e
      if [[ "$environment" == "ccloud" ]]
      then
          get_sr_url_and_security

          value_type=""
          version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1" | jq -r .version)
          if [ "$version" != "null" ]
          then
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1"  | jq -r .schemaType)
          case "${schema_type}" in
              JSON)
              value_type="json-schema"
              ;;
              PROTOBUF)
              value_type="protobuf"
              ;;
              null)
              value_type="avro"
              ;;
          esac
          fi

          if [ ! -f $root_folder/.ccloud/librdkafka.delta ]
          then
              logerror "ERROR: $root_folder/.ccloud/librdkafka.delta has not been generated"
              exit 1
          fi
          tr -d '"' < $root_folder/.ccloud/librdkafka.delta > $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta
          sr_url=$(grep "schema.registry.url=" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_url_hostname=$(echo $sr_url | cut -d "/" -f 3)
          sr_auth=$(grep "basic.auth.user.info=" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_username=$(echo $sr_auth | cut -d ":" -f 1)
          sr_password=$(echo $sr_auth | cut -d ":" -f 2)
          # sr_password_url_encoded=$(urlencode $sr_password)
          grep -v "basic.auth.user.info" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta > $root_folder/.ccloud/librdkafka_no_quotes.delta

          case "${value_type}" in
          avro)
          docker run -i --network=host \
                  -v $root_folder/.ccloud/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -s value=avro \
                  -r https://$sr_username:$sr_password@$sr_url_hostname \
                  -e -q > /tmp/result.log 2>/dev/null
              ;;
          *)
          docker run -i --network=host \
                  -v $root_folder/.ccloud/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -e -q > /tmp/result.log 2>/dev/null
          ;;
          esac
          wc -l /tmp/result.log | awk '{print $1}'
      else
          tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
          if [ $? != 0 ] || [ "$tag" == "" ]
          then
              logerror "Could not find current CP version from docker ps"
              exit 1
          fi
          if ! version_gt $tag "6.9.9" && [ "$security" != "" ]
          then
              # GetOffsetShell does not support security before 7.x
              get_security_broker "--consumer.config"

              set +e
              docker exec $container timeout 15 kafka-console-consumer --bootstrap-server broker:9092 --topic $topic $security --from-beginning --timeout-ms 15000 2>/dev/null | wc -l | tr -d ' '
              set -e
          else
              docker exec $container kafka-run-class kafka.tools.GetOffsetShell --broker-list broker:9092 $security --topic $topic --time -1 | awk -F ":" '{sum += $3} END {print sum}'
          fi
      fi
  done
}

# :command.function
playground_topic_display_consumer_offsets_command() {
  # src/commands/topic/display-consumer-offsets.sh
  get_security_broker "--consumer.config"
  get_environment_used
  verbose="${args[--verbose]}"

  log "Display content of __consumer_offsets topic, press crtl-c to stop..."
  if [[ "$environment" == "ccloud" ]]
  then
      logerror " __consumer_offsets topic is not readable in cloud"
      exit 1
  else

      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" $security"
      fi
      docker exec -i $container kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" $security | grep -v "_confluent-controlcenter"
  fi
}

# :command.function
playground_topic_list_command() {
  # src/commands/topic/list.sh
  log "🔘 List of topics (internal topics are excluded)"
  playground get-topic-list --skip-connect-internal-topics
}

# :command.function
playground_topic_describe_command() {
  # src/commands/topic/describe.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"

  get_security_broker "--command-config"

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  get_environment_used

  items=($topic)
  for topic in ${items[@]}
  do
      log "🔎 Describing topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties"
          fi
          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
      else
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --describe --topic $topic --bootstrap-server broker:9092 $security"
          fi
          docker exec $container kafka-topics --describe --topic $topic --bootstrap-server broker:9092 $security
      fi
  done
}

# :command.function
playground_topic_set_schema_compatibility_command() {
  # src/commands/topic/set-schema-compatibility.sh
  topic="${args[--topic]}"
  compatibility="${args[--compatibility]}"
  verbose="${args[--verbose]}"

  get_environment_used
  get_sr_url_and_security

  if [[ ! -n "$topic" ]]
  then
      logwarn "--topic flag was not provided, applying command to all topics"
      check_if_continue
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    log "🛡️ Set compatibility for subject ${topic}-value to $compatibility"
    if [[ -n "$verbose" ]]
    then
        log "🐞 curl command used"
        echo "curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value""
    fi
    curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value"
  done
}

# :command.function
playground_topic_consume_command() {
  # src/commands/topic/consume.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  max_messages="${args[--max-messages]}"
  grep_string="${args[--grep]}"
  min_expected_messages="${args[--min-expected-messages]}"
  timeout="${args[--timeout]}"
  tail="${args[--tail]}"
  timestamp_field="${args[--plot-latencies-timestamp-field]}"
  key_subject="${args[--key-subject]}"
  value_subject="${args[--value-subject]}"
  max_characters="${args[--max-characters]}"

  if [[ -n "$key_subject" ]]
  then
    original_key_subject=$key_subject
  fi

  if [[ -n "$value_subject" ]]
  then
    original_value_subject=$value_subject
  fi

  get_environment_used
  get_sr_url_and_security

  bootstrap_server="broker:9092"
  container="connect"
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="--consumer.config /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      security="--group test-consumer-group --consumer.config /service/kafka/users/client.properties"
  elif [[ "$environment" == "sasl-plain" ]] || [[ "$environment" == "sasl-scram" ]] || [[ "$environment" == "ldap-sasl-plain" ]]
  then
      security="--consumer.config /tmp/client.properties"

  elif [[ "$environment" == "ccloud" ]]
  then
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  fi

  if [[ -n "$timeout" ]] && [ "$timeout" != "60" ]
  then
    if [[ ! -n "$min_expected_messages" ]] || [ "$min_expected_messages" == "0" ]
    then
      logerror "❌ --timeout was provided without specifying --min-expected-messages"
      exit 1
    fi
  fi

  if [[ ! -n "$topic" ]]
  then
      if [[ -n "$min_expected_messages" ]] && [ "$min_expected_messages" != "0" ]
      then
        logerror "--min-expected-messages was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$key_subject" ]]
      then
        logerror "--key-subject was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$value_subject" ]]
      then
        logerror "--value-subject was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$tail" ]]
      then
        logerror "--tail was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$timestamp_field" ]]
      then
        logerror "--plot-latencies-timestamp-field was provided without specifying --topic"
        exit 1
      fi
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ no topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    key_subject=""
    value_subject=""
    if [ ! -n "$tail" ]
    then
      if [[ -n "$min_expected_messages" ]] && [ "$min_expected_messages" != "0" ]
      then

        start_time=$(date +%s)

        while true; do
          nb_messages=$(playground topic get-number-records -t $topic | tail -1)

          if [[ ! $nb_messages =~ ^[0-9]+$ ]]
          then
            echo $nb_messages | grep "does not exist" > /dev/null 2>&1
            if [ $? == 0 ]
            then
              logwarn "❌ topic $topic does not exist !"
            else
              logwarn "❌ problem while getting number of messages: $nb_messages"
            fi
            exit 1
          fi

          if [ $nb_messages -ge $min_expected_messages ]
          then
            break
          fi

          current_time=$(date +%s)
          elapsed_time=$((current_time - start_time))

          if [ $elapsed_time -ge $timeout ]
          then
            logerror "❌ overall timeout of $timeout seconds exceeded. --min-expected-messages is set with $min_expected_messages but topic $topic contains $nb_messages messages"
            exit 1
          fi

          sleep 1
        done
      else
        nb_messages=$(playground topic get-number-records -t $topic | tail -1)

        if [[ ! $nb_messages =~ ^[0-9]+$ ]]
        then
          echo $nb_messages | grep "does not exist" > /dev/null 2>&1
          if [ $? == 0 ]
          then
            logwarn "❌ topic $topic does not exist !"
          else
            logwarn "❌ problem while getting number of messages: $nb_messages"
          fi
          break
        fi
      fi
    fi

    if [ -n "$tail" ]
    then
      log "✨ Tailing content of topic $topic"
    elif [[ -n "$max_messages" ]] && [ $nb_messages -ge $max_messages ] && [[ ! -n "$timestamp_field" ]]
    then
      log "✨ Display content of topic $topic, it contains $nb_messages messages, but displaying only --max-messages=$max_messages"
      nb_messages=$max_messages
    else
      log "✨ Display content of topic $topic, it contains $nb_messages messages"
    fi

    if [[ -n "$grep_string" ]]
    then
      logwarn "--grep is set so only matched results will be displayed !"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      log "📈 plotting results.."
    fi
    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [[ -n "$original_key_subject" ]]
    then
      log "📛 key subject is set with $original_key_subject"
      key_subject=$original_key_subject
    else
      key_subject="${topic}-key"
    fi

    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${key_subject}/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${key_subject}/versions/latest"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [ "$key_type" != "" ]
    then
      log "🔮🔰 topic is using $key_type for key"
      playground schema get --subject ${key_subject}
    else
      log "🔮🙅 topic is not using any schema for key"
    fi

    if [[ -n "$original_value_subject" ]]
    then
      log "📛 value subject is set with $original_value_subject"
      value_subject=$original_value_subject
    else
      value_subject="${topic}-value"
    fi

    value_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          value_type="json-schema"
        ;;
        PROTOBUF)
          value_type="protobuf"
        ;;
        null)
          value_type="avro"
        ;;
      esac
    fi

    if [ "$value_type" != "" ]
    then
      log "🔮🔰 topic is using $value_type for value"
      playground schema get --subject ${value_subject}
    else
      log "🔮🙅 topic is not using any schema for value"
    fi

    type=""
    tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
    if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
    fifo_path="$tmp_dir/kafka_output_fifo"
    mkfifo "$fifo_path"

    nottailing1=""
    nottailing2=""
    if [ ! -n "$tail" ]
    then
      nottailing1="--from-beginning --max-messages $nb_messages"
      if [[ ! -n "$timestamp_field" ]]
      then
        nottailing2="timeout $timeout"
      fi
    fi

    if [ "$max_messages" != "10" ]
    then
      nottailing2=""
    fi
    if [[ -n "$verbose" ]]
    then
        set -x
    fi
    case "${value_type}" in
      avro|protobuf|json-schema)
          if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
          then
              if [[ "$environment" == "ccloud" ]]
              then
                get_connect_image
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container $nottailing2 kafka-$value_type-console-consumer -bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic  --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          else
              if [[ "$environment" == "ccloud" ]]
              then
                get_connect_image
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container $nottailing2  kafka-$value_type-console-consumer --bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true  --property print.schema.ids=true --property schema.id.separator="|" --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          fi
          ;;
      *)
        if [[ "$environment" == "ccloud" ]]
        then
          get_connect_image
          docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer.config /tmp/configuration/ccloud.properties --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1 &
        else
          docker exec $container $nottailing2 kafka-console-consumer --bootstrap-server $bootstrap_server --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1  &
        fi
      ;;
    esac
    # Detect the platform (macOS or Linux) and set the date command accordingly
    if [[ "$(uname)" == "Darwin" ]]; then
      # macOS
      date_command="date -r "
    else
      # Linux
      date_command="date -d @"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      rm -rf /tmp/latency
      mkdir -p /tmp/latency
      latency_csv="/tmp/latency/latency.csv"
      latency_png="/tmp/latency/latency.png"
    fi
    found=0
    first_record=1
    is_base64=0
    export LC_ALL=C
    # Loop through each line in the named pipe
    while read -r line
    do
      display_line=1
      if [[ $line =~ "CreateTime:" ]]
      then
        # Extract the timestamp from the line
        timestamp_ms=$(echo "$line" | cut -d ":" -f 2 | cut -d "|" -f 1)
        # Convert milliseconds to seconds
        timestamp_sec=$((timestamp_ms / 1000))
        milliseconds=$((timestamp_ms % 1000))
        readable_date="$(${date_command}${timestamp_sec} "+%Y-%m-%d %H:%M:%S.${milliseconds}")"
        line_with_date=$(echo "$line" | sed -E "s/CreateTime:[0-9]{13}/CreateTime:${readable_date}/")

        if [ $first_record -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)

          if [ ${#payload} -lt 1000 ]
          then
            # check if it is base64 encoded
            set +e
            base64=$(echo "$payload" | tr -d '"' | base64 --decode 2>/dev/null)
            if [ $? -eq 0 ]
            then
              if [ "$base64" != "" ]
              then
                decoded=$(echo "$base64" | iconv -t UTF-8//IGNORE 2>/dev/null)
                if [ "$decoded" == "$base64" ]
                then
                  logwarn "🤖 Data is base64 encoded, payload will be decoded"
                  is_base64=1
                fi
              fi
            fi
            set -e
          fi

          first_record=0
        fi

        if [ $is_base64 -eq 1 ]
        then
          base64=$(echo "$payload" | tr -d '"' | base64 --decode)
          line_with_date=$(echo "$line_with_date" | awk -v new_value="$base64" 'BEGIN {FS=OFS="|"} {$6=new_value}1')
        fi

        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "✅ found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [[ ! -n "$timestamp_field" ]]
        then
          if [ $display_line -eq 1 ]
          then
            payload=$(echo "$line_with_date" | cut -d "|" -f 6)
            if [ ${#payload} -lt $max_characters ]
            then
              if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
              then
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="KeySchemaId:"$6; $7="Value:"$7; $8="ValueSchemaId:"$8} 1'
              else
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="Value:"$6; $7="ValueSchemaId:"$7} 1'
              fi
            else
              if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
              then
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="KeySchemaId:"$6; $7="Value:"$7; $8="ValueSchemaId:"$8} 1' | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
              else
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="Value:"$6; $7="ValueSchemaId:"$7} 1' | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
              fi
            fi
          fi
        fi

        if [[ -n "$timestamp_field" ]]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          # JSON is invalid
          if ! echo "$payload" | jq -e .  > /dev/null 2>&1
          then
              logerror "--plot-latencies-timestamp-field is set but value content is not in json representation"
              exit 1
          else
            timestamp_source=$(echo "$payload" | jq -r .${timestamp_field})
            echo "$readable_date,$timestamp_ms,$timestamp_source" >> $latency_csv
          fi
        fi
      elif [[ $line =~ "Unable to find FetchSessionHandler" ]]
      then
        continue
      elif [[ $line =~ "Processed a total of" ]]
      then
        continue
      else
        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "✅ found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [ $display_line -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          if [ ${#payload} -lt $max_characters ]
          then
            echo "$line"
          else
            echo "$line" | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
          fi
        fi
      fi
    done < "$fifo_path"

    if [[ -n "$grep_string" ]]
    then
      if [ $found != 1 ]
      then
        logerror "❌ could not find $grep_string in topic $topic"
        exit 1
      fi
    fi
  done

  if [[ -n "$timestamp_field" ]]
  then
    log "Plot data using gnuplot, see ${latency_png}"
    docker run --quiet --rm -i -v /tmp/latency:/work remuslazar/gnuplot -e \
    "
    set grid;
    set datafile separator ',';
    set timefmt \"%Y-%m-%d %H:%M:%S.%s\";
    set format x '%H:%M:%S';
    set term png size 1200,600;
    set output 'latency.png';
    set xdata time;
    set autoscale;
    set xlabel 'Time';
    set ylabel 'Latency in ms';
    plot 'latency.csv' using 1:(\$2-\$3) with points;"

    # open $latency_csv
    open $latency_png
  fi
}

# :command.function
playground_topic_produce_command() {
  # src/commands/topic/produce.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  debug="${args[--debug]}"
  nb_messages="${args[--nb-messages]}"
  nb_partitions="${args[--nb-partitions]}"
  value="${args[--value]}"
  key="${args[--key]}"
  headers="${args[--headers]}"
  forced_key="${args[--forced-key]}"
  forced_value="${args[--forced-value]}"
  generate_only="${args[--generate-only]}"
  tombstone="${args[--tombstone]}"
  compatibility="${args[--compatibility]}"
  key_subject_name_strategy="${args[--key-subject-name-strategy]}"
  value_subject_name_strategy="${args[--value-subject-name-strategy]}"
  validate="${args[--validate]}"
  record_size="${args[--record-size]}"
  max_nb_messages_per_batch="${args[--max-nb-messages-per-batch]}"
  sleep_time_between_batch="${args[--sleep-time-between-batch]}"
  compression_codec="${args[--compression-codec]}"
  value_schema_id="${args[--value-schema-id]}"
  no_null="${args[--no-null]}"
  # Convert the space delimited string to an array
  eval "validate_config=(${args[--validate-config]})"
  eval "producer_property=(${args[--producer-property]})"
  eval "references=(${args[--reference]})"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  # debug
  if [[ -n "$debug" ]]
  then
      log "🐞 debug mode is on"
      trap 'code $tmp_dir' EXIT
  fi

  ref_schema_file=$tmp_dir/ref_schema
  key_schema_file=$tmp_dir/key_schema
  value_schema_file=$tmp_dir/value_schema

  if [ "$value" = "-" ]
  then
      if [[ ! -n "$tombstone" ]]
      then
          # stdin
          if [ -t 0 ]
          then
              logerror "❌ stdin is empty you probably forgot to set --value !"
              exit 1
          else
              value_content=$(cat "$value")
              echo "$value_content" > $value_schema_file
          fi
      fi
  else
      if [[ $value == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$value" | cut -d "@" -f 2)
          cp $argument_schema_file $value_schema_file
      elif [ -f "$value" ]
      then
          cp $value $value_schema_file
      else
          value_content=$value
          echo "$value_content" > $value_schema_file
      fi
  fi

  get_environment_used
  get_sr_url_and_security

  bootstrap_server="broker:9092"
  container="connect"
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="--producer.config /etc/kafka/producer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      security="--producer.config /service/kafka/users/client.properties"
  elif [[ "$environment" == "sasl-plain" ]] || [[ "$environment" == "sasl-scram" ]] || [[ "$environment" == "ldap-sasl-plain" ]]
  then
      security="--producer.config /tmp/client.properties"
  elif [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
      if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
      then
          logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi
  fi

  if [[ -n "$tombstone" ]]
  then
      if [[ ! -n "$key" ]] && [[ ! -n "$forced_key" ]]
      then
          logerror "❌ --tombstone is set but neither --key or --forced-key are set!"
          exit 1
      fi
      get_connect_image
      if ! version_gt $CONNECT_TAG "7.1.99"
      then
          logerror "❌ --tombstone is set but it can be produced only with CP 7.2+"
          exit 1
      fi
      if [[ -n "$forced_key" ]]
      then
          key=$forced_key
      fi
      log "🧟 Sending tombstone for key $key in topic $topic"
      if [[ -n "$verbose" ]]
      then
          set -x
      fi
      if [[ "$environment" == "ccloud" ]]
      then
          get_connect_image
          echo "$key|NULL" | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security --property parse.key=true --property key.separator="|" --property null.marker=NULL
      else
          echo "$key|NULL" | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security --property parse.key=true --property key.separator="|" --property null.marker=NULL
      fi
      # nothing else to do
      exit 0
  fi

  if [[ -n "$headers" ]]
  then
      get_connect_image
      if ! version_gt $CONNECT_TAG "7.1.99"
      then
          logerror "❌ --headers is set but it can be produced only with CP 7.2+"
          exit 1
      fi
  fi

  function identify_schema() {
      schema_file=$1
      type=$2

      if grep -q "proto3" $schema_file
      then
          log "🔮 $type schema was identified as protobuf"
          schema_type=protobuf
      elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
      then
          log "🔮 $type schema was identified as json schema"
          schema_type=json-schema
      elif grep -q "_meta" $schema_file
      then
          log "🔮 $type schema was identified as json"
          schema_type=json
      elif grep -q "CREATE TABLE" $schema_file
      then
          log "🔮 $type schema was identified as sql"
          schema_type=sql
      elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
      then
          log "🔮 $type schema was identified as avro"
          schema_type=avro
      elif grep -xq "\".*\"" $schema_file
      then
          log "🔮 $type schema was identified as avro (single line surrounded by double quotes)"
          schema_type=avro
      else
          log "📢 $type no known schema could be identified, payload will be sent as raw data"
          schema_type=raw
      fi
  }

  ref_array_schema_file=$tmp_dir/ref_array_schema
    if [ ${#references[@]} -ne 0 ]
    then
      declare -a array_ref_name=()
      i=0
      list_file=""
      for ref in "${references[@]}"
      do
          log "🖇️ ref is $ref"

          if [[ $ref == @* ]]
          then
              # this is a schema file
              argument_schema_file=$(echo "$ref" | cut -d "@" -f 2)
              cp $argument_schema_file $ref_schema_file
          elif [ -f "$ref" ]
          then
              cp $ref $ref_schema_file
          else
              echo "$ref" > "$ref_schema_file"
          fi

          cp $ref_schema_file $tmp_dir/schema_ref_$i
          list_file="$list_file $tmp_dir/schema_ref_$i"

          identify_schema "$ref_schema_file" "ref"
          ref_schema_type=$schema_type

          ref_name=$(cat $ref_schema_file | jq -r '.["$id"]')

          log "🔖 registering schema reference with subject $ref_name"
          playground schema register --subject "$ref_name" < "$ref_schema_file"

          array_ref_name+=("$ref_name")
          ((i=i+1))
      done

      jq -s '.' $list_file > $ref_array_schema_file

      json_new_file=$tmp_dir/json_new_file
      json="{\"schemaType\":\"JSON\"}"
      content=$(cat $value_schema_file | tr -d '\n' | tr -s ' ')
      json_new=$(echo $json | jq --arg content "$content" '. + { "schema": $content }')
      echo "$json_new" > $json_new_file
      references=""
      curl_tmp_ref_schema=$tmp_dir/curl_tmp_ref_schema
      curl_ref_array_schema_file=$tmp_dir/curl_ref_array_schema

      i=0
      list_file=""
      for ref_name in "${array_ref_name[@]}"
      do
          reference="{\"name\":\"$ref_name\",\"subject\":\"$ref_name\",\"version\":1}"
          echo "$reference" > $curl_tmp_ref_schema
          cp $curl_tmp_ref_schema $tmp_dir/ref_$i
          list_file="$list_file $tmp_dir/ref_$i"
          ((i=i+1))
      done

      jq -s '.' $list_file > $curl_ref_array_schema_file

      references=$(cat $curl_ref_array_schema_file | tr -d '\n' | tr -s ' ')

      register_ref_array_schema=$tmp_dir/register_ref_array_schema

      jq --argjson addition "$(cat $curl_ref_array_schema_file)" '. + {references: $addition}' $json_new_file > $register_ref_array_schema

      log "🔖 registering schema with subject $topic-value and reference"
      playground schema register --subject "${topic}-value" < $register_ref_array_schema

      value_schema_id=$(playground schema get --subject "${topic}-value" | grep "subject" | cut -d "(" -f 2 | cut -d " " -f 2 | cut -d ")" -f 1)

      if [[ "$value_schema_id" =~ ^-?[0-9]+$ ]]
      then
          :
      else
          logerror "❌ value schema id $value_schema_id is not valid"
          exit 1
      fi

  fi

  if [[ -n "$key" ]]
  then
      if [[ $key == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$key" | cut -d "@" -f 2)
          cp $argument_schema_file $key_schema_file
      elif [ -f "$key" ]
      then
          cp $key $key_schema_file
      else
          echo "$key" > "$key_schema_file"
      fi

      identify_schema "$key_schema_file" "key"
      key_schema_type=$schema_type
  fi

  identify_schema "$value_schema_file" "value"
  value_schema_type=$schema_type

  if [[ -n "$key" ]]
  then
      if ([ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]) &&

          ([ "$value_schema_type" = "avro" ] || [ "$value_schema_type" = "protobuf" ] || [ "$value_schema_type" = "json-schema" ])
      then
          if [ "$key_schema_type" != "$value_schema_type" ]
          then
              logerror "❌ both key and schemas are set with schema registry aware converters, but they are not the same"
              exit 1
          fi
      fi

      if ([ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]) &&

          ([ "$value_schema_type" = "raw" ] || [ "$value_schema_type" = "json" ] || [ "$value_schema_type" = "sql" ])
      then
          logerror "❌ key is set with schema registry aware converter, but not value"
          exit 1
      fi
  fi

  if [[ -n "$validate" ]]
  then
      if [ $nb_messages != 1 ]
      then
          logwarn "--validate is set, ignoring --nb-messages"
          nb_messages=1
      fi
  fi

  # https://stackoverflow.com/questions/22818814/repeat-a-file-content-until-reach-a-defined-line-count
  function repcat() {
      while cat "$1"
      do

          :
      done
  }

  function generate_data() {
      schema_type=$1
      schema_file=$2
      output_file=$3
      type="$4"
      input_file=""

      if [ "$value_schema_type" == "protobuf" ]
      then
          nb_max_messages_to_generate=50
      else
          if [ $record_size != 0 ]
          then
              nb_max_messages_to_generate=10
          else
              nb_max_messages_to_generate=500
          fi
      fi
      if [ $nb_messages = -1 ]
      then
          nb_messages_to_generate=$nb_max_messages_to_generate
      elif [ $nb_messages -lt $nb_max_messages_to_generate ]
      then
          nb_messages_to_generate=$nb_messages
      else
          nb_messages_to_generate=$nb_max_messages_to_generate
      fi

      if [[ -n "$forced_value" ]] && [ "$type" == "VALUE" ]
      then
          log "☢️ --forced-value is set"
          echo "$forced_value" > $tmp_dir/out.json
      elif [[ -n "$forced_key" ]] && [ "$type" == "KEY" ]
      then
          log "☢️ --forced-key is set"
          echo "$forced_key" > $tmp_dir/out.json
      else
          if [[ -n "$no_null" ]]
          then
              no_null="true"
          else
              no_null="false"
          fi
          case "${schema_type}" in
              json|sql)
                  # https://github.com/MaterializeInc/datagen
                  set +e
                  docker run --quiet --rm -i -v $schema_file:/app/schema.$schema_type materialize/datagen -s schema.$schema_type -n $nb_messages_to_generate --dry-run > $tmp_dir/result.log

                  nb=$(grep -c "Payload: " $tmp_dir/result.log)
                  if [ $nb -eq 0 ]
                  then
                      logerror "❌ materialize/datagen failed to produce $schema_type "
                      cat $tmp_dir/result.log
                      exit 1
                  fi
                  set -e
                  cat $tmp_dir/result.log | grep "Payload: " | sed 's/  Payload: //' > $tmp_dir/out.json
              ;;
              avro)
                  schema_file_name="$(basename "${schema_file}")"
                  docker run --quiet --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools random /tmp/out.avro --schema-file /tmp/$schema_file_name --count $nb_messages_to_generate --no-null "$no_null"
                  docker run --quiet --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools tojson /tmp/out.avro > $tmp_dir/out.json
              ;;
              json-schema)
                  # https://github.com/json-schema-faker/json-schema-faker/tree/master/docs
                  schema_file_name="$(basename "${schema_file}")"
                  if [ -f $ref_array_schema_file ]
                  then
                      ref_array_schema_file_name="$(basename "${ref_array_schema_file}")"
                      docker run --quiet --rm -v $tmp_dir:/tmp/ -e NB_MESSAGES=$nb_messages_to_generate -e SCHEMA=/tmp/$schema_file_name -e REFS=/tmp/$ref_array_schema_file_name -e NO_NULL="$no_null" vdesabou/json-schema-faker > $tmp_dir/out.json
                  else
                      docker run --quiet --rm -v $tmp_dir:/tmp/ -e NB_MESSAGES=$nb_messages_to_generate -e SCHEMA=/tmp/$schema_file_name -e NO_NULL="$no_null" vdesabou/json-schema-faker > $tmp_dir/out.json
                  fi
              ;;
              protobuf)
                  # https://github.com/JasonkayZK/mock-protobuf.js
                  docker run -u0 --rm -v $tmp_dir:/tmp/ -v $schema_file:/app/schema.proto -e NB_MESSAGES=$nb_messages_to_generate vdesabou/protobuf-faker bash -c "bash /app/produce.sh && chown -R $(id -u $USER):$(id -g $USER) /tmp/" > $tmp_dir/out.json
              ;;
              raw)
                  if jq -e . >/dev/null 2>&1 <<< "$(head -1 "$schema_file")"
                  then
                      log "💫 payload is one json per line, one json record per line will be sent"
                      set +e
                      repcat "$schema_file" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  elif jq -e . >/dev/null 2>&1 <<< "$(cat "$schema_file")"
                  then
                      log "💫 payload is single json, it will be sent as one record"
                      jq -c . "$schema_file" > $tmp_dir/minified.json
                      set +e
                      repcat "$tmp_dir/minified.json" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  else
                      log "💫 payload is not single json, one record per line will be sent"
                      set +e
                      repcat "$schema_file" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  fi
              ;;
              *)
                  logerror "❌ schema_type name not valid ! Should be one of raw, json, avro, json-schema or protobuf"
                  exit 1
              ;;
          esac
      fi

      if [ "$input_file" = "" ]
      then
          input_file=$tmp_dir/out.json
      fi

      input2_file=$tmp_dir/input2.json
      if [ -f $input2_file ]
      then
          rm -f $input2_file
      fi
      record_size_temp_file_line=$tmp_dir/line.json
      record_size_temp_file_output=$tmp_dir/output.json
      lines_count=0

      while IFS= read -r line
      do
          if [ $record_size != 0 ]
          then
              if ! echo "$line" | jq -e .  > /dev/null 2>&1
              then
                  echo "${line}PLACEHOLDER" > $record_size_temp_file_output
              else
                  echo $line > $record_size_temp_file_line
                  new_value="PLACEHOLDER"

                  first_string_field=$(echo "$line" | jq -r 'path(.. | select(type == "string")) | .[-1]' | tail -1)

                  if [ $lines_count -eq 0 ]
                  then
                      log "🔮 Replacing first string field $first_string_field value with long payload"
                  fi
                  jq -c --arg new_val "$new_value" ".${first_string_field} |= \$new_val" $record_size_temp_file_line > $record_size_temp_file_output
              fi

              # The size needed for the new_value
              size_with_placeholder=$(wc -c < $record_size_temp_file_output)

              # The size needed for the new_value
              new_value_size=$((record_size - size_with_placeholder))

              if [[ $new_value_size -gt 0 ]]
              then
                  # Create a string of '-' characters with length equivalent to new_value_size
                  new_value_string=$(LC_ALL=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c$new_value_size)

                  echo -n "$new_value_string" > temp.txt

                  # Replace placeholder with the content of temp.txt file in $record_size_temp_file_output
                  # Perl can handle very large arguments and perform replacement effectively
                  perl -pi -e 'BEGIN{undef $/;} s/PLACEHOLDER/`cat temp.txt`/gse' $record_size_temp_file_output

                  cat $record_size_temp_file_output >> "$input2_file"
                  # Remove temp file
                  rm temp.txt
              else
                  log "❌ record-size is too small"
                  exit 1
              fi
          else
              echo "$line" >> "$input2_file"
          fi

          lines_count=$((lines_count+1))
          if [ $nb_messages != -1 ]
          then
              if [ $lines_count -ge $nb_messages ]
              then
                  break
              fi
          fi
          counter=$((counter+1))
      done < "$input_file"

      if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
      then
          set +e
          repcat "$input2_file" | head -n "$max_nb_messages_per_batch" > "$output_file"
          set -e
      elif [ $lines_count -lt $nb_messages ]
      then
          set +e
          repcat "$input2_file" | head -n "$nb_messages" > "$output_file"
          set -e
      else
          cp $input2_file $output_file
      fi
  }

  output_key_file=$tmp_dir/out_key_final.json
  output_value_file=$tmp_dir/out_value_final.json
  output_final_file=$tmp_dir/out_final.json
  SECONDS=0
  if [[ -n "$key" ]]
  then
      log "✨ generating key data..."
      generate_data "$key_schema_type" "$key_schema_file" "$output_key_file" "KEY"
  fi
  log "✨ generating value data..."
  generate_data "$value_schema_type" "$value_schema_file" "$output_value_file" "VALUE"

  nb_generated_messages=$(wc -l < $output_value_file)
  nb_generated_messages=${nb_generated_messages// /}

  if [ "$nb_generated_messages" == "0" ]
  then
      logerror "❌ records could not be generated!"
      exit 1
  fi

  if [[ -n "$key" ]] && [ "$key_schema_type" = "raw" ]
  then
      if [[ $key =~ ^([^0-9]*)([0-9]+)([^0-9]*)$ ]]; then
          prefix="${BASH_REMATCH[1]}"
          number="${BASH_REMATCH[2]}"
          suffix="${BASH_REMATCH[3]}"

          log "🗝️ key $key is set with a number $number, it will be used as starting point"
          while read -r line
          do
              new_key="${prefix}${number}${suffix}"
              echo "${new_key}" >> "$tmp_dir/temp_value_file"
              number=$((number + 1))
          done < "$output_key_file"

          mv "$tmp_dir/temp_value_file" "$output_key_file"
      else
          counter=1
          log "🗝️ key is set with a string $key, it will be used for all records"
          while read -r line
          do
              echo "${key}" >> "$tmp_dir/temp_value_file"
          done < "$output_key_file"

          mv "$tmp_dir/temp_value_file" "$output_key_file"
      fi
  fi

  if [[ -n "$key" ]]
  then
      # merging key and value files
      paste -d "|" $output_key_file $output_value_file > $output_final_file
  else
      cp $output_value_file $output_final_file
  fi

  # headers need to be set first
  if [[ -n "$headers" ]]
  then
      log "🚏 headers are set $headers"
      while read line
      do
          echo "${headers}|${line}" >> $tmp_dir/temp_headers_file
      done < $output_final_file

      mv $tmp_dir/temp_headers_file $output_final_file
  fi

  value_str=""
  if [[ -n "$forced_value" ]]
  then
      value_str=" based on --forced-value "
  fi

  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"

  size_limit_to_show=2500
  if [ $record_size -gt $size_limit_to_show ]
  then
      log "✨ $nb_generated_messages records were generated$value_str (only showing first 1 as record size is $record_size), $ELAPSED"
      log "✨ only showing first $size_limit_to_show characters"
      head -n 1 "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | cut -c 1-${size_limit_to_show} | awk "{print \$0 \"...<truncated, only showing first $size_limit_to_show characters, out of $record_size>...\"}"
  else
      if (( nb_generated_messages < 10 ))
      then
          log "✨ $nb_generated_messages records were generated$value_str"
          cat "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}'
      else
          log "✨ $nb_generated_messages records were generated$value_str (only showing first 10), $ELAPSED"
          head -n 10 "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}'
      fi
  fi

  if [[ -n "$generate_only" ]]
  then
    log "🚪 --generate-only is set, exiting now."
    exit 0
  fi

  if [[ -n "$validate" ]]
  then
      log "✔️ --validate is set, validating schema now..."

      if [ "$value_schema_type" == "json-schema" ]
      then
          log "✨ also validating with https://raw.githubusercontent.com/conan-goldsmith/Python-Scripts/main/json_type_validator.py"
          curl -s -L https://raw.githubusercontent.com/conan-goldsmith/Python-Scripts/main/json_type_validator.py -o /tmp/json_type_validator.py
          docker run -i --rm -v "/tmp/json_type_validator.py:/tmp/json_type_validator.py" -v "$value_schema_file:/tmp/schema" python:3.7-slim python /tmp/json_type_validator.py -f /tmp/schema
      fi

      set +e
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "Could not find current CP version from docker ps"
          exit 1
      fi
      log "🏗 Building jar for schema-validator"
      docker run -i --rm -e TAG=$tag -v "${root_folder}/scripts/cli/src/schema-validator":/usr/src/mymaven -v "$HOME/.m2":/root/.m2 -v "$root_folder/scripts/settings.xml:/tmp/settings.xml" -v "${root_folder}/scripts/cli/src/schema-validator/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=$tag package > /tmp/result.log 2>&1
      if [ $? != 0 ]
      then
          logerror "ERROR: failed to build java component schema-validator"
          tail -500 /tmp/result.log
          exit 1
      fi
      set -e

      docker cp ${root_folder}/scripts/cli/src/schema-validator/target/schema-validator-1.0.0-jar-with-dependencies.jar connect:/tmp/schema-validator-1.0.0-jar-with-dependencies.jar > /dev/null 2>&1
      docker cp $value_schema_file connect:/tmp/schema > /dev/null 2>&1
      docker cp $output_value_file connect:/tmp/message.json > /dev/null 2>&1
      env_list=""
      for conf in "${validate_config[@]}"
      do
          case "${conf}" in

              "connect.meta.data=false")
                  env_list="$env_list -e KAFKA_CONNECT_META_DATA=false"
              ;;

              # avro specifics
              "scrub.invalid.names=true")
                  env_list="$env_list -e KAFKA_SCRUB_INVALID_NAMES=true"
              ;;
              "enhanced.avro.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_AVRO_SCHEMA_SUPPORT=true"
              ;;

              # json-schema specifics
              "use.optional.for.nonrequired=true")
                  env_list="$env_list -e KAFKA_USE_OPTIONAL_FOR_NONREQUIRED=true"
              ;;
              "ignore.default.for.nullables=true")
                  env_list="$env_list -e KAFKA_IGNORE_DEFAULT_FOR_NULLABLES=true"
              ;;
              "generalized.sum.type.support=true")
                  env_list="$env_list -e KAFKA_GENERALIZED_SUM_TYPE_SUPPORT=true"
              ;;

              # protobuf specifics
              "enhanced.protobuf.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_PROTOBUF_SCHEMA_SUPPORT=true"
              ;;
              "generate.index.for.unions=false")
                  env_list="$env_list -e KAFKA_GENERATE_INDEX_FOR_UNIONS=false"
              ;;
              "int.for.enums=true")
                  env_list="$env_list -e KAFKA_INT_FOR_ENUMS=true"
              ;;
              "optional.for.nullables=true")
                  env_list="$env_list -e KAFKA_OPTIONAL_FOR_NULLABLES=true"
              ;;
              "generate.struct.for.nulls=true")
                  env_list="$env_list -e KAFKA_GENERATE_STRUCT_FOR_NULLS=true"
              ;;
              "wrapper.for.nullables=true")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_NULLABLES=true"
              ;;
              "wrapper.for.raw.primitives=false")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_RAW_PRIMITIVES=false"
              ;;
              *)
                  logerror "default (none of above)"
              ;;
          esac
      done

      docker exec $env_list -e SCHEMA_TYPE=$value_schema_type connect bash -c "java -jar /tmp/schema-validator-1.0.0-jar-with-dependencies.jar" > $tmp_dir/result.log
      set +e
      nb=$(grep -c "ERROR" $tmp_dir/result.log)
      if [ $nb -ne 0 ]
      then
          logerror "❌ schema is not valid according to $value_schema_type converter"
          cat $tmp_dir/result.log
          exit 1
      else
          log "👌 schema is valid according to $value_schema_type converter"
      fi
      set -e
  fi

  playground topic get-number-records --topic $topic > $tmp_dir/result.log 2>$tmp_dir/result.log
  set +e
  grep "does not exist" $tmp_dir/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      log "✨ topic $topic does not exist, it will be created.."
      if [[ "$environment" == "ccloud" ]]
      then
          if [ "$nb_partitions" != "1" ]
          then
              log "⛅ creating topic in confluent cloud with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              log "⛅ creating topic in confluent cloud"
              playground topic create --topic $topic --nb-partitions 1
          fi
      else
          if [ "$nb_partitions" != "1" ]
          then
              log "--nb-partitions is set, creating topic with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              playground topic create --topic $topic
          fi
      fi
  else
      nb=$(playground topic get-number-records -t $topic | tail -1)
      if [ "$nb_partitions" != "1" ]
      then
          if [ $nb == 0 ]
          then
              log "--nb-partitions is set and topic is empty, re-creating it with $nb_partitions partitions..."
              playground topic delete --topic $topic
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              logerror "--nb-partitions is set, but topic is not empty, delete it first and retry"
              echo "playground topic delete --topic $topic"
              exit 0
          fi
      else
          log "💯 Get number of records in topic $topic"
          echo $nb
      fi
  fi

  if [ "$compatibility" != "" ]
  then
      playground topic set-schema-compatibility --topic $topic --compatibility $compatibility
  fi

  if [[ ! -n "$key" ]] && [[ -n "$key_subject_name_strategy" ]]
  then
      logerror "❌ --key-subject-name-strategy is set but not --key"
      exit 1

  fi

  if [ "$key_schema_type" != "" ]
  then
      case "${key_schema_type}" in
          avro|json-schema|protobuf)

          ;;
          *)
              if [[ -n "$validate" ]]
              then
                  logerror "❌ --validate is set but $key_schema_type is used. This is only valid for avro|json-schema|protobuf"
                  exit 1
              fi
              if [[ -n "$key_subject_name_strategy" ]]
              then
                  logerror "❌ --key-subject-name-strategy is set but $key_schema_type is used. This is only valid for avro|json-schema|protobuf"
                  exit 1

              fi
          ;;
      esac
  fi

  case "${value_schema_type}" in
      avro|json-schema|protobuf)

      ;;
      *)
          if [[ -n "$validate" ]]
          then
              logerror "❌ --validate is set but $value_schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1
          fi
          if [[ -n "$value_subject_name_strategy" ]]
          then
              logerror "❌ --value-subject-name-strategy is set but $value_schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1

          fi
      ;;
  esac

  compression=""
  producer_properties=""

  set -e
  SECONDS=0
  if [ $nb_messages = -1 ]
  then
      log "📤 producing infinite records to topic $topic (--nb-messages is set to -1)"
  else
      log "📤 producing $nb_messages records to topic $topic"
  fi
  sleep_msg=""
  if [[ $sleep_time_between_batch -gt 0 ]]
  then
      sleep_msg=" with $sleep_time_between_batch seconds between each batch"
  fi
  if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
  then
      log "✨ it will be done in batches of maximum $max_nb_messages_per_batch records$sleep_msg"

      log "✨ setting --producer-property linger.ms=100 and --producer-property batch.size=500000"
      producer_properties="$producer_properties --producer-property linger.ms=1000 --producer-property batch.size=500000"
  fi

  if [ $record_size -gt 1048576 ]
  then
      log "✨ record-size $record_size is greater than 1Mb (1048576), setting --producer-property max.request.size=$((record_size + 1000)) and --producer-property buffer.memory=67108864"
      producer_properties="$producer_properties --producer-property max.request.size=$((record_size + 1000)) --producer-property buffer.memory=67108864"
      log "✨ topic $topic max.message.bytes is also set to $((record_size + 1000))"
      playground topic alter --topic $topic --add-config max.message.bytes=$((record_size + 1000))
  fi

  for producer_prop in "${producer_property[@]}"
  do
      producer_properties="$producer_properties --producer-property $producer_prop"
  done

  if [ "$producer_properties" != "" ]
  then
      log "⚙️ following producer properties will be used: $producer_properties"
  fi

  if [[ -n "$compression_codec" ]]
  then
      log "🤐 --compression-codec $compression_codec will be used"
      compression="--compression-codec $compression_codec"
  fi

  function handle_signal {
    echo "Stopping..."
    stop=1
  }
  # Set the signal handler
  trap handle_signal SIGINT

  nb_messages_sent=0
  nb_messages_to_send=0
  stop=0
  should_stop=0
  while [ $stop != 1 ]
  do
      if [ $nb_messages -eq -1 ]
      then
          nb_messages_to_send=$nb_generated_messages
      elif [ $((nb_messages_sent + nb_generated_messages)) -le $nb_messages ]
      then
          nb_messages_to_send=$nb_generated_messages
      else
          nb_messages_to_send=$((nb_messages - nb_messages_sent))
          should_stop=1
      fi
      if [ $nb_messages_to_send -eq 0 ]
      then
          stop=1
          continue
      fi
      if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
      then
          if [ $nb_messages -eq -1 ]
          then
              log "📤 producing a batch of $nb_messages_to_send records to topic $topic (press ctrl-c to stop)"
              log "💯 $nb_messages_sent records sent so far..."
          else
              log "📤 producing a batch of $nb_messages_to_send records to topic $topic"
              log "💯 $nb_messages_sent/$nb_messages records sent so far..."
          fi
      fi

      if [[ -n "$verbose" ]]
      then
          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' > /tmp/verbose_input_file.txt
      fi
      case "${value_schema_type}" in
          json|sql|raw)
              if [[ "$environment" == "ccloud" ]]
              then
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.key=true --property key.separator=\"|\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.key=true --property key.separator=\"|\" "
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.key=true --property key.separator="|"

                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression"
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression
                      fi
                  fi
              else
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.key=true --property key.separator=\"|\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.key=true --property key.separator=\"|\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.key=true --property key.separator="|"
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties $compression
                      fi
                  fi
              fi
          ;;
          *)
              force_schema_id=""
              if [[ -n "$value_schema_id" ]]
              then
                  log "🔰 --value-schema-id is set: adding --property value.schema.id=$value_schema_id --property auto.register=false --property use.latest.version=true"
                  force_schema_id="--property value.schema.id=$value_schema_id --property auto.register=false --property use.latest.version=true"
              fi

              key_subject_name_strategy_property=""
              if [[ -n "$key_subject_name_strategy" ]]
              then
                  key_subject_name_strategy_property="--property key.subject.name.strategy=io.confluent.kafka.serializers.subject.$key_subject_name_strategy"
              fi

              value_subject_name_strategy_property=""
              if [[ -n "$value_subject_name_strategy" ]]
              then
                  value_subject_name_strategy_property="--property value.subject.name.strategy=io.confluent.kafka.serializers.subject.$value_subject_name_strategy"
              fi

              avro_use_logical_type_converters_property=""
              if [ "${value_schema_type}" == "avro" ]
              then
                  avro_use_logical_type_converters_property=" --property avro.use.logical.type.converters=true"
              fi
              if [[ "$environment" == "ccloud" ]]
              then
                  cp $root_folder/scripts/cli/src/tools-log4j.properties /tmp/tools-log4j.properties > /dev/null 2>&1
                  if [ -f $key_schema_file ]
                  then
                      cp $key_schema_file /tmp/key_schema_file > /dev/null 2>&1
                  fi
                  if [ -f $value_schema_file ]
                  then
                      cp $value_schema_file /tmp/value_schema_file > /dev/null 2>&1
                  fi
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              get_connect_image
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              get_connect_image
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          fi
                      else
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              get_connect_image
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              get_connect_image
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          fi
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                          fi
                          get_connect_image
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                      fi
                  fi
              else
                  if [ -f $key_schema_file ]
                  then
                      docker cp $key_schema_file $container:/tmp/key_schema_file > /dev/null 2>&1
                  fi
                  if [ -f $value_schema_file ]
                  then
                      docker cp $value_schema_file $container:/tmp/value_schema_file > /dev/null 2>&1
                  fi
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          docker cp $root_folder/scripts/cli/src/tools-log4j.properties $container:/tmp/tools-log4j.properties > /dev/null 2>&1
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi

                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi

                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          fi
                      else
                          docker cp $root_folder/scripts/cli/src/tools-log4j.properties $container:/tmp/tools-log4j.properties > /dev/null 2>&1
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                          fi
                      fi
                  else
                      docker cp $root_folder/scripts/cli/src/tools-log4j.properties $container:/tmp/tools-log4j.properties > /dev/null 2>&1
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/tools-log4j.properties" -i $container kafka-$value_schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression
                      fi
                  fi
              fi
          ;;
      esac
      # Increment the number of sent messages
      nb_messages_sent=$((nb_messages_sent + nb_messages_to_send))

      if [[ $sleep_time_between_batch -gt 0 ]]
      then
          sleep $sleep_time_between_batch
      fi
      if [ $nb_messages != -1 ] && [ $should_stop -eq 1 ]
      then
          stop=1
      fi
  done
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  log "📤 produced $nb_messages records to topic $topic, $ELAPSED"
  playground topic get-number-records --topic $topic
}

# :command.function
playground_topic_create_command() {
  # src/commands/topic/create.sh
  topic="${args[--topic]}"
  nb_partitions="${args[--nb-partitions]}"
  verbose="${args[--verbose]}"

  get_security_broker "--command-config"
  get_environment_used

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      set -e
      log "🆕 Creating topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --create --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --partitions $nb_partitions ${other_args[*]}"
          fi
          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --create --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --partitions $nb_partitions ${other_args[*]}
      else
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --create --topic $topic --bootstrap-server broker:9092 --partitions $nb_partitions $security ${other_args[*]}"
          fi
          docker exec $container kafka-topics --create --topic $topic --bootstrap-server broker:9092 --partitions $nb_partitions $security ${other_args[*]}
      fi
  else
      logerror "❌ topic $topic already exist !"
      exit 1
  fi
}

# :command.function
playground_topic_delete_command() {
  # src/commands/topic/delete.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  skip_delete_schema="${args[--skip-delete-schema]}"

  get_security_broker "--command-config"
  get_environment_used

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      logwarn "❌ topic $topic does not exist !"
      exit 1
  fi
  set -e

  log "❌ Deleting topic $topic"
  if [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
      if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
      then
          logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi
      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-topics --delete --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties"
      fi
      get_connect_image
      docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --delete --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
  else
      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-topics --delete --topic $topic --bootstrap-server broker:9092 $security"
      fi
      docker exec $container kafka-topics --delete --topic $topic --bootstrap-server broker:9092 $security
  fi

  if [[ -n "$skip_delete_schema" ]]
  then
      log "🔰 Do not delete subject/schema as --skip-delete-schema is set"
  else
      set +e
      playground schema get --subject "$topic-key" > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "🔰 Delete subject $topic-key"
          playground schema delete --subject "$topic-key" --permanent
      fi

      playground schema get --subject "$topic-value" > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "🔰 Delete subject $topic-value"
          playground schema delete --subject "$topic-value" --permanent
      fi
  fi
}

# :command.function
playground_topic_alter_command() {
  # src/commands/topic/alter.sh
  topic="${args[--topic]}"

  get_security_broker "--command-config"
  get_environment_used

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      logwarn "🆕 topic $topic does not exist, creating it..."
      playground topic create --topic $topic

      playground topic alter --topic $topic ${other_args[*]}
  else
      log "🪛 Altering topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties ${other_args[*]}
      else
          docker exec $container kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server broker:9092 $security ${other_args[*]}
      fi
  fi
  set -e

}

# :command.function
playground_connector_plugin_search_jar_command() {
  # src/commands/connector-plugin/search-jar.sh
  connector_plugin="${args[--connector-plugin]}"
  connector_tag="${args[--connector-tag]}"
  class="${args[--class]}"

  if [[ $connector_plugin == *"@"* ]]
  then
    connector_plugin=$(echo "$connector_plugin" | cut -d "@" -f 2)
  fi

  if [[ -n "$connector_tag" ]]
  then
      if [ "$connector_tag" == " " ]
      then
          ret=$(choose_connector_tag "$connector_plugin")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')
      fi
  else
      connector_tag="latest"
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  get_connect_image
  log "🔌 Downloading connector plugin $connector_plugin:$connector_tag"
  docker run -u0 -i --rm -v $tmp_dir:/usr/share/confluent-hub-components ${CP_CONNECT_IMAGE}:${CONNECT_TAG} bash -c "confluent-hub install --no-prompt $connector_plugin:$connector_tag && chown -R $(id -u $USER):$(id -g $USER) /usr/share/confluent-hub-components" | grep "Downloading"

  log "🤎 Listing jar files"
  cd $tmp_dir/*/lib
  ls -1 | sort

  if [[ -n "$class" ]]
  then
    log "Searching for java class $class in all jars"
    find . -name '*.jar' -print | while read i;

    do

      set +e
      jar -tvf "$i" | grep -Hsi ${class} | awk '{print $10}' | sed 's/\.class$//' | tr '/' '.' | while read j
      do
        if [ $? -eq 0 ]
        then
          if [ "$j" != "" ]
          then
            log "👉 method signatures from $i jar for class $j"
            javap -classpath $i $j
          fi
        fi
      done
    done
  fi
}

# :command.function
playground_connector_plugin_versions_command() {
  # src/commands/connector-plugin/versions.sh
  connector_plugin="${args[--connector-plugin]}"
  last="${args[--last]}"
  force_refresh="${args[--force-refresh]}"

  if [[ $connector_plugin == *"@"* ]]
  then
    connector_plugin=$(echo "$connector_plugin" | cut -d "@" -f 2)
  fi

  owner=$(echo "$connector_plugin" | cut -d "/" -f 1)
  name=$(echo "$connector_plugin" | cut -d "/" -f 2)

  filename="/tmp/version_$owner_$name"
  if [[ -n "$force_refresh" ]]
  then
      if [ -f $filename ]
      then
          rm -f $filename
      fi
  fi

  if [[ -n "$last" ]]
  then
      if [ "$last" != "1" ]
      then
          log "💯 Listing last $last versions for connector plugin $connector_plugin"
      fi
  else
      log "💯 Listing all versions for connector plugin $connector_plugin"
  fi

  if [ ! -f $filename ]
  then
      curl_output=$(curl -s https://api.hub.confluent.io/api/plugins/$owner/$name/versions)
      ret=$?
      set -e
      if [ $ret -eq 0 ]
      then
          if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
          then
              set +e
              json_file=/tmp/json
              echo "$curl_output" > $json_file
              jq_output=$(jq . "$json_file" 2>&1)
              error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

              if [[ -n "$error_line" ]]; then
                  logerror "❌ Invalid JSON at line $error_line"
              fi
              set -e

              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  if [[ $(type -f bat 2>&1) =~ "not found" ]]
                  then
                      cat -n $json_file
                  else
                      bat $json_file --highlight-line $error_line
                  fi
              fi
              exit 1
          fi

          if [ "$curl_output" == "[]" ]
          then
              logwarn "❌ could not get versions for connector plugin $connector_plugin"
              exit 0
          fi

          if [[ "$(uname)" == "Darwin" ]]; then
              # macOS
              current_date=$(date -j -f "%Y-%m-%d" "$(date "+%Y-%m-%d")" "+%s")
          else
              # Linux
              current_date=$(date +%s)
          fi
          while IFS= read -r row; do
              IFS=$'\n'
              arr=($(echo "$row" | jq -r '.version, .manifest_url, .release_date'))
              version="${arr[0]}"
              #manifest_url="${arr[1]}"
              release_date="${arr[2]}"
              if [ "$release_date" != "null" ]
              then
                  if [[ "$(uname)" == "Darwin" ]]; then
                      # macOS
                      release_date_sec=$(date -j -f "%Y-%m-%d" "$release_date" "+%s")
                  else
                      # Linux
                      release_date_sec=$(date -d "$release_date" "+%s")
                  fi

                  # Calculate the difference in days
                  diff=$(( (current_date - release_date_sec) / 60 / 60 / 24 ))
                  echo "🔢 v$version - 📅 release date: $release_date ($diff days ago)" >> $filename
              else
                  echo "🔢 v$version - 📅 release date: <unknown>" >> $filename
              fi
          done <<< "$(echo "$curl_output" | jq -c '.[]')"
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi

      if [ ! -f $filename ]
      then
          logerror "❌ could not get versions for connector plugin $connector_plugin"
          exit 1
      fi
  fi

  if [[ -n "$last" ]]
  then
      tail -${last} $filename
  else
      cat $filename
  fi
}

# :command.function
playground_connector_status_command() {
  # src/commands/connector/status.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      set +e
      log "🧩 Displaying $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""

          printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
          echo "-------------------------------------------------------------------------------------------------------------"
          status=$(echo "$curl_output" | jq -r '.connector.state')

          if [ "$status" == "RUNNING" ]
          then
              status="✅ RUNNING"
          elif [ "$status" == "PAUSED" ]
          then
              status="⏸️  PAUSED"
          elif [ "$status" == "FAILED" ]
          then
              status="❌ FAILED"
          elif [ "$status" == "STOPPED" ]
          then
              status="🛑 STOPPED"
          else
              status="🤔 UNKNOWN"
          fi

          tasks=$(echo "$curl_output" | jq -r '.tasks[] | "\(.id):\(.state)"' | tr '\n' ',' | sed 's/,$/\n/')

          if [[ "$tasks" == *"RUNNING"* ]]
          then
              tasks="${tasks//RUNNING/🟢 RUNNING}"
          elif [[ "$tasks" == *"PAUSED"* ]]
          then
              tasks="${tasks//PAUSED/⏸️  PAUSED}"
          elif [[ "$tasks" == *"STOPPED"* ]]
          then
              tasks="${tasks//STOPPED/🛑  STOPPED}"
          elif [[ "$tasks" == *"FAILED"* ]]
          then
              tasks="${tasks//FAILED/🛑 FAILED}"
          else
              tasks="🤔 N/A"
          fi

          stacktrace_connector=$(echo "$curl_output" | jq -r '.connector.trace | select(length > 0)')
          errors_from_trace=$(echo "$curl_output" | jq -r '.errors_from_trace[0].error | select(length > 0)')
          validation_errors=$(echo "$curl_output" | jq -r '.validation_errors[0] | select(length > 0)')
          stacktrace=""
          if [ "$stacktrace_connector" != "" ]
          then
              stacktrace="connector: $stacktrace_connector"
          fi

          if [ "$errors_from_trace" != "" ]
          then
              stacktrace="$stacktrace errors_from_trace: $errors_from_trace"
          fi

          if [ "$validation_errors" != "" ]
          then
              stacktrace="$stacktrace validation_errors: $validation_errors"
          fi

          if [ -z "$stacktrace" ]
          then
              stacktrace="-"
          fi

          printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
          echo "-------------------------------------------------------------------------------------------------------------"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""

          printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
          echo "-------------------------------------------------------------------------------------------------------------"
          status=$(echo "$curl_output" | jq -r '.connector.state')

          if [ "$status" == "RUNNING" ]
          then
              status="✅ RUNNING"
          elif [ "$status" == "PAUSED" ]
          then
              status="⏸️  PAUSED"
          elif [ "$status" == "FAILED" ]
          then
              status="❌ FAILED"
          elif [ "$status" == "STOPPED" ]
          then
              status="🛑 STOPPED"
          else
              status="🤔 UNKNOWN"
          fi

          tasks=$(echo "$curl_output" | jq -r '.tasks[] | "\(.id):\(.state)[\(.worker_id)]"' | tr '\n' ',' | sed 's/,$/\n/' | sed 's/:8083//g' | sed 's/:8283//g' | sed 's/:8383//g')

          if [[ "$tasks" == *"RUNNING"* ]]
          then
              tasks="${tasks//RUNNING/🟢 RUNNING}"
          elif [[ "$tasks" == *"PAUSED"* ]]
          then
              tasks="${tasks//PAUSED/⏸️  PAUSED}"
          elif [[ "$tasks" == *"STOPPED"* ]]
          then
              tasks="${tasks//STOPPED/🛑  STOPPED}"
          elif [[ "$tasks" == *"FAILED"* ]]
          then
              tasks="${tasks//FAILED/🛑 FAILED}"
          else
              tasks="🤔 N/A"
          fi

          stacktrace_connector=$(echo "$curl_output" | jq -r '.connector.trace | select(length > 0)')
          stacktrace_tasks=$(echo "$curl_output" | jq -r '.tasks[].trace | select(length > 0)')
          stacktrace=""
          if [ "$stacktrace_connector" != "" ]
          then
              stacktrace="connector: $stacktrace_connector"
          fi

          if [ "$stacktrace_tasks" != "" ]
          then
              stacktrace="$stacktrace tasks: $stacktrace_tasks"
          fi

          if [ -z "$stacktrace" ]
          then
              stacktrace="-"
          fi

          printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
          echo "-------------------------------------------------------------------------------------------------------------"
      fi
      set -e
  done
}

# :command.function
playground_connector_offsets_get_command() {
  # src/commands/connector/offsets/get.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.4.99"
          then
              logerror "❌ command is available since CP 7.5 only"
              return
          fi

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/offsets\""
      fi

      echo "$curl_output" | jq .
  }
  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi
      log "🏹 Getting offsets for $connector_type $type connector $connector"
      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
      else
          # SINK CONNECTOR

          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security"
          fi
          get_environment_used
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
          then
              handle_first_class_offset

          else
              if version_gt $tag "7.5.99"
              then
                  handle_first_class_offset
                  if [ $? != 0 ]
                  then
                      continue
                  fi
              else
                  docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security

              fi
          fi
      fi
  done
}

# :command.function
playground_connector_offsets_reset_command() {
  # src/commands/connector/offsets/reset.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then

          echo '{"type":"DELETE"}' > /tmp/delete.json
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request POST -H \"Content-Type: application/json\" --data @/tmp/delete.json \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.5.99"; then
              logerror "❌ command is available since CP 7.6 only"
              return
          fi
          playground connector stop --connector $connector

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X DELETE \"$connect_url/connectors/$connector/offsets\""

          echo "$curl_output" | jq .

          playground connector resume --connector $connector
      fi
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi
      log "🆕 Resetting offsets for $connector_type connector $connector"
      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
          sleep 5
          get_ccloud_connect
          log "🎯 get the status of the last offset request"
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request/status\" --header \"authorization: Basic $authorization\""
          echo "$curl_output" | jq .
          sleep 20
          playground connector offsets get --connector $connector
      else
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              sleep 5
              get_ccloud_connect
              log "🎯 get the status of the last offset request"
              handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request/status\" --header \"authorization: Basic $authorization\""
              echo "$curl_output" | jq .
              sleep 20
              playground connector offsets get --connector $connector
              exit 0
          fi

          if version_gt $tag "7.5.99"
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              playground connector offsets get --connector $connector
          else
              docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security | grep -v PARTITION

              if version_gt $tag "7.4.99"
              then
                  playground connector stop --connector $connector
              else
                  playground --output-level ERROR connector show-config --connector $connector > "$tmp_dir/create-$connector-config.sh"
                  playground connector delete --connector $connector
              fi

              docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector $security --to-earliest --reset-offsets --all-topics --execute

              if version_gt $tag "7.4.99"
              then
                  playground connector resume --connector $connector
              else
                  bash "$tmp_dir/create-$connector-config.sh"
              fi
              playground connector offsets get --connector $connector
          fi
      fi
  done
}

# :command.function
playground_connector_offsets_alter_command() {
  # src/commands/connector/offsets/alter.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then

          file=$tmp_dir/offsets-$connector.json
          file_tmp=$tmp_dir/tmp.json

          playground --output-level ERROR connector offsets get --connector $connector > $file

          # add mandatory name field
          new_json_content=$(cat $file | jq ". + {\"type\": \"PATCH\"}")
          echo "$new_json_content" > $file

          jq 'del(.id)' $file > $file_tmp
          cp $file_tmp $file
          jq 'del(.name)' $file > $file_tmp
          cp $file_tmp $file
          jq 'del(.metadata)' $file > $file_tmp
          cp $file_tmp $file

          editor=$(playground config get editor)
          if [ "$editor" != "" ]
          then
              log "✨ Update the connector offsets as per your needs, save and close the file to continue"
              if [ "$editor" = "code" ]
              then
                  code --wait $file
              else
                  $editor $file
              fi
          else
              if [[ $(type code 2>&1) =~ "not found" ]]
              then
                  logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                  exit 1
              else
                  log "✨ Update the connector offsets as per your needs, save and close the file to continue"
                  code --wait $file
              fi
          fi

          handle_ccloud_connect_rest_api "curl -s --request POST -H \"Content-Type: application/json\" --data @$file \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.5.99"; then
              logerror "❌ command is available since CP 7.6 only"
              return
          fi

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/offsets\""

          file=$tmp_dir/offsets-$connector.json
          echo "$curl_output" | jq . > $file

          editor=$(playground config get editor)
          if [ "$editor" != "" ]
          then
              log "✨ Update the connector offsets as per your needs, save and close the file to continue"
              if [ "$editor" = "code" ]
              then
                  code --wait $file
              else
                  $editor $file
              fi
          else
              if [[ $(type code 2>&1) =~ "not found" ]]
              then
                  logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                  exit 1
              else
                  log "✨ Update the connector offsets as per your needs, save and close the file to continue"
                  code --wait $file
              fi
          fi

          playground connector stop --connector $connector

          handle_onprem_connect_rest_api "curl $security -s -X PATCH -H \"Content-Type: application/json\" --data @$file \"$connect_url/connectors/$connector/offsets\""

          echo "$curl_output" | jq .

          playground connector resume --connector $connector
      fi
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi

      type=$(echo "$curl_output" | jq -r '.type')
      log "⛏️ Altering offsets for $connector_type connector $connector"

      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
          sleep 5
          get_ccloud_connect
          log "🎯 get the status of the last offset request"
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request/status\" --header \"authorization: Basic $authorization\""
          echo "$curl_output" | jq .
          sleep 20
          playground connector offsets get --connector $connector
      else
          # SINK CONNECTOR
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              sleep 5
              get_ccloud_connect
              log "🎯 get the status of the last offset request"
              handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request/status\" --header \"authorization: Basic $authorization\""
              echo "$curl_output" | jq .
              sleep 20
              playground connector offsets get --connector $connector
          else
              if version_gt $tag "7.5.99"
              then
                  handle_first_class_offset
                  if [ $? != 0 ]
                  then
                      continue
                  fi
                  playground connector offsets get --connector $connector
              else
                  # if [[ -n "$verbose" ]]
                  # then
                  #     log "🐞 CLI command used"
                  #     echo "kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security"
                  # fi
                  get_environment_used
                  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
                  then
                      logwarn "command is not available with $connector_type $type connector"
                      continue
                  else
                      file=$tmp_dir/offsets-$connector.csv

                      if version_gt $tag "7.4.99"
                      then
                          playground connector stop --connector $connector
                      else
                          playground --output-level ERROR connector show-config --connector $connector > "$tmp_dir/create-$connector-config.sh"
                          playground connector delete --connector $connector
                      fi

                      echo "topic,partition,current-offset" > $file
                      docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector $security --export --reset-offsets --to-current --all-topics --dry-run >> $file

                      editor=$(playground config get editor)
                      if [ "$editor" != "" ]
                      then
                          log "✨ Update the connector offsets as per your needs, save and close the file to continue"
                          if [ "$editor" = "code" ]
                          then
                              code --wait $file
                          else
                              $editor $file
                          fi
                      else
                          if [[ $(type code 2>&1) =~ "not found" ]]
                          then
                              logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                              exit 1
                          else
                              log "✨ Update the connector offsets as per your needs, save and close the file to continue"
                              code --wait $file
                          fi
                      fi

                      # remove any empty lines and header
                      grep -v '^$' "$file" > $tmp_dir/tmp && mv $tmp_dir/tmp "$file"
                      grep -v 'current-offset' "$file" > $tmp_dir/tmp && mv $tmp_dir/tmp "$file"

                      docker cp $file $container:/tmp/offsets.csv > /dev/null 2>&1
                      docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector $security --reset-offsets --from-file /tmp/offsets.csv --execute

                      if version_gt $tag "7.4.99"
                      then
                          playground connector resume --connector $connector
                      else
                          bash "$tmp_dir/create-$connector-config.sh"
                      fi
                  fi
                  playground connector offsets get --connector $connector
              fi
          fi
      fi
  done
}

# :command.function
playground_connector_plugins_command() {
  # src/commands/connector/plugins.sh
  all="${args[--all]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  log "🎨 Displaying all connector plugins installed"
  if [[ -n "$all" ]]
  then
      log "🌕 Displaying also transforms, converters, predicates available"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          logerror "❌ --all is set but not supported with $connector_type connector"
          exit 1
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connector-plugins?connectorsOnly=false\""
      fi

      echo "$curl_output" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t

  else
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connector-plugins\""
      fi

      echo "$curl_output" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t
  fi

}

# :command.function
playground_connector_pause_command() {
  # src/commands/connector/pause.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "⏸️ Pausing $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request PUT \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/pause\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/pause\""
      fi

      log "⏸️ $connector_type connector $connector has been paused successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_versions_command() {
  # src/commands/connector/versions.sh
  test_file=$(playground state get run.test_file)

  connector_type=$(playground state get run.connector_type)
  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector versions command is not supported with $connector_type connector"
      exit 0
  fi

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
      exit 1
  else
      current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
      log "🎯 Version currently used for confluent platform"
      echo "$current_tag"

      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
              # happens when plugin is not coming from confluent hub
              logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
          fi

          playground connector-plugin versions --connector-plugin $owner/$name --last 10

          # latest
          latest=$(playground connector-plugin versions --connector-plugin $owner/$name --last 1)
          latest_to_compare=$(echo "$latest" | sed 's/ ([0-9]* days ago)//')

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              version=$(cat $manifest_file | jq -r '.version')
              release_date=$(cat $manifest_file | jq -r '.release_date')
          else
              logwarn "file $manifest_file does not exist, could not retrieve version"
              exit 0
          fi

          current="🔢 v$version - 📅 release date: $release_date"
          if [ "$current" == "$latest_to_compare" ]
          then
              log "👻 Version currently used for $owner/$name is latest"
              echo "$current"
          else
              log "🗯️ Version currently used for $owner/$name is not latest"
              log "Current"
              echo "$current"
              log "Latest on Hub"
              echo "$latest"
          fi

      done
  fi
}

# :command.function
playground_connector_restart_command() {
  # src/commands/connector/restart.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector restart command is not supported with $connector_type connector"
      exit 0
  fi

  tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
  if [ $? != 0 ] || [ "$tag" == "" ]
  then
      logerror "Could not find current CP version from docker ps"
      exit 1
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "🔄 Restarting $connector_type connector $connector"

      get_connect_url_and_security
      log "🔄 Restarting connector $connector"
      if ! version_gt $tag "6.9.9"
      then
          handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/tasks"

          task_ids=$(echo "$curl_output" | jq -r '.[].id.task')

          for task_id in $task_ids
          do
              log "🤹‍♂️ Restart task $task_id"
              handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/tasks/$task_id/restart\""
          done
      else
          handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/restart?includeTasks=true&onlyFailed=false\""
      fi
      log "🔄 $connector_type connector $connector has been restarted successfully"
  done
  sleep 3
  playground connector status --connector $connector
}

# :command.function
playground_connector_stop_command() {
  # src/commands/connector/stop.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector stop command is not available with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
  if [ $? != 0 ] || [ "$tag" == "" ]
  then
      logerror "❌ could not find current CP version from docker ps"
      exit 1
  fi

  if ! version_gt $tag "7.4.99"; then
      logerror "❌ stop connector is available since CP 7.5 only"
      exit 1
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "🛑 Stopping $connector_type connector $connector"
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/stop\""

      log "🛑 $connector_type connector $connector has been stopped successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_resume_command() {
  # src/commands/connector/resume.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "⏯️ Resuming $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request PUT \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/resume\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/resume\""
      fi

      log "⏯️ $connector_type connector $connector has been resumed successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_delete_command() {
  # src/commands/connector/delete.sh
  verbose="${args[--verbose]}"
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      check_if_continue
  fi
  for connector in "${items[@]}"
  do
      log "❌ Deleting $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request DELETE \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X DELETE \"$connect_url/connectors/$connector\""
      fi

      log "❌ $connector_type connector $connector has been deleted successfully"
  done
}

# :command.function
playground_connector_show_lag_command() {
  # src/commands/connector/show-lag.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"
  interval="${args[--interval]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  declare -A prev_lags
  prev_lags=()

  function show_output () {
    prev_topic=""
    while read line; do
      arr=($line)
      topic=${arr[1]}
      partition=${arr[2]}
      current_offset=${arr[3]}
      end_offset=${arr[4]}
      lag=${arr[5]}
      prev_lag=${prev_lags["${topic}_${partition}"]}
      compare_line=""
      compare_action=""

      if [ "$topic" != "$prev_topic" ] && [ "$prev_topic" != "" ]
      then
        echo "---"
      fi

      if [[ "$total_lag" =~ ^[0-9]+$ ]]
      then
        if [[ "$prev_lag" =~ ^[0-9]+$ ]] && [[ "$lag" =~ ^[0-9]+$ ]]
        then
          if [ $lag -lt $prev_lag ]
          then
            compare_line="🔻 $(($prev_lag - $lag))"
            compare_action="up"
          elif [ $lag -eq $prev_lag ]
          then
            compare_line="🔸"
            compare_action="same"
          else
            compare_line="🔺 $(($lag - $prev_lag))"
            compare_action="down"
          fi
        fi
      fi

      if [ $lag == 0 ]
      then
        compare_line="🏁"
      fi

      if [[ "$end_offset" =~ ^[0-9]+$ ]] && [[ "$end_offset" =~ ^[0-9]+$ ]] && [ $end_offset != 0 ] && [[ "$lag" =~ ^[0-9]+$ ]]
      then
        # calculate the percentage of lag
        percentage=$((100 * lag / end_offset))
        inverse_percentage=$((100 - percentage))

        # create the progress bar
        bar_length=20
        filled_length=$((percentage * bar_length / 100))
        empty_length=$((bar_length - filled_length))
        bar=$(printf "%${empty_length}s" | tr ' ' '🔹')
        bar+=$(printf "%${filled_length}s" | tr ' ' '💠')
      fi

      prev_lags["${topic}_${partition}"]=$lag
      if [ "$compare_line" != "" ]
      then
        case "${compare_action}" in
          up)
            printf "\033[32mtopic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\033[0m\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
          down)
            printf "\033[31mtopic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\033[0m\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
          *)
            printf "topic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
        esac
      else
        printf "topic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%%\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage"
      fi
      prev_topic="$topic"
    done < <(cat "$lag_output" | grep -v PARTITION | sed '/^$/d' | sort -k2n)
  }

  function log_down() {
    GREEN='\033[0;32m'
    NC='\033[0m' # No Color
    echo -e "$GREEN$(date +"%H:%M:%S") 🔻$@$NC"
  }

  function log_up() {
    RED='\033[0;31m'
    NC='\033[0m' # No Color
    echo -e "$RED$(date +"%H:%M:%S") 🔺$@$NC"
  }

  function log_same() {
    ORANGE='\033[0;33m'
    NC='\033[0m' # No Color
    echo -e "$ORANGE`date +"%H:%M:%S"` 🔸$@$NC"
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  lag_output=$tmp_dir/lag_output

  function handle_signal {
    echo "Stopping..."
    stop=1
  }
  # Set the signal handler
  trap handle_signal SIGINT

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
    maybe_id=""
    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
        get_ccloud_connect
        handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
        connectorId=$(get_ccloud_connector_lcc $connector)
        maybe_id=" ($connectorId)"
    else
        get_connect_url_and_security
        handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
    fi

    type=$(echo "$curl_output" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
      logwarn "⏭️ Skipping $type $connector_type connector ${connector}${maybe_id}, it must be a sink to show the lag"
      continue

    fi

    playground connector status --connector $connector  > $tmp_dir/result.log  2>&1
    if [ $(grep -c "✅" $tmp_dir/result.log) -ne 1 ]
    then
        logerror "❌ $connector_type connector ${connector}${maybe_id} instance is not in ✅ RUNNING state"
        exit 1
    fi

    if [ $(grep -c "🟢" $tmp_dir/result.log) -lt 1 ]
    then
        logerror "❌ $connector_type connector ${connector}${maybe_id} does not have 🟢 task in RUNNING state"
        exit 1
    fi

    if [[ -n "$verbose" ]]
    then
        log "🐞 CLI command used"
        echo "kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security"
    fi

    SECONDS=0
    prev_lag=0
    stop=0

    get_environment_used
    while [ $stop != 1 ]
    do
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
      then
        get_ccloud_connect
        get_connect_image

        if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]

        then
          consumer_group="connect-$connectorId"
        else
          consumer_group="connect-$connector"
        fi
        docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-consumer-groups --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --group $consumer_group --describe | grep -v PARTITION | sed '/^$/d' &> $lag_output
      else
        docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security | grep -v PARTITION | sed '/^$/d' &> $lag_output
      fi

      if grep -q "Warning" $lag_output
      then
        logwarn "🐢 consumer group for $connector_type connector ${connector}${maybe_id} is rebalancing"
        cat $lag_output
        sleep $interval
        continue
      fi

      set +e
      lag_not_set=$(cat "$lag_output" | awk -F" " '{ print $6 }' | grep "-")

      if [ ! -z "$lag_not_set" ]
      then
        logwarn "🐢 consumer lag for $connector_type connector ${connector}${maybe_id} is not available"
        show_output
        sleep $interval
      else
        total_lag=$(cat "$lag_output" | grep -v "PARTITION" | awk -F" " '{sum+=$6;} END{print sum;}')

        if [[ "$total_lag" =~ ^[0-9]+$ ]]
        then
          if [ $total_lag -ne 0 ]
          then
            compare=""
            compare_action=""
            if [[ "$prev_lag" =~ ^[0-9]+$ ]]
            then
              if [ $prev_lag != 0 ]
              then
                if [ $total_lag -lt $prev_lag ]
                then
                  compare="🔻 $(($prev_lag - $total_lag))"
                  compare_action="down"
                elif [ $total_lag -eq $prev_lag ]
                then
                  compare="🔸"
                  compare_action="same"
                else
                  compare="🔺 $(($total_lag - $prev_lag))"
                  compare_action="up"
                fi
              fi
            fi
            if [ "$compare" != "" ]
            then
              case "${compare_action}" in
                up)
                  log_up "🔥 total consumer lag for $connector_type connector ${connector}${maybe_id} has increased to $total_lag $compare (press ctrl-c to stop)"
                ;;
                down)
                  log_down "🚀 consumer lag for $connector_type connector ${connector}${maybe_id} has decreased to $total_lag $compare (press ctrl-c to stop)"
                ;;
                *)
                  log_same "🐌 consumer lag for $connector_type connector ${connector}${maybe_id} is still $total_lag $compare (press ctrl-c to stop)"
                ;;
              esac
            else
              log "🐢 consumer lag for $connector_type connector ${connector}${maybe_id} is $total_lag"
            fi
            show_output
            prev_lag=$total_lag
            sleep $interval
          else
            ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
            log "🏁 consumer lag for $connector_type connector ${connector}${maybe_id} is 0 ! $ELAPSED"
            stop=1
            show_output
            break
          fi
        fi
      fi
    done
  done
}

# :command.function
playground_connector_show_config_command() {
  # src/commands/connector/show-config.sh
  connector="${args[--connector]}"
  force_rest_endpoint="${args[--force-rest-endpoint]}"
  verbose="${args[--verbose]}"
  no_clipboard="${args[--no-clipboard]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  ci_ok=0
  if [ ! -z "$GITHUB_RUN_NUMBER" ] && [[ -n "$no_clipboard" ]]
  then
      ci_ok=1
  fi
  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      if [ -f "/tmp/config-$connector" ] && [ ${ci_ok} -eq 1 ] && [[ ! -n "$force_rest_endpoint" ]]
      then
          log "🧰 Current config for $connector_type connector $connector"
          if [[ -n "$no_clipboard" ]]
          then
              echo "playground connector create-or-update --connector $connector --no-clipboard << EOF"
        else
            echo "playground connector create-or-update --connector $connector << EOF"
        fi
        cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g'
        echo "EOF"

        if [[ "$OSTYPE" == "darwin"* ]]
        then
            clipboard=$(playground config get clipboard)
            if [ "$clipboard" == "" ]
            then
                playground config set clipboard true
            fi

            if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
            then
                tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
                if [ -z "$PG_VERBOSE_MODE" ]
                then
                    trap 'rm -rf $tmp_dir' EXIT
                else
                    log "🐛📂 not deleting tmp dir $tmp_dir"
                fi
                echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir/tmp
                cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir/tmp
                echo "EOF" >> $tmp_dir/tmp

                cat $tmp_dir/tmp | pbcopy
                log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config set clipboard false')"
            fi
        fi
    else
        log "🧰 Current config for $connector_type connector $connector (using REST API /config endpoint)"

        if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
        then
            get_ccloud_connect
            handle_ccloud_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config\" --header \"authorization: Basic $authorization\""
        else
            get_connect_url_and_security
            handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/config\""
        fi

        if [[ -n "$no_clipboard" ]]
        then
            echo "playground connector create-or-update --connector $connector --no-clipboard << EOF"
        else
            echo "playground connector create-or-update --connector $connector << EOF"
        fi
        echo "$curl_output" | jq -S . | sed 's/\$/\\$/g'
        echo "EOF"

        if [[ "$OSTYPE" == "darwin"* ]]
        then
            clipboard=$(playground config get clipboard)
            if [ "$clipboard" == "" ]
            then
                playground config set clipboard true
            fi

            if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
            then
                tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
                if [ -z "$PG_VERBOSE_MODE" ]
                then
                    trap 'rm -rf $tmp_dir' EXIT
                else
                    log "🐛📂 not deleting tmp dir $tmp_dir"
                fi
                echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir/tmp
                echo "$curl_output" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir/tmp
                echo "EOF" >> $tmp_dir/tmp

                cat $tmp_dir/tmp | pbcopy
                log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config set clipboard false')"
            fi
        fi
    fi
done
}

# :command.function
playground_connector_show_config_parameters_command() {
  # src/commands/connector/show-config-parameters.sh
  connector="${args[--connector]}"
  open="${args[--open]}"
  force_refresh="${args[--force-refresh]}"
  only_show_file_path="${args[--only-show-file-path]}"
  only_show_json="${args[--only-show-json]}"
  only_show_json_file_path="${args[--only-show-json-file-path]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector show-config-parameters command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  json_file=$tmp_dir/connector.json

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/config\""
      fi

      echo "$curl_output" > $json_file

      connector_class=$(echo "$curl_output" | jq -r '."connector.class"')
      class=$(echo $connector_class | rev | cut -d '.' -f 1 | rev)

      version="unknown"
      if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
      then
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" $connect_url/connector-plugins/"
          for row in $(echo "$curl_output" | jq -r '.[] | @base64'); do
              _jq() {
                  echo ${row} | base64 --decode | jq -r ${1}
              }

              class=$(_jq '.class')

              if [ "$class" != "$connector_class" ]
              then
                  version=$(_jq '.version')
              fi
          done
      fi

      mkdir -p $root_folder/.connector_config
      filename="$root_folder/.connector_config/config-$connector_class-$version.txt"
      json_filename="$root_folder/.connector_config/config-$connector_class-$version.json"

      if [[ ! -n "$only_show_json_file_path" ]]
      then
          if [[ -n "$only_show_json" ]]
          then
              log "🔩 list of all available parameters for $connector_type connector $connector ($class) and version $version (with default value when applicable)"
          else
              log "🔩 getting parameters for $connector_type connector $connector ($class) and version $version"
          fi
      fi

      if [[ -n "$force_refresh" ]]
      then
          if [ -f $filename ]
          then
              rm -f $filename
          fi
          if [ -f $json_filename ]
          then
              rm -f $json_filename
          fi
      fi
      if [ ! -f $filename ] || [ ! -f $json_filename ]
      then
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              get_ccloud_connect
              handle_ccloud_connect_rest_api "curl -s --request PUT -H \"Content-Type: application/json\" --data @$json_file \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins/$connector_class/config/validate\" --header \"authorization: Basic $authorization\""
          else
              get_connect_url_and_security
              handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$json_file $connect_url/connector-plugins/$connector_class/config/validate"
          fi

          if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
          then
              set +e
              json_file=/tmp/json
              echo "$curl_output" > $json_file
              jq_output=$(jq . "$json_file" 2>&1)
              error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

              if [[ -n "$error_line" ]]; then
                  logerror "❌ Invalid JSON at line $error_line"
              fi
              set -e

              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  if [[ $(type -f bat 2>&1) =~ "not found" ]]
                  then
                      cat -n $json_file
                  else
                      bat $json_file --highlight-line $error_line
                  fi
              fi

              exit 1
          fi

          current_group=""
          configs=$(echo "$curl_output" | jq -r '.configs')
          while IFS= read -r row; do

              IFS=$'\n'
              arr=($(echo "$row" | jq -r '.definition.group, .definition.name, .definition.default_value, .definition.type, .definition.required, .definition.importance, .definition.documentation'))
              group="${arr[0]}"
                                  set +x
              if [[ "$group" == "Common" || "$group" == "Transforms" || "$group" == "Error Handling" || "$group" == "Topic Creation" || "$group" == "offsets.topic" || "$group" == "Exactly Once Support" || "$group" == "Predicates" || "$group" == "Confluent Licensing" ]] ; then
                  continue
              fi

              if [ "$group" != "$current_group" ]
              then
                  echo -e "==========================" >> "$filename"
                  echo -e "$group"                     >> "$filename"
                  echo -e "==========================" >> "$filename"
                  current_group=$group
              fi

              param="${arr[1]}"
              default="${arr[2]}"
              type="${arr[3]}"
              required="${arr[4]}"
              importance="${arr[5]}"
              description="${arr[6]}"

              echo -e "🔘 $param" >> "$filename"
              echo -e "" >> "$filename"
              echo -e "$description" >> "$filename"
              echo -e "" >> "$filename"
              echo -e "\t - Type: $type" >> "$filename"
              echo -e "\t - Default: $default" >> "$filename"
              echo -e "\t - Importance: $importance" >> "$filename"
              echo -e "\t - Required: $required" >> "$filename"
              echo -e "" >> "$filename"

              if [ "$default" == "null" ]
              then
                  default=""
              fi
              echo -e "    \"$param\": \"$default\"," >> "$json_filename"
              sort "$json_filename" -o /tmp/tmp
              mv /tmp/tmp "$json_filename"
          done <<< "$(echo "$configs" | jq -c '.[]')"
      fi

      if [ ! -f $filename ]
      then
          logwarn "❌ there was no specific config for this $connector_type connector"
          exit 0
      fi

      if [[ -n "$open" ]]
      then
          if [[ -n "$only_show_json" ]]
          then
              filename=$json_filename
          else
              cat $filename > "/tmp/config-$connector_class-$version.txt"
              filename="/tmp/config-$connector_class-$version.txt"
              cat $json_filename >> $filename
              echo "🔩 list of all available parameters for connector $connector ($class) and version $version (with default value when applicable)" >> $filename
          fi

          editor=$(playground config get editor)
          if [ "$editor" != "" ]
          then
              log "📖 Opening ${filename} using configured editor $editor"
              $editor ${filename}
          else
              if [[ $(type code 2>&1) =~ "not found" ]]
              then
                  logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
                  exit 1
              else
                  log "📖 Opening ${filename} with code (default) - you can change editor by using playground config editor <editor>"
                  code ${filename}
              fi
          fi
      else
          if [[ -n "$only_show_json" ]] || [[ -n "$only_show_json_file_path" ]]
          then
              if [[ -n "$only_show_json_file_path" ]]
              then
                  echo "$json_filename"
              else
                  cat $json_filename
              fi
              return
          fi

          if [[ -n "$only_show_file_path" ]]
          then
              echo "$filename"
          else
              cat $filename
              log "🔩 list of all available parameters for $connector_type connector $connector ($class) and version $version (with default value when applicable)"
              cat $json_filename
          fi
      fi
  done
}

# :command.function
playground_connector_select_config_command() {
  # src/commands/connector/select-config.sh
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  log "🗜️ Easily select config from all possible configuration parameters"
  log "🎓 Tip: use <tab> to select multiple config at once !"

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      json_file=$(playground connector show-config-parameters --only-show-json --only-show-json-file-path --connector $connector)
      if [ ! -f "$json_file" ]
      then
          logwarn "❌ file <$json_file> does not exist, could not retrieve json config file for connector $connector."
          exit 1
      fi

      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
          fzf_option_wrap="--preview-window=40%,wrap"
          fzf_option_pointer="--pointer=👉"
          fzf_option_rounded="--border=rounded"
      else
          fzf_options=""
          fzf_option_pointer=""
          fzf_option_rounded=""
      fi

      res=$(cat $json_file | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🗜️" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)

      log "🗜️ selected config parameter(s) for connector $connector"
      echo "$res"

      if [[ "$OSTYPE" == "darwin"* ]]
      then
          clipboard=$(playground config get clipboard)
          if [ "$clipboard" == "" ]
          then
              playground config set clipboard true
          fi

          if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
          then
              tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
              if [ -z "$PG_VERBOSE_MODE" ]
              then
                  trap 'rm -rf $tmp_dir' EXIT
              else
                  log "🐛📂 not deleting tmp dir $tmp_dir"
              fi
              echo "$res" > $tmp_dir/tmp

              cat $tmp_dir/tmp | pbcopy
              log "📋 config has been copied to the clipboard (disable with 'playground config set clipboard false')"
          fi
      fi
  done
}

# :command.function
playground_connector_snippets_command() {
  # src/commands/connector/snippets.sh
  converter=${args[--converter]}
  dlq=${args[--dlq]}

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ ! -n "$converter" ]] && [[ ! -n "$dlq" ]]
  then
      logerror "❌ neither --converter or --dlq were provided"
      exit 1
  fi

  if [[ -n "$dlq" ]]
  then
      dlq_file=$tmp_dir/dlq
      echo -e "    \"errors.tolerance\": \"all\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.topic.name\": \"dlq\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.topic.replication.factor\": \"1\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.context.headers.enable\": \"true\"," >> $dlq_file
      echo -e "    \"errors.log.enable\": \"true\"," >> $dlq_file
      echo -e "    \"errors.log.include.messages\": \"true\"," >> $dlq_file
  fi

  if [[ -n "$converter" ]]
  then
      converter_file=$tmp_dir/converter
      case "${converter}" in
          string)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," >> $converter_file
          ;;
          bytearray)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.converters.ByteArrayConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.converters.ByteArrayConverter\"," >> $converter_file
          ;;
          json)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"key.converter.schemas.enable\": \"false\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"value.converter.schemas.enable\": \"false\"," >> $converter_file
          ;;
          json-schema-enabled)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
          ;;
          avro|json-schema|protobuf)

              case "${converter}" in
                  avro)
                      converter_class="io.confluent.connect.avro.AvroConverter"
                  ;;
                  json-schema)
                      converter_class="io.confluent.connect.json.JsonSchemaConverter"
                  ;;
                  protobuf)
                      converter_class="io.confluent.connect.protobuf.ProtobufConverter"
                  ;;
              esac

              environment=$(playground state get run.environment_before_switch)
              if [ "$environment" = "" ]
              then
                  environment=$(playground state get run.environment)
              fi

              if [ "$environment" = "" ]
              then
                  environment="plaintext"
              fi

              case "${environment}" in
              plaintext|sasl-plain|ldap-authorizer-sasl-plain|ldap-sasl-plain|sasl-scram|kerberos|ssl_kerberos)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
              ;;
              ccloud)
                  if [ -f $root_folder/.ccloud/env.delta ]
                  then
                      source $root_folder/.ccloud/env.delta
                  else
                      logerror "ERROR: $root_folder/.ccloud/env.delta has not been generated"
                      exit 1
                  fi
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"$SCHEMA_REGISTRY_URL\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.user.info\": \"\${file:/data:schema.registry.basic.auth.user.info}\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"$SCHEMA_REGISTRY_URL\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.user.info\": \"\${file:/data:schema.registry.basic.auth.user.info}\"," >> $converter_file
                  ;;

              sasl-ssl|2way-ssl)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"https://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.truststore.location\": \"/etc/kafka/secrets/kafka.connect.truststore.jks\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.truststore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.keystore.location\": \"/etc/kafka/secrets/kafka.connect.keystore.jks\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.keystore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.key.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"https://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.truststore.location\": \"/etc/kafka/secrets/kafka.connect.truststore.jks\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.truststore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.keystore.location\": \"/etc/kafka/secrets/kafka.connect.keystore.jks\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.keystore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.key.password\": \"confluent\"," >> $converter_file
                  ;;

              rbac-sasl-plain)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.user.info\": \"connectorSA:connectorSA\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.user.info\": \"connectorSA:connectorSA\"," >> $converter_file
                  ;;
              *)
                  return
              ;;
              esac
          ;;
      esac
  fi

  clipboard_file=$tmp_dir/clipboard
  if [ -f "$dlq_file" ]
  then
      log "💀 add this for getting dead letter queue"
      cat $dlq_file

      cat $dlq_file >> $clipboard_file
  fi

  if [ -f "$converter_file" ]
  then
      log "🔌 converter config for $converter"
      cat $converter_file

      cat $converter_file >> $clipboard_file
  fi

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ -f "$clipboard_file" ]
      then
          if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
          then
              cat $clipboard_file | pbcopy
              log "📋 config has been copied to the clipboard (disable with 'playground config set clipboard false')"
          fi
      fi
  fi
}

# :command.function
playground_connector_open_docs_command() {
  # src/commands/connector/open-docs.sh
  test_file=$(playground state get run.test_file)
  only_show_url="${args[--only-show-url]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector open-docs command is not supported with $connector_type connector"
      exit 0
  fi

  if [ ! -f $test_file ]
  then

      logerror "❌ File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
      exit 1
  else
      doc_available=1
      doc_links=""
      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              url=$(cat $manifest_file | jq -r '.documentation_url')
              name=$(cat $manifest_file | jq -r '.name')
              url=${url//)/}

              if [[ $url =~ "http" ]]
              then
                  short_url=$(echo $url | cut -d '#' -f 1)
                  if [[ -n "$only_show_url" ]]
                  then
                      log "🌐 documentation for $connector_type connector $name is available at:"
                      echo "$short_url"
                      doc_links="${doc_links}|$name@$short_url"
                  else
                      log "🌐 opening documentation for $connector_type connector $name $short_url"
                      open "$short_url"
                  fi
              else
                  doc_available=0
              fi
          else
              doc_available=0
          fi
      done
      if [ $doc_available -eq 0 ]
      then
          log "🌐 documentation could not be retrieved"

      else
          doc_links="${doc_links#|}"
          doc_links=$(echo "${doc_links}" | tr -d '${}')
          playground state set run.connector_docs_links "$doc_links"
      fi
  fi
}

# :command.function
playground_connector_log_level_command() {
  # src/commands/connector/log-level.sh
  level="${args[--level]}"
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector log-level command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  log "🔰 also setting io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema registry rest requests) to $level"
  playground debug log-level set -p "io.confluent.kafka.schemaregistry.client.rest.RestService" -l $level
  log "🔗 also setting org.apache.kafka.connect.runtime.TransformationChain (to see records before and after SMTs) to $level"
  playground debug log-level set -p "org.apache.kafka.connect.runtime.TransformationChain" -l $level

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector\""

      tmp=$(echo "$curl_output" | jq -r '.config."connector.class"')
      package="${tmp%.*}"

      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "sink" ]
      then
          log "🔗 also setting org.apache.kafka.connect.runtime.WorkerSinkTask to $level"
          playground debug log-level set -p "org.apache.kafka.connect.runtime.WorkerSinkTask" -l $level
      else
          log "🔗 also setting org.apache.kafka.connect.runtime.WorkerSourceTask to $level"
          playground debug log-level set -p "org.apache.kafka.connect.runtime.WorkerSourceTask" -l $level
      fi
      # log "🧬 Set log level for connector $connector to $level"
      playground debug log-level set -p "$package" -l "$level"
  done
}

# :command.function
playground_connector_logs_command() {
  # src/commands/connector/logs.sh
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"
  lcc_id="${args[--lcc-id]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      logerror "🚨 This command is not supported for custom connectors"
      exit 1
  fi

  opensearch_script="$root_folder/reproduction-models/_miscellaneous/opensearch/alfred-workflow/alfred-opensearch-connect-workflow/open-lcc-logs.ksh"
  datadog_script="$root_folder/reproduction-models/_miscellaneous/opensearch/alfred-workflow/alfred-opensearch-connect-workflow/open-lcc-datadog.ksh"

  if [[ -n "$lcc_id" ]]
  then
      if [ -f "$opensearch_script" ]
      then
          # confluent employee
          export number_of_days=4
          export open_audit_logs=1
          log "🐛 Opening dashboards for $CONNECTOR_TYPE_FULLY_MANAGED connector ($lcc_id)"
          bash "$opensearch_script" "$lcc_id"
          bash "$datadog_script" "$lcc_id"
          exit 0
      else
          logerror "🚨 This command with --lcc-id is not supported for non Confluent employees ($$root_folder/reproduction-models does not contain required scripts)"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ]
  then
      if [ -f "$opensearch_script" ]
      then
          # confluent employee
          if [[ ! -n "$lcc_id" ]]
          then
              connector=$(playground get-connector-list)
              if [ "$connector" == "" ]
              then
                  log "💤 No $connector_type connector is running !"
                  exit 1
              fi
          fi

          items=($connector)
          length=${#items[@]}
          if ((length > 1))
          then
              log "✨ --lcc-id flag was not provided, applying command to all $CONNECTOR_TYPE_FULLY_MANAGED connectors"
          fi
          export number_of_days=4
          export open_audit_logs=1
          for connector in "${items[@]}"
          do
              connectorId=$(get_ccloud_connector_lcc $connector)
              log "🐛 Opening dashboards for $connector_type connector $connector ($connectorId)"
              bash "$opensearch_script" "$connectorId"
              bash "$datadog_script" "$connectorId"
          done

      else
          logerror "🚨 This command is not supported for fully managed connectors or non Confluent employees ($$root_folder/reproduction-models does not contain required scripts)"
          exit 1
      fi
  else
      if [[ -n "$open" ]]
      then
          playground container logs --open --container connect
      elif [[ -n "$log" ]]
      then
          playground container logs --container connect --wait-for-log "$log" --max-wait "$max_wait"
      else

          playground container logs --container connect
      fi
  fi
}

# :command.function
playground_connector_open_in_confluent_cloud_command() {
  # src/commands/connector/open-in-confluent-cloud.sh
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector open-in-confluent-cloud command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      check_if_continue
  fi
  for connector in "${items[@]}"
  do
      get_ccloud_connect
      handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
      connectorId=$(get_ccloud_connector_lcc $connector)

      type=$(echo "$curl_output" | jq -r '.type')
      TYPE=""
      if [ "$type" == "sink" ]
      then
          TYPE="sinks"
      else
          TYPE="sources"
      fi

      log "🤖 Open $connector_type connector $connector ($connectorId) in Confluent Cloud dashboard"
      open "https://confluent.cloud/environments/$environment/clusters/$cluster/connectors/$TYPE/$connector?granularity=PT1M&interval=3600000&label=Last%20hour"
  done
}

# :command.function
playground_connector_create_or_update_command() {
  # src/commands/connector/create-or-update.sh
  connector="${args[--connector]}"
  json=${args[json]}
  level=${args[--level]}
  package=${args[--package]}
  validate=${args[--validate]}
  wait_for_zero_lag=${args[--wait-for-zero-lag]}
  skip_automatic_connector_config=${args[--skip-automatic-connector-config]}
  verbose="${args[--verbose]}"
  no_clipboard="${args[--no-clipboard]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      if [[ -n "$level" ]]
      then
          logerror "❌ --level is set but not supported with $connector_type connector"
          exit 1
      fi

      if [[ -n "$package" ]]
      then
          logerror "❌ --package is set but not supported with $connector_type connector"
          exit 1
      fi
  fi

  environment=$(playground state get run.environment_before_switch)
  if [ "$environment" = "" ]
  then
      environment=$(playground state get run.environment)
  fi

  if [ "$environment" = "" ]
  then
      environment="plaintext"
  fi

  if [ "$json" = "-" ]
  then
      # stdin
      json_content=$(cat "$json")
  else
      json_content=$json
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  json_file=$tmp_dir/connector.json
  new_json_file=$tmp_dir/connector_new.json
  json_validate_file=$tmp_dir/json_validate_file

  echo "$json_content" > $json_file

  # JSON is invalid
  if ! echo "$json_content" | jq -e .  > /dev/null 2>&1
  then
      set +e
      jq_output=$(jq . "$json_file" 2>&1)
      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

      if [[ -n "$error_line" ]]; then
          logerror "❌ Invalid JSON at line $error_line"
      fi
      set -e

      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          if [[ $(type -f bat 2>&1) =~ "not found" ]]
          then
              cat -n $json_file
          else
              bat $json_file --highlight-line $error_line
          fi
      fi
      exit 1
  fi

  is_create=1
  set +e
  connectors=$(playground get-connector-list)
  ret=$?
  if [ $ret -ne 0 ]
  then
      logerror "❌ Failed to get list of connectors"
      playground get-connector-list
      exit 1
  fi
  set -e
  items=($connectors)
  for con in ${items[@]}
  do
      if [[ "$con" == "$connector" ]]
      then
          is_create=0
      fi
  done

  if [[ -n "$validate" ]]
  then
      log "✅ --validate is set"
      set +e
      connector_class=$(echo "$json_content" | jq -r '."connector.class"')

      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" -H \"authorization: Basic $authorization\" --data @$json_file https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins/$connector_class/config/validate"
      else
          get_connect_url_and_security
          if [[ -n "$skip_automatic_connector_config" ]]
          then
              log "🤖 --skip-automatic-connector-config is set"
          else
              add_connector_config_based_on_environment "$environment" "$json_content"
          fi
          # add mandatory name field
          new_json_content=$(echo $json_content | jq ". + {\"name\": \"$connector\"}")

          echo "$new_json_content" > $new_json_file
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$new_json_file $connect_url/connector-plugins/$connector_class/config/validate"
      fi
      set -e
      if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
      then
          set +e
          echo "$curl_output" > $json_validate_file
          jq_output=$(jq . "$json_validate_file" 2>&1)
          error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

          if [[ -n "$error_line" ]]; then
              logerror "❌ Invalid JSON at line $error_line"
          fi
          set -e

          if [ -z "$GITHUB_RUN_NUMBER" ]
          then
              if [[ $(type -f bat 2>&1) =~ "not found" ]]
              then
                  cat -n $json_validate_file
              else
                  bat $json_validate_file --highlight-line $error_line
              fi
          fi

          exit 1
      fi

      is_valid=1
      for row in $(echo "$curl_output" | jq -r '.configs[] | @base64'); do
          _jq() {
              echo ${row} | base64 --decode | jq -r ${1}
          }

          name=$(_jq '.value.name')
          value=$(_jq '.value.value')
          errors=$(_jq '.value.errors')

          if [ "$(echo "$errors" | jq 'length')" -gt 0 ]
          then
              is_valid=0
              logerror "❌ validation error for config <$name=$value>"

              echo "$errors" | jq .
          fi
      done

      if [ $is_valid -eq 1 ]
      then
          log "✅ $connector_type connector config is valid !"

      else
          exit 1
      fi
  fi

  if [ $is_create == 1 ]
  then
      log "🛠️ Creating $connector_type connector $connector"
  else
      log "🔄 Updating $connector_type connector $connector"
  fi

  echo "$json_content" > "/tmp/config-$connector"

  if [ -z "$GITHUB_RUN_NUMBER" ]
  then
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          clipboard=$(playground config get clipboard)
          if [ "$clipboard" == "" ]
          then
              playground config set clipboard true
          fi

          if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
          then
              tmp_dir_clipboard=$(mktemp -d -t pg-XXXXXXXXXX)
              if [ -z "$PG_VERBOSE_MODE" ]
              then
                  trap 'rm -rf $tmp_dir_clipboard' EXIT
              else
                  log "🐛📂 not deleting tmp dir $tmp_dir_clipboard"
              fi
              echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir_clipboard/tmp
            cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir_clipboard/tmp
            echo "EOF" >> $tmp_dir_clipboard/tmp

            cat $tmp_dir_clipboard/tmp | pbcopy
            log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config set clipboard false')"
        fi
    fi
fi

if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
then
    get_ccloud_connect
    handle_ccloud_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" -H \"authorization: Basic $authorization\" --data @$json_file https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config"
else
    get_connect_url_and_security
    if [[ -n "$skip_automatic_connector_config" ]]
    then
        log "🤖 --skip-automatic-connector-config is set"
    else
        add_connector_config_based_on_environment "$environment" "$json_content"
    fi
    echo "$json_content" > $new_json_file
    handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$new_json_file $connect_url/connectors/$connector/config"
fi

if [[ -n "$level" ]]
then
    if [[ -n "$package" ]]
    then
        playground debug log-level set --level $level --package $package
    else
        playground connector log-level --connector $connector --level $level
    fi
fi
if [ $is_create == 1 ]
then
    log "✅ $connector_type connector $connector was successfully created"
else
    log "✅ $connector_type connector $connector was successfully updated"
fi
if [ -z "$GITHUB_RUN_NUMBER" ]
then
    playground connector show-config --connector "$connector" --no-clipboard
fi

playground connector show-config-parameters --connector "$connector" --only-show-json
log "🥁 Waiting a few seconds to get new status"
sleep 5
set +e
playground connector status --connector $connector
if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
then
    playground connector open-docs --only-show-url
fi
set -e

if [[ -n "$wait_for_zero_lag" ]]
then
    maybe_id=""
    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
        handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
        connectorId=$(get_ccloud_connector_lcc $connector)
        maybe_id=" ($connectorId)"
    else
        handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
    fi

    type=$(echo "$curl_output" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
        logwarn "⏭️ --wait-for-zero-lag is set but $connector_type connector ${connector}${maybe_id} is not a sink"
    fi
    playground connector show-lag --connector $connector
fi
}

# :command.function
playground_connector_update_command() {
  # src/commands/connector/update.sh
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "🛠️ Updating $connector_type connector $connector"
      file=$tmp_dir/config-$connector.sh

      set +e
      echo "#!/bin/bash" > $file
      echo -e "" >> $file
      echo -e "##########################" >> $file
      echo "# this is the part to edit" >> $file
      playground connector show-config --connector "$connector" --no-clipboard | grep -v "Current config for" >> $file
      if [ $? -ne 0 ]
      then
          logerror "❌ playground connector show-config --connector $connector failed with:"
          cat $file
          exit 1
      fi
      set -e
      echo "# end of part to edit" >> $file
      echo -e "##########################" >> $file
      echo -e "" >> $file
      echo "exit 0" >> $file

      echo -e "" >> $file
      docs_links=$(playground state get run.connector_docs_links)
      if [ "$docs_links" != "" ]
      then
          for docs_link in $(echo "${docs_links}" | tr '|' ' ')
          do
              name=$(echo "$docs_link" | cut -d "@" -f 1)
              url=$(echo "$docs_link" | cut -d "@" -f 2)
              echo "🌐⚡ documentation for $connector_type connector $name is available at:" >> $file
              echo "$url" >> $file
          done
      else
          playground connector open-docs --only-show-url | sed -r "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g" >> $file
      fi

      echo -e "" >> $file
      playground connector show-config-parameters --connector $connector  | sed -r "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g" >> $file

      editor=$(playground config get editor)
      if [ "$editor" != "" ]
      then
          log "✨ Update the connector config as per your needs, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
              code --wait $file
          else
              $editor $file
          fi
      else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by using playground config editor <editor>"
              exit 1
          else
              log "✨ Update the connector config as per your needs, save and close the file to continue"
              code --wait $file
          fi
      fi

      bash $file
  done

}

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --version)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        playground_usage
        exit
        ;;

      # :flag.case
      --vvv | -v)

        # :flag.case_no_arg
        args['--vvv']=1
        shift
        ;;

      # :flag.case
      --output-level | -o)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--output-level']="$2"
          shift
          shift
        else
          printf "%s\n" "--output-level requires an argument: --output-level, -o LEVEL" >&2
          exit 1
        fi
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v docker >/dev/null 2>&1; then
    deps['docker']="$(command -v docker | head -n1)"
  else
    printf "missing dependency: docker\n" >&2
    printf "%s\n" "visit https://docs.docker.com/get-docker to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    help)
      action="help"
      shift
      playground_help_parse_requirements "$@"
      shift $#
      ;;

    status)
      action="status"
      shift
      playground_status_parse_requirements "$@"
      shift $#
      ;;

    get-connector-list)
      action="get-connector-list"
      shift
      playground_get_connector_list_parse_requirements "$@"
      shift $#
      ;;

    generate-fzf-find-files)
      action="generate-fzf-find-files"
      shift
      playground_generate_fzf_find_files_parse_requirements "$@"
      shift $#
      ;;

    generate-tag-list)
      action="generate-tag-list"
      shift
      playground_generate_tag_list_parse_requirements "$@"
      shift $#
      ;;

    generate-connector-plugin-list)
      action="generate-connector-plugin-list"
      shift
      playground_generate_connector_plugin_list_parse_requirements "$@"
      shift $#
      ;;

    generate-kafka-region-list)
      action="generate-kafka-region-list"
      shift
      playground_generate_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-connector-plugin)
      action="get-connector-plugin"
      shift
      playground_get_connector_plugin_parse_requirements "$@"
      shift $#
      ;;

    get-ccloud-environment-list)
      action="get-ccloud-environment-list"
      shift
      playground_get_ccloud_environment_list_parse_requirements "$@"
      shift $#
      ;;

    get-ccloud-cluster-list)
      action="get-ccloud-cluster-list"
      shift
      playground_get_ccloud_cluster_list_parse_requirements "$@"
      shift $#
      ;;

    get-tag-list)
      action="get-tag-list"
      shift
      playground_get_tag_list_parse_requirements "$@"
      shift $#
      ;;

    get-kafka-region-list)
      action="get-kafka-region-list"
      shift
      playground_get_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-topic-list)
      action="get-topic-list"
      shift
      playground_get_topic_list_parse_requirements "$@"
      shift $#
      ;;

    get-subject-list)
      action="get-subject-list"
      shift
      playground_get_subject_list_parse_requirements "$@"
      shift $#
      ;;

    get-examples-list-with-fzf)
      action="get-examples-list-with-fzf"
      shift
      playground_get_examples_list_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-zip-or-jar-with-fzf)
      action="get-zip-or-jar-with-fzf"
      shift
      playground_get_zip_or_jar_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-any-file-with-fzf)
      action="get-any-file-with-fzf"
      shift
      playground_get_any_file_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-playground-repro-export-with-fzf)
      action="get-playground-repro-export-with-fzf"
      shift
      playground_get_playground_repro_export_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-predefined-schemas)
      action="get-predefined-schemas"
      shift
      playground_get_predefined_schemas_parse_requirements "$@"
      shift $#
      ;;

    update-readme)
      action="update-readme"
      shift
      playground_update_readme_parse_requirements "$@"
      shift $#
      ;;

    bashly-reload)
      action="bashly-reload"
      shift
      playground_bashly_reload_parse_requirements "$@"
      shift $#
      ;;

    state)
      action="state"
      shift
      playground_state_parse_requirements "$@"
      shift $#
      ;;

    config)
      action="config"
      shift
      playground_config_parse_requirements "$@"
      shift $#
      ;;

    run)
      action="run"
      shift
      playground_run_parse_requirements "$@"
      shift $#
      ;;

    re-run)
      action="re-run"
      shift
      playground_re_run_parse_requirements "$@"
      shift $#
      ;;

    history)
      action="history"
      shift
      playground_history_parse_requirements "$@"
      shift $#
      ;;

    start-environment)
      action="start-environment"
      shift
      playground_start_environment_parse_requirements "$@"
      shift $#
      ;;

    switch-ccloud)
      action="switch-ccloud"
      shift
      playground_switch_ccloud_parse_requirements "$@"
      shift $#
      ;;

    switch-back)
      action="switch-back"
      shift
      playground_switch_back_parse_requirements "$@"
      shift $#
      ;;

    update-version)
      action="update-version"
      shift
      playground_update_version_parse_requirements "$@"
      shift $#
      ;;

    open)
      action="open"
      shift
      playground_open_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_stop_parse_requirements "$@"
      shift $#
      ;;

    remove-all-docker-images)
      action="remove-all-docker-images"
      shift
      playground_remove_all_docker_images_parse_requirements "$@"
      shift $#
      ;;

    open-docs)
      action="open-docs"
      shift
      playground_open_docs_parse_requirements "$@"
      shift $#
      ;;

    cleanup-cloud-resources)
      action="cleanup-cloud-resources"
      shift
      playground_cleanup_cloud_resources_parse_requirements "$@"
      shift $#
      ;;

    repro)
      action="repro"
      shift
      playground_repro_parse_requirements "$@"
      shift $#
      ;;

    get-docker-compose)
      action="get-docker-compose"
      shift
      playground_get_docker_compose_parse_requirements "$@"
      shift $#
      ;;

    schema)
      action="schema"
      shift
      playground_schema_parse_requirements "$@"
      shift $#
      ;;

    debug)
      action="debug"
      shift
      playground_debug_parse_requirements "$@"
      shift $#
      ;;

    get-jmx-metrics)
      action="get-jmx-metrics"
      shift
      playground_get_jmx_metrics_parse_requirements "$@"
      shift $#
      ;;

    container)
      action="container"
      shift
      playground_container_parse_requirements "$@"
      shift $#
      ;;

    topic)
      action="topic"
      shift
      playground_topic_parse_requirements "$@"
      shift $#
      ;;

    connector-plugin)
      action="connector-plugin"
      shift
      playground_connector_plugin_parse_requirements "$@"
      shift $#
      ;;

    connector)
      action="connector"
      shift
      playground_connector_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--output-level']:-} ]] && [[ ! ${args['--output-level']:-} =~ ^(INFO|WARN|ERROR)$ ]]; then
    printf "%s\n" "--output-level must be one of: INFO, WARN, ERROR" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_docker_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_help_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_help_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="help"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['command']+x} ]]; then
          args['command']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_fzf_find_files_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_generate_fzf_find_files_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-fzf-find-files"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_tag_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_generate_tag_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-tag-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_connector_plugin_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_generate_connector_plugin_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-connector-plugin-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_generate_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="generate-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_plugin_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_connector_plugin_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-plugin"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ccloud_environment_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_ccloud_environment_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ccloud-environment-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ccloud_cluster_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_ccloud_cluster_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ccloud-cluster-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_tag_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_tag_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-tag-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-topic-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --skip-connect-internal-topics)

        # :flag.case_no_arg
        args['--skip-connect-internal-topics']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_subject_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_subject_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-subject-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --deleted)

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_examples_list_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-examples-list-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --without-repro)

        # :flag.case_no_arg
        args['--without-repro']=1
        shift
        ;;

      # :flag.case
      --sink-only)

        # :flag.case_no_arg
        args['--sink-only']=1
        shift
        ;;

      # :flag.case
      --ccloud-only)

        # :flag.case_no_arg
        args['--ccloud-only']=1
        shift
        ;;

      # :flag.case
      --connector-only)

        # :flag.case_no_arg
        args['--connector-only']=1
        shift
        ;;

      # :flag.case
      --repro-only)

        # :flag.case_no_arg
        args['--repro-only']=1
        shift
        ;;

      # :flag.case
      --environment-only)

        # :flag.case_no_arg
        args['--environment-only']=1
        shift
        ;;

      # :flag.case
      --fully-managed-connector-only)

        # :flag.case_no_arg
        args['--fully-managed-connector-only']=1
        shift
        ;;

      # :flag.case
      --ksql-only)

        # :flag.case_no_arg
        args['--ksql-only']=1
        shift
        ;;

      # :flag.case
      --schema-registry-only)

        # :flag.case_no_arg
        args['--schema-registry-only']=1
        shift
        ;;

      # :flag.case
      --rest-proxy-only)

        # :flag.case_no_arg
        args['--rest-proxy-only']=1
        shift
        ;;

      # :flag.case
      --other-playgrounds-only)

        # :flag.case_no_arg
        args['--other-playgrounds-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_zip_or_jar_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_zip_or_jar_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-zip-or-jar-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--type']="$2"
          shift
          shift
        else
          printf "%s\n" "--type requires an argument: --type TYPE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--type']:-} ]] && [[ ! ${args['--type']:-} =~ ^(zip|jar)$ ]]; then
    printf "%s\n" "--type must be one of: zip, jar" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_any_file_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_any_file_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-any-file-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_playground_repro_export_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_playground_repro_export_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-playground-repro-export-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_predefined_schemas_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_predefined_schemas_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-predefined-schemas"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_readme_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_update_readme_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  env_var_names+=("GH_TOKEN")

  # :command.command_filter
  action="update-readme"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tags)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tags']="$2"
          shift
          shift
        else
          printf "%s\n" "--tags requires an argument: --tags TAGS" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--tags'] && -n $(validate_not_empty "${args['--tags']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--tags TAGS" "$(validate_not_empty "${args['--tags']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_bashly_reload_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_bashly_reload_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v bashly >/dev/null 2>&1; then
    deps['bashly']="$(command -v bashly | head -n1)"
  else
    printf "missing dependency: bashly\n" >&2
    printf "%s\n" "visit https://bashly.dannyb.co/installation/ to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="bashly-reload"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_state_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    show)
      action="show"
      shift
      playground_state_show_parse_requirements "$@"
      shift $#
      ;;

    get)
      action="get"
      shift
      playground_state_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_state_set_parse_requirements "$@"
      shift $#
      ;;

    del)
      action="del"
      shift
      playground_state_del_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_state_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_show_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_state_show_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state show"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_state_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state get KEY\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_state_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_state_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        # :argument.case
        elif [[ -z ${args['value']+x} ]]; then
          args['value']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state set KEY VALUE\n" >&2
    exit 1
  fi
  if [[ -z ${args['value']+x} ]]; then
    printf "missing required argument: VALUE\nusage: playground state set KEY VALUE\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_state_del_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_state_del_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state del"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state del KEY\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    show)
      action="show"
      shift
      playground_config_show_parse_requirements "$@"
      shift $#
      ;;

    get)
      action="get"
      shift
      playground_config_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_config_set_parse_requirements "$@"
      shift $#
      ;;

    editor)
      action="editor"
      shift
      playground_config_editor_parse_requirements "$@"
      shift $#
      ;;

    folder_zip_or_jar)
      action="folder_zip_or_jar"
      shift
      playground_config_folder_zip_or_jar_parse_requirements "$@"
      shift $#
      ;;

    clipboard)
      action="clipboard"
      shift
      playground_config_clipboard_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_config_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_show_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_show_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config show"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground config get KEY\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_config_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        # :argument.case
        elif [[ -z ${args['value']+x} ]]; then
          args['value']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground config set KEY VALUE\n" >&2
    exit 1
  fi
  if [[ -z ${args['value']+x} ]]; then
    printf "missing required argument: VALUE\nusage: playground config set KEY VALUE\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_config_editor_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_editor_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config editor"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['editor']+x} ]]; then
          args['editor']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['editor']+x} ]]; then
    printf "missing required argument: EDITOR\nusage: playground config editor EDITOR\n" >&2
    exit 1
  fi

  # :command.validations
  # :argument.validations
  if [[ -v args['editor'] && -n $(validate_editor_exists "${args['editor']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "EDITOR" "$(validate_editor_exists "${args['editor']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_config_folder_zip_or_jar_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_folder_zip_or_jar_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config folder_zip_or_jar"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_repeatable
        # :argument.case_repeatable
        escaped="$(printf '%q' "$1")"
        if [[ -z ${args['folder']+x} ]]; then
          args['folder']="$escaped"
          unique_lookup["folder:$escaped"]=1
        elif [[ -z "${unique_lookup["folder:$escaped"]:-}" ]]; then
          args['folder']="${args['folder']} $escaped"
          unique_lookup["folder:$escaped"]=1

        fi
        shift

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['folder']+x} ]]; then
    printf "missing required argument: FOLDER\nusage: playground config folder_zip_or_jar FOLDER...\n" >&2
    exit 1
  fi

  # :command.validations
  # :argument.validations
  if [[ -v args['folder'] ]]; then
    eval "values=(${args['folder']})"
    for value in "${values[@]}"; do
      if [[ -n $(validate_dir_exists "$value") ]]; then
        printf "validation error in %s:\n%s\n" "FOLDER" "$(validate_dir_exists "$value")" >&2
        exit 1
      fi
    done
  fi

}

# :command.parse_requirements
playground_config_clipboard_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_config_clipboard_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config clipboard"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['enabled']+x} ]]; then
          args['enabled']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['enabled']:-} ]] || args['enabled']="true"

}

# :command.parse_requirements
playground_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--environment requires an argument: --environment ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-rest-proxy)

        # :flag.case_no_arg
        args['--enable-rest-proxy']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      # :flag.case
      --cluster-cloud)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-cloud']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-cloud requires an argument: --cluster-cloud CLUSTER-CLOUD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-type requires an argument: --cluster-type CLUSTER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --force-interactive-re-run)

        # :flag.case_no_arg
        args['--force-interactive-re-run']=1
        shift
        ;;

      # :flag.case
      --force-interactive-repro)

        # :flag.case_no_arg
        args['--force-interactive-repro']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--environment']:-} ]] || args['--environment']="plaintext"

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] && -n $(validate_file_exists_with_trick "${args['--file']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "${args['--file']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--connector-zip'] && -n $(validate_file_exists_with_trick "${args['--connector-zip']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "${args['--connector-zip']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--connector-jar'] && -n $(validate_file_exists_with_trick "${args['--connector-jar']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "${args['--connector-jar']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--cluster-environment'] && -n $(validate_not_empty "${args['--cluster-environment']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$(validate_not_empty "${args['--cluster-environment']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--cluster-name'] && -n $(validate_not_empty "${args['--cluster-name']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$(validate_not_empty "${args['--cluster-name']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--cluster-creds'] && -n $(validate_not_empty "${args['--cluster-creds']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$(validate_not_empty "${args['--cluster-creds']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--cluster-schema-registry-creds'] && -n $(validate_not_empty "${args['--cluster-schema-registry-creds']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$(validate_not_empty "${args['--cluster-schema-registry-creds']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--environment']:-} ]] && [[ ! ${args['--environment']:-} =~ ^(ccloud|plaintext|sasl-ssl|sasl-plain|2way-ssl|sasl-scram|kraft-external-plaintext|kraft-plaintext|kerberos|ssl_kerberos|ldap-authorizer-sasl-plain|ldap-sasl-plain|rbac-sasl-plain)$ ]]; then
    printf "%s\n" "--environment must be one of: ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kraft-external-plaintext, kraft-plaintext, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain" >&2
    exit 1
  fi
  if [[ ${args['--cluster-cloud']:-} ]] && [[ ! ${args['--cluster-cloud']:-} =~ ^(aws|gcp|azure)$ ]]; then
    printf "%s\n" "--cluster-cloud must be one of: aws, gcp, azure" >&2
    exit 1
  fi
  if [[ ${args['--cluster-type']:-} ]] && [[ ! ${args['--cluster-type']:-} =~ ^(basic|standard|dedicated)$ ]]; then
    printf "%s\n" "--cluster-type must be one of: basic, standard, dedicated" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_re_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_re_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="re-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_history_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_history_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="history"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_start_environment_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_start_environment_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="start-environment"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--environment requires an argument: --environment ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-control-center)

        # :flag.case_no_arg
        args['--wait-for-control-center']=1
        shift
        ;;

      # :flag.case
      --docker-compose-override-file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--docker-compose-override-file']="$2"
          shift
          shift
        else
          printf "%s\n" "--docker-compose-override-file requires an argument: --docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--environment']:-} ]] || args['--environment']="plaintext"

  # :command.validations
  # :flag.validations
  if [[ -v args['--docker-compose-override-file'] && -n $(validate_file_exists "${args['--docker-compose-override-file']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE" "$(validate_file_exists "${args['--docker-compose-override-file']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--environment']:-} ]] && [[ ! ${args['--environment']:-} =~ ^(ccloud|2way-ssl|kerberos|kraft-external-plaintext|kraft-plaintext|ldap-authorizer-sasl-plain|ldap-sasl-plain|mdc-kerberos|mdc-plaintext|mdc-sasl-plain|plaintext|rbac-sasl-plain|sasl-plain|sasl-scram|sasl-ssl|ssl_kerberos)$ ]]; then
    printf "%s\n" "--environment must be one of: ccloud, 2way-ssl, kerberos, kraft-external-plaintext, kraft-plaintext, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_switch_ccloud_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_switch_ccloud_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="switch-ccloud"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_switch_back_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_switch_back_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="switch-back"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_version_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_update_version_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="update-version"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connector-zip'] && -n $(validate_file_exists_with_trick "${args['--connector-zip']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "${args['--connector-zip']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--connector-jar'] && -n $(validate_file_exists_with_trick "${args['--connector-jar']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "${args['--connector-jar']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_open_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_open_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="open"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] && -n $(validate_file_exists_with_trick "${args['--file']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "${args['--file']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_remove_all_docker_images_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_remove_all_docker_images_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="remove-all-docker-images"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_open_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_open_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="open-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_cleanup_cloud_resources_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_cleanup_cloud_resources_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  env_var_names+=("AZ_USER")
  env_var_names+=("AZ_PASS")
  env_var_names+=("GCP_PROJECT")
  env_var_names+=("AWS_ACCESS_KEY_ID")
  env_var_names+=("AWS_SECRET_ACCESS_KEY")
  env_var_names+=("GCP_KEYFILE_CONTENT")

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="cleanup-cloud-resources"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --force)

        # :flag.case_no_arg
        args['--force']=1
        shift
        ;;

      # :flag.case
      --user)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--user']="$2"
          shift
          shift
        else
          printf "%s\n" "--user requires an argument: --user USER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --resource)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--resource']+x} ]]; then
            args['--resource']="$escaped"
          elif [[ -z "${unique_lookup["--resource:${escaped}"]:-}" ]]; then
            args['--resource']="${args['--resource']} $escaped"
          fi
          unique_lookup["--resource:${escaped}"]=1
          shift
          shift
        else
          printf "%s\n" "--resource requires an argument: --resource RESOURCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--resource']:-} ]] || args['--resource']="aws gcp azure ccloud salesforce"

  # :command.whitelist_filter
  eval "input_array=(${args[--resource]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(aws|gcp|azure|ccloud|salesforce)$ ]]; then
      printf "%s\n" "--resource must be one of: aws, gcp, azure, ccloud, salesforce" >&2
      exit 1
    fi
  done

}

# :command.parse_requirements
playground_repro_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export OUTPUT_FOLDER="${OUTPUT_FOLDER:-reproduction-models}"

  env_var_names+=("OUTPUT_FOLDER")

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    export)
      action="export"
      shift
      playground_repro_export_parse_requirements "$@"
      shift $#
      ;;

    import)
      action="import"
      shift
      playground_repro_import_parse_requirements "$@"
      shift $#
      ;;

    bootstrap)
      action="bootstrap"
      shift
      playground_repro_bootstrap_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_repro_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_export_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_export_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v git >/dev/null 2>&1; then
    deps['git']="$(command -v git | head -n1)"
  else
    printf "missing dependency: git\n" >&2
    printf "%s\n" "visit https://git-scm.com/downloads to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="repro export"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_import_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_import_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro import"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] && -n $(validate_file_exists_with_trick "${args['--file']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "${args['--file']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_repro_bootstrap_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_bootstrap_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro bootstrap"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --description | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--description']="$2"
          shift
          shift
        else
          printf "%s\n" "--description requires an argument: --description, -d DESCRIPTION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer | -p)
        # :flag.conflicts
        if [[ -n "${args['--pipeline']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--pipeline" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--producer']="$2"
          shift
          shift
        else
          printf "%s\n" "--producer requires an argument: --producer, -p PRODUCER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-producers | -n)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-producers']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-producers requires an argument: --nb-producers, -n NB-PRODUCERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-schema-key)

        # :flag.case_no_arg
        args['--producer-schema-key']=1
        shift
        ;;

      # :flag.case
      --producer-schema-value)

        # :flag.case_no_arg
        args['--producer-schema-value']=1
        shift
        ;;

      # :flag.case
      --custom-smt)

        # :flag.case_no_arg
        args['--custom-smt']=1
        shift
        ;;

      # :flag.case
      --pipeline)
        # :flag.conflicts
        if [[ -n "${args['--producer']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--producer" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--pipeline']+x} ]]; then
            args['--pipeline']="$escaped"
          else
            args['--pipeline']="${args['--pipeline']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--pipeline requires an argument: --pipeline SINK_FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--producer']:-} ]] || args['--producer']="none"

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] && -n $(validate_file_exists_with_trick "${args['--file']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "${args['--file']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--description'] && -n $(validate_not_empty "${args['--description']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--description, -d DESCRIPTION" "$(validate_not_empty "${args['--description']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--pipeline'] ]]; then
    eval "values=(${args['--pipeline']})"
    for value in "${values[@]}"; do
      if [[ -n $(validate_file_exists_with_trick "$value") ]]; then
        printf "validation error in %s:\n%s\n" "--pipeline SINK_FILE" "$(validate_file_exists_with_trick "$value")" >&2
        exit 1
      fi
    done
  fi

  # :command.whitelist_filter
  if [[ ${args['--producer']:-} ]] && [[ ! ${args['--producer']:-} =~ ^(none|avro|avro-with-key|protobuf|protobuf-with-key|json-schema|json-schema-with-key)$ ]]; then
    printf "%s\n" "--producer must be one of: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_docker_compose_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_docker_compose_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-docker-compose"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_schema_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_schema_get_parse_requirements "$@"
      shift $#
      ;;

    register)
      action="register"
      shift
      playground_schema_register_parse_requirements "$@"
      shift $#
      ;;

    get-compatibility)
      action="get-compatibility"
      shift
      playground_schema_get_compatibility_parse_requirements "$@"
      shift $#
      ;;

    set-compatibility)
      action="set-compatibility"
      shift
      playground_schema_set_compatibility_parse_requirements "$@"
      shift $#
      ;;

    get-mode)
      action="get-mode"
      shift
      playground_schema_get_mode_parse_requirements "$@"
      shift $#
      ;;

    set-mode)
      action="set-mode"
      shift
      playground_schema_set_mode_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_schema_delete_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_schema_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_schema_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)
        # :flag.conflicts
        if [[ -n "${args['id']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "id" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --id)
        # :flag.conflicts
        for conflict in subject deleted; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--id']="$2"
          shift
          shift
        else
          printf "%s\n" "--id requires an argument: --id ID" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --deleted)
        # :flag.conflicts
        if [[ -n "${args['id']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "id" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--id'] && -n $(validate_integer "${args['--id']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--id ID" "$(validate_integer "${args['--id']:-}")" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_register_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_register_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema register"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --schema)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--schema']="$2"
          shift
          shift
        else
          printf "%s\n" "--schema requires an argument: --schema SCHEMA" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--id']="$2"
          shift
          shift
        else
          printf "%s\n" "--id requires an argument: --id ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--schema']:-} ]] || args['--schema']="-"

  # :command.validations
  # :flag.validations
  if [[ -v args['--id'] && -n $(validate_integer "${args['--id']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--id ID" "$(validate_integer "${args['--id']:-}")" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_set_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_set_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --mode)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--mode']="$2"
          shift
          shift
        else
          printf "%s\n" "--mode requires an argument: --mode MODE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--mode']+x} ]]; then
    printf "missing required flag: --mode MODE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--mode']:-} ]] && [[ ! ${args['--mode']:-} =~ ^(IMPORT|READONLY|READWRITE)$ ]]; then
    printf "%s\n" "--mode must be one of: IMPORT, READONLY, READWRITE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --version)
        # :flag.conflicts
        if [[ -n "${args['--id']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--id" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --id)
        # :flag.conflicts
        if [[ -n "${args['--version']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--version" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--id']="$2"
          shift
          shift
        else
          printf "%s\n" "--id requires an argument: --id ID" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --permanent)

        # :flag.case_no_arg
        args['--permanent']=1
        shift
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--version'] && -n $(validate_integer "${args['--version']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--version VERSION" "$(validate_integer "${args['--version']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--id'] && -n $(validate_integer "${args['--id']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--id ID" "$(validate_integer "${args['--id']:-}")" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    install-vscode-extension)
      action="install-vscode-extension"
      shift
      playground_debug_install_vscode_extension_parse_requirements "$@"
      shift $#
      ;;

    enable-remote-debugging)
      action="enable-remote-debugging"
      shift
      playground_debug_enable_remote_debugging_parse_requirements "$@"
      shift $#
      ;;

    testssl)
      action="testssl"
      shift
      playground_debug_testssl_parse_requirements "$@"
      shift $#
      ;;

    generate-diagnostics)
      action="generate-diagnostics"
      shift
      playground_debug_generate_diagnostics_parse_requirements "$@"
      shift $#
      ;;

    thread-dump)
      action="thread-dump"
      shift
      playground_debug_thread_dump_parse_requirements "$@"
      shift $#
      ;;

    heap-dump)
      action="heap-dump"
      shift
      playground_debug_heap_dump_parse_requirements "$@"
      shift $#
      ;;

    tcp-dump)
      action="tcp-dump"
      shift
      playground_debug_tcp_dump_parse_requirements "$@"
      shift $#
      ;;

    block-traffic)
      action="block-traffic"
      shift
      playground_debug_block_traffic_parse_requirements "$@"
      shift $#
      ;;

    flight-recorder)
      action="flight-recorder"
      shift
      playground_debug_flight_recorder_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_debug_log_level_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_install_vscode_extension_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_install_vscode_extension_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v code >/dev/null 2>&1; then
    deps['code']="$(command -v code | head -n1)"
  else
    printf "missing dependency: code\n" >&2
    printf "%s\n" "visit https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="debug install-vscode-extension"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_enable_remote_debugging_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_enable_remote_debugging_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug enable-remote-debugging"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_testssl_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_testssl_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug testssl"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['arguments']+x} ]]; then
          args['arguments']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_generate_diagnostics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_generate_diagnostics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug generate-diagnostics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_thread_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_thread_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug thread-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_heap_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_heap_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug heap-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_tcp_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_tcp_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug tcp-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --duration)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--duration']="$2"
          shift
          shift
        else
          printf "%s\n" "--duration requires an argument: --duration DURATION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--duration']:-} ]] || args['--duration']="30"

  # :command.validations
  # :flag.validations
  if [[ -v args['--port'] && -n $(validate_integer "${args['--port']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--port PORT" "$(validate_integer "${args['--port']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--duration'] && -n $(validate_integer "${args['--duration']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--duration DURATION" "$(validate_integer "${args['--duration']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_block_traffic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_block_traffic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug block-traffic"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --destination)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--destination']="$2"
          shift
          shift
        else
          printf "%s\n" "--destination requires an argument: --destination DESTINATION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--destination']+x} ]]; then
    printf "missing required flag: --destination DESTINATION\n" >&2
    exit 1
  fi
  if [[ -z ${args['--action']+x} ]]; then
    printf "missing required flag: --action ACTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.validations
  # :flag.validations
  if [[ -v args['--port'] && -n $(validate_integer "${args['--port']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--port PORT" "$(validate_integer "${args['--port']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(start|stop)$ ]]; then
    printf "%s\n" "--action must be one of: start, stop" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_flight_recorder_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_flight_recorder_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug flight-recorder"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--action']+x} ]]; then
    printf "missing required flag: --action ACTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.whitelist_filter
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(start|stop)$ ]]; then
    printf "%s\n" "--action must be one of: start, stop" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_debug_log_level_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_debug_log_level_set_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_log_level_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] && -n $(validate_not_empty "${args['--package']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "${args['--package']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--package']+x} ]]; then
    printf "missing required flag: --package, -p PACKAGE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] && -n $(validate_not_empty "${args['--package']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "${args['--package']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_jmx_metrics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_jmx_metrics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v java >/dev/null 2>&1; then
    deps['java']="$(command -v java | head -n1)"
  else
    printf "missing dependency: java\n" >&2
    printf "%s\n" "visit https://openjdk.org/install/ to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-jmx-metrics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --domain | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--domain']="$2"
          shift
          shift
        else
          printf "%s\n" "--domain requires an argument: --domain, -d DOMAIN" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-properties)
      action="get-properties"
      shift
      playground_container_get_properties_parse_requirements "$@"
      shift $#
      ;;

    recreate)
      action="recreate"
      shift
      playground_container_recreate_parse_requirements "$@"
      shift $#
      ;;

    get-ip-addresses)
      action="get-ip-addresses"
      shift
      playground_container_get_ip_addresses_parse_requirements "$@"
      shift $#
      ;;

    kill-all)
      action="kill-all"
      shift
      playground_container_kill_all_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_container_logs_parse_requirements "$@"
      shift $#
      ;;

    ssh)
      action="ssh"
      shift
      playground_container_ssh_parse_requirements "$@"
      shift $#
      ;;

    exec)
      action="exec"
      shift
      playground_container_exec_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_container_restart_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_container_pause_parse_requirements "$@"
      shift $#
      ;;

    resume | unpause)
      action="resume"
      shift
      playground_container_resume_parse_requirements "$@"
      shift $#
      ;;

    kill)
      action="kill"
      shift
      playground_container_kill_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_container_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_properties_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_get_properties_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-properties"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_recreate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_recreate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container recreate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --ignore-current-versions)

        # :flag.case_no_arg
        args['--ignore-current-versions']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_ip_addresses_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_get_ip_addresses_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-ip-addresses"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_kill_all_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_all_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill-all"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

  # :command.validations
  # :flag.validations
  if [[ -v args['--wait-for-log'] && -n $(validate_not_empty "${args['--wait-for-log']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$(validate_not_empty "${args['--wait-for-log']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--max-wait'] && -n $(validate_integer "${args['--max-wait']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$(validate_integer "${args['--max-wait']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_ssh_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_ssh_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container ssh"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --shell | -s)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell, -s SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']:-} ]] && [[ ! ${args['--shell']:-} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_exec_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_exec_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container exec"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --command)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--command']="$2"
          shift
          shift
        else
          printf "%s\n" "--command requires an argument: --command COMMAND" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --root)

        # :flag.case_no_arg
        args['--root']=1
        shift
        ;;

      # :flag.case
      --shell)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--command']+x} ]]; then
    printf "missing required flag: --command COMMAND\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.validations
  # :flag.validations
  if [[ -v args['--command'] && -n $(validate_not_empty "${args['--command']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--command COMMAND" "$(validate_not_empty "${args['--command']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--shell']:-} ]] && [[ ! ${args['--shell']:-} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_kill_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_topic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-number-records)
      action="get-number-records"
      shift
      playground_topic_get_number_records_parse_requirements "$@"
      shift $#
      ;;

    display-consumer-offsets)
      action="display-consumer-offsets"
      shift
      playground_topic_display_consumer_offsets_parse_requirements "$@"
      shift $#
      ;;

    list)
      action="list"
      shift
      playground_topic_list_parse_requirements "$@"
      shift $#
      ;;

    describe)
      action="describe"
      shift
      playground_topic_describe_parse_requirements "$@"
      shift $#
      ;;

    set-schema-compatibility)
      action="set-schema-compatibility"
      shift
      playground_topic_set_schema_compatibility_parse_requirements "$@"
      shift $#
      ;;

    consume)
      action="consume"
      shift
      playground_topic_consume_parse_requirements "$@"
      shift $#
      ;;

    produce)
      action="produce"
      shift
      playground_topic_produce_parse_requirements "$@"
      shift $#
      ;;

    create)
      action="create"
      shift
      playground_topic_create_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_topic_delete_parse_requirements "$@"
      shift $#
      ;;

    alter)
      action="alter"
      shift
      playground_topic_alter_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_topic_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_get_number_records_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_get_number_records_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic get-number-records"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_display_consumer_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic display-consumer-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_describe_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_describe_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic describe"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_set_schema_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_set_schema_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic set-schema-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_consume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_consume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic consume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-messages requires an argument: --max-messages MAX-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --min-expected-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--min-expected-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--min-expected-messages requires an argument: --min-expected-messages MIN-EXPECTED-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --grep)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--grep']="$2"
          shift
          shift
        else
          printf "%s\n" "--grep requires an argument: --grep GREP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --timeout)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--timeout']="$2"
          shift
          shift
        else
          printf "%s\n" "--timeout requires an argument: --timeout TIMEOUT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --tail)
        # :flag.conflicts
        for conflict in --min-expected-messages --max-messages; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_no_arg
        args['--tail']=1
        shift
        ;;

      # :flag.case
      --plot-latencies-timestamp-field)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--plot-latencies-timestamp-field']="$2"
          shift
          shift
        else
          printf "%s\n" "--plot-latencies-timestamp-field requires an argument: --plot-latencies-timestamp-field TIMESTAMP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --key-subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key-subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--key-subject requires an argument: --key-subject KEY-SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-subject requires an argument: --value-subject VALUE-SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-characters)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-characters']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-characters requires an argument: --max-characters MAX-CHARACTERS" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-messages']:-} ]] || args['--max-messages']="10"
  [[ -n ${args['--min-expected-messages']:-} ]] || args['--min-expected-messages']="0"
  [[ -n ${args['--grep']:-} ]] || args['--grep']=""
  [[ -n ${args['--timeout']:-} ]] || args['--timeout']="60"
  [[ -n ${args['--max-characters']:-} ]] || args['--max-characters']="2500"

  # :command.validations
  # :flag.validations
  if [[ -v args['--max-messages'] && -n $(validate_integer "${args['--max-messages']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--max-messages MAX-MESSAGES" "$(validate_integer "${args['--max-messages']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--min-expected-messages'] && -n $(validate_integer "${args['--min-expected-messages']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--min-expected-messages MIN-EXPECTED-MESSAGES" "$(validate_integer "${args['--min-expected-messages']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--timeout'] && -n $(validate_integer "${args['--timeout']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--timeout TIMEOUT" "$(validate_integer "${args['--timeout']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--max-characters'] && -n $(validate_integer "${args['--max-characters']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--max-characters MAX-CHARACTERS" "$(validate_integer "${args['--max-characters']:-}")" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_produce_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_produce_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic produce"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --key)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key']="$2"
          shift
          shift
        else
          printf "%s\n" "--key requires an argument: --key KEY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value']="$2"
          shift
          shift
        else
          printf "%s\n" "--value requires an argument: --value VALUE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --debug | -d)

        # :flag.case_no_arg
        args['--debug']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-messages requires an argument: --nb-messages NB-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-nb-messages-per-batch)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-nb-messages-per-batch']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-nb-messages-per-batch requires an argument: --max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --sleep-time-between-batch)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--sleep-time-between-batch']="$2"
          shift
          shift
        else
          printf "%s\n" "--sleep-time-between-batch requires an argument: --sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compression-codec)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compression-codec']="$2"
          shift
          shift
        else
          printf "%s\n" "--compression-codec requires an argument: --compression-codec COMPRESSION-CODEC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --key-subject-name-strategy)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key-subject-name-strategy']="$2"
          shift
          shift
        else
          printf "%s\n" "--key-subject-name-strategy requires an argument: --key-subject-name-strategy KEY-SUBJECT-NAME-STRATEGY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-subject-name-strategy)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-subject-name-strategy']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-subject-name-strategy requires an argument: --value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --headers)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--headers']="$2"
          shift
          shift
        else
          printf "%s\n" "--headers requires an argument: --headers HEADERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --forced-key)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--forced-key']="$2"
          shift
          shift
        else
          printf "%s\n" "--forced-key requires an argument: --forced-key FORCED-KEY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --forced-value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--forced-value']="$2"
          shift
          shift
        else
          printf "%s\n" "--forced-value requires an argument: --forced-value FORCED-VALUE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --generate-only)

        # :flag.case_no_arg
        args['--generate-only']=1
        shift
        ;;

      # :flag.case
      --tombstone)

        # :flag.case_no_arg
        args['--tombstone']=1
        shift
        ;;

      # :flag.case
      --validate)

        # :flag.case_no_arg
        args['--validate']=1
        shift
        ;;

      # :flag.case
      --no-null)

        # :flag.case_no_arg
        args['--no-null']=1
        shift
        ;;

      # :flag.case
      --reference)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--reference']+x} ]]; then
            args['--reference']="$escaped"
          else
            args['--reference']="${args['--reference']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--reference requires an argument: --reference REFERENCE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --validate-config)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--validate-config']+x} ]]; then
            args['--validate-config']="$escaped"
          else
            args['--validate-config']="${args['--validate-config']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--validate-config requires an argument: --validate-config VALIDATE-CONFIG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-property)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--producer-property']+x} ]]; then
            args['--producer-property']="$escaped"
          else
            args['--producer-property']="${args['--producer-property']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--producer-property requires an argument: --producer-property PRODUCER-PROPERTY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --record-size)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--record-size']="$2"
          shift
          shift
        else
          printf "%s\n" "--record-size requires an argument: --record-size RECORD-SIZE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-schema-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-schema-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-schema-id requires an argument: --value-schema-id VALUE-SCHEMA-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--value']:-} ]] || args['--value']="-"
  [[ -n ${args['--nb-messages']:-} ]] || args['--nb-messages']="1"
  [[ -n ${args['--max-nb-messages-per-batch']:-} ]] || args['--max-nb-messages-per-batch']="300000"
  [[ -n ${args['--sleep-time-between-batch']:-} ]] || args['--sleep-time-between-batch']="0"
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']="1"
  [[ -n ${args['--record-size']:-} ]] || args['--record-size']="0"

  # :command.validations
  # :flag.validations
  if [[ -v args['--nb-messages'] && -n $(validate_integer "${args['--nb-messages']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--nb-messages NB-MESSAGES" "$(validate_integer "${args['--nb-messages']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--max-nb-messages-per-batch'] && -n $(validate_integer "${args['--max-nb-messages-per-batch']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH" "$(validate_integer "${args['--max-nb-messages-per-batch']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--sleep-time-between-batch'] && -n $(validate_integer "${args['--sleep-time-between-batch']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH" "$(validate_integer "${args['--sleep-time-between-batch']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--nb-partitions'] && -n $(validate_integer "${args['--nb-partitions']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$(validate_integer "${args['--nb-partitions']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--record-size'] && -n $(validate_integer "${args['--record-size']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--record-size RECORD-SIZE" "$(validate_integer "${args['--record-size']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--value-schema-id'] && -n $(validate_integer "${args['--value-schema-id']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--value-schema-id VALUE-SCHEMA-ID" "$(validate_integer "${args['--value-schema-id']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compression-codec']:-} ]] && [[ ! ${args['--compression-codec']:-} =~ ^(gzip|snappy|lz4|zstd)$ ]]; then
    printf "%s\n" "--compression-codec must be one of: gzip, snappy, lz4, zstd" >&2
    exit 1
  fi
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi
  if [[ ${args['--key-subject-name-strategy']:-} ]] && [[ ! ${args['--key-subject-name-strategy']:-} =~ ^(TopicNameStrategy|RecordNameStrategy|TopicRecordNameStrategy)$ ]]; then
    printf "%s\n" "--key-subject-name-strategy must be one of: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy" >&2
    exit 1
  fi
  if [[ ${args['--value-subject-name-strategy']:-} ]] && [[ ! ${args['--value-subject-name-strategy']:-} =~ ^(TopicNameStrategy|RecordNameStrategy|TopicRecordNameStrategy)$ ]]; then
    printf "%s\n" "--value-subject-name-strategy must be one of: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy" >&2
    exit 1
  fi
  eval "input_array=(${args[--validate-config]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(scrub.invalid.names=true|enhanced.avro.schema.support=true|connect.meta.data=false|object.additional.properties=false|use.optional.for.nonrequired=true|ignore.default.for.nullables=true|generalized.sum.type.support=true|enhanced.protobuf.schema.support=true|generate.index.for.unions=false|int.for.enums=true|optional.for.nullables=true|generate.struct.for.nulls=true|wrapper.for.nullables=true|wrapper.for.raw.primitives=false)$ ]]; then
      printf "%s\n" "--validate-config must be one of: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false" >&2
      exit 1
    fi
  done

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_create_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_create_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic create"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']="1"

  # :command.validations
  # :flag.validations
  if [[ -v args['--nb-partitions'] && -n $(validate_integer "${args['--nb-partitions']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$(validate_integer "${args['--nb-partitions']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --skip-delete-schema)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--skip-delete-schema']="$2"
          shift
          shift
        else
          printf "%s\n" "--skip-delete-schema requires an argument: --skip-delete-schema SKIP-DELETE-SCHEMA" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_alter_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_alter_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic alter"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_plugin_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    search-jar)
      action="search-jar"
      shift
      playground_connector_plugin_search_jar_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_plugin_versions_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_plugin_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugin_search_jar_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_search_jar_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v javap >/dev/null 2>&1; then
    deps['javap']="$(command -v javap | head -n1)"
  else
    printf "missing dependency: javap\n" >&2
    printf "%s\n" "visit https://openjdk.org/install/ to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="connector-plugin search-jar"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector-plugin | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-plugin requires an argument: --connector-plugin, -c CONNECTOR-PLUGIN" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --class)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--class']="$2"
          shift
          shift
        else
          printf "%s\n" "--class requires an argument: --class CLASS" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector-plugin']+x} ]]; then
    printf "missing required flag: --connector-plugin, -c CONNECTOR-PLUGIN\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_plugin_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector-plugin versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector-plugin | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-plugin requires an argument: --connector-plugin, -c CONNECTOR-PLUGIN" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --last)
        # :flag.conflicts
        if [[ -n "${args['--all']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--all" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--last']="$2"
          shift
          shift
        else
          printf "%s\n" "--last requires an argument: --last LAST" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector-plugin']+x} ]]; then
    printf "missing required flag: --connector-plugin, -c CONNECTOR-PLUGIN\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--last'] && -n $(validate_integer "${args['--last']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--last LAST" "$(validate_integer "${args['--last']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_connector_status_parse_requirements "$@"
      shift $#
      ;;

    offsets)
      action="offsets"
      shift
      playground_connector_offsets_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_versions_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_connector_restart_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_connector_stop_parse_requirements "$@"
      shift $#
      ;;

    resume | unpause)
      action="resume"
      shift
      playground_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    show-config)
      action="show-config"
      shift
      playground_connector_show_config_parse_requirements "$@"
      shift $#
      ;;

    show-config-parameters)
      action="show-config-parameters"
      shift
      playground_connector_show_config_parameters_parse_requirements "$@"
      shift $#
      ;;

    select-config)
      action="select-config"
      shift
      playground_connector_select_config_parse_requirements "$@"
      shift $#
      ;;

    snippets)
      action="snippets"
      shift
      playground_connector_snippets_parse_requirements "$@"
      shift $#
      ;;

    open-docs)
      action="open-docs"
      shift
      playground_connector_open_docs_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_connector_log_level_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_connector_logs_parse_requirements "$@"
      shift $#
      ;;

    open-in-confluent-cloud)
      action="open-in-confluent-cloud"
      shift
      playground_connector_open_in_confluent_cloud_parse_requirements "$@"
      shift $#
      ;;

    create-or-update)
      action="create-or-update"
      shift
      playground_connector_create_or_update_parse_requirements "$@"
      shift $#
      ;;

    update)
      action="update"
      shift
      playground_connector_update_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_connector_offsets_get_parse_requirements "$@"
      shift $#
      ;;

    reset)
      action="reset"
      shift
      playground_connector_offsets_reset_parse_requirements "$@"
      shift $#
      ;;

    alter)
      action="alter"
      shift
      playground_connector_offsets_alter_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_offsets_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_reset_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_reset_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets reset"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_alter_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_alter_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets alter"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --interval)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--interval']="$2"
          shift
          shift
        else
          printf "%s\n" "--interval requires an argument: --interval INTERVAL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--interval']:-} ]] || args['--interval']="20"

  # :command.validations
  # :flag.validations
  if [[ -v args['--interval'] && -n $(validate_integer "${args['--interval']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--interval INTERVAL" "$(validate_integer "${args['--interval']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_show_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --no-clipboard)

        # :flag.case_no_arg
        args['--no-clipboard']=1
        shift
        ;;

      # :flag.case
      --force-rest-endpoint)

        # :flag.case_no_arg
        args['--force-rest-endpoint']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_config_parameters_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_parameters_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config-parameters"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --only-show-file-path)

        # :flag.case_no_arg
        args['--only-show-file-path']=1
        shift
        ;;

      # :flag.case
      --only-show-json)

        # :flag.case_no_arg
        args['--only-show-json']=1
        shift
        ;;

      # :flag.case
      --only-show-json-file-path)

        # :flag.case_no_arg
        args['--only-show-json-file-path']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_select_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_select_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="connector select-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_snippets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_snippets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector snippets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --converter)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--converter']="$2"
          shift
          shift
        else
          printf "%s\n" "--converter requires an argument: --converter CONVERTER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --dlq)

        # :flag.case_no_arg
        args['--dlq']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--converter']:-} ]] && [[ ! ${args['--converter']:-} =~ ^(avro|protobuf|json-schema|json|json-schema-enabled|string|bytearray)$ ]]; then
    printf "%s\n" "--converter must be one of: avro, protobuf, json-schema, json, json-schema-enabled, string, bytearray" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_open_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_open_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector open-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector log-level"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --lcc-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--lcc-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--lcc-id requires an argument: --lcc-id LCC-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

  # :command.validations
  # :flag.validations
  if [[ -v args['--wait-for-log'] && -n $(validate_not_empty "${args['--wait-for-log']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$(validate_not_empty "${args['--wait-for-log']:-}")" >&2
    exit 1
  fi

  # :flag.validations
  if [[ -v args['--max-wait'] && -n $(validate_integer "${args['--max-wait']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$(validate_integer "${args['--max-wait']:-}")" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_open_in_confluent_cloud_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_open_in_confluent_cloud_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector open-in-confluent-cloud"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_create_or_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_create_or_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector create-or-update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --no-clipboard)

        # :flag.case_no_arg
        args['--no-clipboard']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-zero-lag)

        # :flag.case_no_arg
        args['--wait-for-zero-lag']=1
        shift
        ;;

      # :flag.case
      --validate)

        # :flag.case_no_arg
        args['--validate']=1
        shift
        ;;

      # :flag.case
      --skip-automatic-connector-config)

        # :flag.case_no_arg
        args['--skip-automatic-connector-config']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['json']+x} ]]; then
          args['json']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['json']:-} ]] || args['json']="-"

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] && -n $(validate_not_empty "${args['--package']:-}") ]]; then
    printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "${args['--package']:-}")" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.user_hooks
before_hook() {
  # src/before.sh

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  vvv="${args[--vvv]}"
  level="${args[--output-level]}"

  if [[ -n "$vvv" ]]
  then
      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          log "🐛 --vvv is set"
          export PS4='\[\033[0;36m\]🐞$(date "+%H:%M:%S")[$(basename $0):${LINENO}] \[\033[0m\]'
          set -x
          export PG_VERBOSE_MODE=true
      fi
  fi

  if [[ -n "$level" ]]
  then
      export PG_LOG_LEVEL="$level"
      log "🔖 --output-level is set with $level"
  fi
}

# :command.initialize
initialize() {
  version="1.0.0"
  long_usage=''
  set -e

}

# :command.run
run() {
  declare -A args=()
  declare -A deps=()
  declare -a other_args=()
  declare -a env_var_names=()
  declare -a input=()
  declare -A unique_lookup=()
  normalize_input "$@"
  parse_requirements "${input[@]}"
  before_hook

  case "$action" in
    "help") playground_help_command ;;
    "status") playground_status_command ;;
    "get-connector-list") playground_get_connector_list_command ;;
    "generate-fzf-find-files") playground_generate_fzf_find_files_command ;;
    "generate-tag-list") playground_generate_tag_list_command ;;
    "generate-connector-plugin-list") playground_generate_connector_plugin_list_command ;;
    "generate-kafka-region-list") playground_generate_kafka_region_list_command ;;
    "get-connector-plugin") playground_get_connector_plugin_command ;;
    "get-ccloud-environment-list") playground_get_ccloud_environment_list_command ;;
    "get-ccloud-cluster-list") playground_get_ccloud_cluster_list_command ;;
    "get-tag-list") playground_get_tag_list_command ;;
    "get-kafka-region-list") playground_get_kafka_region_list_command ;;
    "get-topic-list") playground_get_topic_list_command ;;
    "get-subject-list") playground_get_subject_list_command ;;
    "get-examples-list-with-fzf") playground_get_examples_list_with_fzf_command ;;
    "get-zip-or-jar-with-fzf") playground_get_zip_or_jar_with_fzf_command ;;
    "get-any-file-with-fzf") playground_get_any_file_with_fzf_command ;;
    "get-playground-repro-export-with-fzf") playground_get_playground_repro_export_with_fzf_command ;;
    "get-predefined-schemas") playground_get_predefined_schemas_command ;;
    "update-readme") playground_update_readme_command ;;
    "bashly-reload") playground_bashly_reload_command ;;
    "state") playground_state_command ;;
    "state show") playground_state_show_command ;;
    "state get") playground_state_get_command ;;
    "state set") playground_state_set_command ;;
    "state del") playground_state_del_command ;;
    "config") playground_config_command ;;
    "config show") playground_config_show_command ;;
    "config get") playground_config_get_command ;;
    "config set") playground_config_set_command ;;
    "config editor") playground_config_editor_command ;;
    "config folder_zip_or_jar") playground_config_folder_zip_or_jar_command ;;
    "config clipboard") playground_config_clipboard_command ;;
    "run") playground_run_command ;;
    "re-run") playground_re_run_command ;;
    "history") playground_history_command ;;
    "start-environment") playground_start_environment_command ;;
    "switch-ccloud") playground_switch_ccloud_command ;;
    "switch-back") playground_switch_back_command ;;
    "update-version") playground_update_version_command ;;
    "open") playground_open_command ;;
    "stop") playground_stop_command ;;
    "remove-all-docker-images") playground_remove_all_docker_images_command ;;
    "open-docs") playground_open_docs_command ;;
    "cleanup-cloud-resources") playground_cleanup_cloud_resources_command ;;
    "repro") playground_repro_command ;;
    "repro export") playground_repro_export_command ;;
    "repro import") playground_repro_import_command ;;
    "repro bootstrap") playground_repro_bootstrap_command ;;
    "get-docker-compose") playground_get_docker_compose_command ;;
    "schema") playground_schema_command ;;
    "schema get") playground_schema_get_command ;;
    "schema register") playground_schema_register_command ;;
    "schema get-compatibility") playground_schema_get_compatibility_command ;;
    "schema set-compatibility") playground_schema_set_compatibility_command ;;
    "schema get-mode") playground_schema_get_mode_command ;;
    "schema set-mode") playground_schema_set_mode_command ;;
    "schema delete") playground_schema_delete_command ;;
    "debug") playground_debug_command ;;
    "debug install-vscode-extension") playground_debug_install_vscode_extension_command ;;
    "debug enable-remote-debugging") playground_debug_enable_remote_debugging_command ;;
    "debug testssl") playground_debug_testssl_command ;;
    "debug generate-diagnostics") playground_debug_generate_diagnostics_command ;;
    "debug thread-dump") playground_debug_thread_dump_command ;;
    "debug heap-dump") playground_debug_heap_dump_command ;;
    "debug tcp-dump") playground_debug_tcp_dump_command ;;
    "debug block-traffic") playground_debug_block_traffic_command ;;
    "debug flight-recorder") playground_debug_flight_recorder_command ;;
    "debug log-level") playground_debug_log_level_command ;;
    "debug log-level get") playground_debug_log_level_get_command ;;
    "debug log-level set") playground_debug_log_level_set_command ;;
    "get-jmx-metrics") playground_get_jmx_metrics_command ;;
    "container") playground_container_command ;;
    "container get-properties") playground_container_get_properties_command ;;
    "container recreate") playground_container_recreate_command ;;
    "container get-ip-addresses") playground_container_get_ip_addresses_command ;;
    "container kill-all") playground_container_kill_all_command ;;
    "container logs") playground_container_logs_command ;;
    "container ssh") playground_container_ssh_command ;;
    "container exec") playground_container_exec_command ;;
    "container restart") playground_container_restart_command ;;
    "container pause") playground_container_pause_command ;;
    "container resume") playground_container_resume_command ;;
    "container kill") playground_container_kill_command ;;
    "topic") playground_topic_command ;;
    "topic get-number-records") playground_topic_get_number_records_command ;;
    "topic display-consumer-offsets") playground_topic_display_consumer_offsets_command ;;
    "topic list") playground_topic_list_command ;;
    "topic describe") playground_topic_describe_command ;;
    "topic set-schema-compatibility") playground_topic_set_schema_compatibility_command ;;
    "topic consume") playground_topic_consume_command ;;
    "topic produce") playground_topic_produce_command ;;
    "topic create") playground_topic_create_command ;;
    "topic delete") playground_topic_delete_command ;;
    "topic alter") playground_topic_alter_command ;;
    "connector-plugin") playground_connector_plugin_command ;;
    "connector-plugin search-jar") playground_connector_plugin_search_jar_command ;;
    "connector-plugin versions") playground_connector_plugin_versions_command ;;
    "connector") playground_connector_command ;;
    "connector status") playground_connector_status_command ;;
    "connector offsets") playground_connector_offsets_command ;;
    "connector offsets get") playground_connector_offsets_get_command ;;
    "connector offsets reset") playground_connector_offsets_reset_command ;;
    "connector offsets alter") playground_connector_offsets_alter_command ;;
    "connector plugins") playground_connector_plugins_command ;;
    "connector pause") playground_connector_pause_command ;;
    "connector versions") playground_connector_versions_command ;;
    "connector restart") playground_connector_restart_command ;;
    "connector stop") playground_connector_stop_command ;;
    "connector resume") playground_connector_resume_command ;;
    "connector delete") playground_connector_delete_command ;;
    "connector show-lag") playground_connector_show_lag_command ;;
    "connector show-config") playground_connector_show_config_command ;;
    "connector show-config-parameters") playground_connector_show_config_parameters_command ;;
    "connector select-config") playground_connector_select_config_command ;;
    "connector snippets") playground_connector_snippets_command ;;
    "connector open-docs") playground_connector_open_docs_command ;;
    "connector log-level") playground_connector_log_level_command ;;
    "connector logs") playground_connector_logs_command ;;
    "connector open-in-confluent-cloud") playground_connector_open_in_confluent_cloud_command ;;
    "connector create-or-update") playground_connector_create_or_update_command ;;
    "connector update") playground_connector_update_command ;;
  esac
}

initialize
run "$@"
